{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b97f8959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rdkit\n",
      "  Downloading rdkit-2023.3.3-cp38-cp38-win_amd64.whl (20.6 MB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\anaconda3\\lib\\site-packages (from rdkit) (9.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from rdkit) (1.22.4)\n",
      "Installing collected packages: rdkit\n",
      "Successfully installed rdkit-2023.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "a76c4f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from rdkit import DataStructs\n",
    "from rdkit import rdBase, Chem\n",
    "from rdkit.Chem import AllChem, PandasTools, Descriptors\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import autogluon.core as ag\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "beb0cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"C:/Users/user/Desktop/데이콘 신약대회/open/train.csv\")\n",
    "test=pd.read_csv(\"C:/Users/user/Desktop/데이콘 신약대회/open/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "d32f608a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            0\n",
       "SMILES                        0\n",
       "MLM                           0\n",
       "HLM                           0\n",
       "AlogP                         2\n",
       "Molecular_Weight              0\n",
       "Num_H_Acceptors               0\n",
       "Num_H_Donors                  0\n",
       "Num_RotatableBonds            0\n",
       "LogD                          0\n",
       "Molecular_PolarSurfaceArea    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "1be372a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            0\n",
       "SMILES                        0\n",
       "AlogP                         1\n",
       "Molecular_Weight              0\n",
       "Num_H_Acceptors               0\n",
       "Num_H_Donors                  0\n",
       "Num_RotatableBonds            0\n",
       "LogD                          0\n",
       "Molecular_PolarSurfaceArea    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "655bd76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3498 entries, 0 to 3497\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          3498 non-null   object \n",
      " 1   SMILES                      3498 non-null   object \n",
      " 2   MLM                         3498 non-null   float64\n",
      " 3   HLM                         3498 non-null   float64\n",
      " 4   AlogP                       3496 non-null   float64\n",
      " 5   Molecular_Weight            3498 non-null   float64\n",
      " 6   Num_H_Acceptors             3498 non-null   int64  \n",
      " 7   Num_H_Donors                3498 non-null   int64  \n",
      " 8   Num_RotatableBonds          3498 non-null   int64  \n",
      " 9   LogD                        3498 non-null   float64\n",
      " 10  Molecular_PolarSurfaceArea  3498 non-null   float64\n",
      "dtypes: float64(6), int64(3), object(2)\n",
      "memory usage: 300.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "ba8d2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 보간\n",
    "train['AlogP'] = train['AlogP'].interpolate()\n",
    "test['AlogP'] = test['AlogP'].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadfdd28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "4a942780",
   "metadata": {},
   "outputs": [],
   "source": [
    "PandasTools.AddMoleculeColumnToFrame(train,'SMILES')\n",
    "PandasTools.AddMoleculeColumnToFrame(test,'SMILES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "a8db9ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3498, 12)\n",
      "(483, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "034ac99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, SMILES, MLM, HLM, AlogP, Molecular_Weight, Num_H_Acceptors, Num_H_Donors, Num_RotatableBonds, LogD, Molecular_PolarSurfaceArea, ROMol]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [id, SMILES, AlogP, Molecular_Weight, Num_H_Acceptors, Num_H_Donors, Num_RotatableBonds, LogD, Molecular_PolarSurfaceArea, ROMol]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(train[train.ROMol.isnull()])\n",
    "print(test[test.ROMol.isnull()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "03a85e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in Descriptors.descList:\n",
    "    train[i] = train.ROMol.map(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d8e8e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in Descriptors.descList:\n",
    "    test[i] = test.ROMol.map(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "a288f311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3498, 221)\n",
      "(483, 219)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "819c6df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>MLM</th>\n",
       "      <th>HLM</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>Molecular_Weight</th>\n",
       "      <th>Num_H_Acceptors</th>\n",
       "      <th>Num_H_Donors</th>\n",
       "      <th>Num_RotatableBonds</th>\n",
       "      <th>LogD</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC</td>\n",
       "      <td>26.010</td>\n",
       "      <td>50.680</td>\n",
       "      <td>3.259</td>\n",
       "      <td>400.495</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3.259</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1</td>\n",
       "      <td>29.270</td>\n",
       "      <td>50.590</td>\n",
       "      <td>2.169</td>\n",
       "      <td>301.407</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1</td>\n",
       "      <td>5.586</td>\n",
       "      <td>80.892</td>\n",
       "      <td>1.593</td>\n",
       "      <td>297.358</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.585</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC5)CC4)c3C)nn2)cc1</td>\n",
       "      <td>5.710</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.771</td>\n",
       "      <td>494.652</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.475</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2</td>\n",
       "      <td>93.270</td>\n",
       "      <td>99.990</td>\n",
       "      <td>2.335</td>\n",
       "      <td>268.310</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.337</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  \\\n",
       "0  TRAIN_0000   \n",
       "1  TRAIN_0001   \n",
       "2  TRAIN_0002   \n",
       "3  TRAIN_0003   \n",
       "4  TRAIN_0004   \n",
       "\n",
       "                                                            SMILES     MLM  \\\n",
       "0                  CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC  26.010   \n",
       "1                             Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1  29.270   \n",
       "2                                 CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1   5.586   \n",
       "3  Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC5)CC4)c3C)nn2)cc1   5.710   \n",
       "4                              Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2  93.270   \n",
       "\n",
       "      HLM  AlogP  Molecular_Weight  Num_H_Acceptors  Num_H_Donors  \\\n",
       "0  50.680  3.259           400.495                5             2   \n",
       "1  50.590  2.169           301.407                2             1   \n",
       "2  80.892  1.593           297.358                5             0   \n",
       "3   2.000  4.771           494.652                6             0   \n",
       "4  99.990  2.335           268.310                3             0   \n",
       "\n",
       "   Num_RotatableBonds   LogD  ...  fr_sulfide fr_sulfonamd  fr_sulfone  \\\n",
       "0                   8  3.259  ...           0            0           0   \n",
       "1                   2  2.172  ...           0            0           0   \n",
       "2                   3  1.585  ...           0            0           0   \n",
       "3                   5  3.475  ...           0            1           0   \n",
       "4                   1  2.337  ...           0            0           0   \n",
       "\n",
       "   fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiocyan  fr_thiophene  \\\n",
       "0                  0             0            1            0             0   \n",
       "1                  0             0            1            0             0   \n",
       "2                  0             1            0            0             0   \n",
       "3                  0             0            0            0             0   \n",
       "4                  0             0            0            0             0   \n",
       "\n",
       "   fr_unbrch_alkane  fr_urea  \n",
       "0                 0        0  \n",
       "1                 0        0  \n",
       "2                 0        0  \n",
       "3                 0        0  \n",
       "4                 0        0  \n",
       "\n",
       "[5 rows x 221 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "7151932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['FP'] = train.apply(lambda x: AllChem.GetMorganFingerprintAsBitVect(x.ROMol, 2, 1024), axis=1)\n",
    "test['FP'] = test.apply(lambda x: AllChem.GetMorganFingerprintAsBitVect(x.ROMol, 2, 1024), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "01a87f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_1 = [AllChem.GetMorganFingerprintAsBitVect(mol, 2, 1024) for mol in train.ROMol]\n",
    "FP_2 = [AllChem.GetMorganFingerprintAsBitVect(mol, 2, 1024) for mol in test.ROMol]\n",
    "df_FP_1 = pd.DataFrame(np.array(FP_1)) \n",
    "df_FP_2 = pd.DataFrame(np.array(FP_2)) \n",
    "\n",
    "df_FP_1.index = train.index\n",
    "df_FP_2.index = test.index\n",
    "\n",
    "train = pd.concat([train, df_FP_1], axis=1)\n",
    "test = pd.concat([test, df_FP_2], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fbdaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "375a3004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3498 entries, 0 to 3497\n",
      "Columns: 1246 entries, id to 1023\n",
      "dtypes: float64(111), int32(1024), int64(107), object(4)\n",
      "memory usage: 19.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "40b23f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 483 entries, 0 to 482\n",
      "Columns: 1244 entries, id to 1023\n",
      "dtypes: float64(109), int32(1024), int64(107), object(4)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "e1fe9a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>ROMol</th>\n",
       "      <th>FP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000271C82B75F0&gt;</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000271C82B7430&gt;</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000271C82B7900&gt;</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC5)CC4)c3C)nn2)cc1</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000271C82B7970&gt;</td>\n",
       "      <td>[0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000271C82B79E0&gt;</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>TRAIN_3493</td>\n",
       "      <td>Cn1nc(CNC(=O)Cn2nc(C(F)(F)F)c3c2CCC3)c(Cl)c1Cl</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000271C7A167B0&gt;</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>TRAIN_3494</td>\n",
       "      <td>CCn1[nH]cc/c1=N\\C(=O)c1nn(-c2ccccc2)c(=O)c2ccccc12</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000271C7A16820&gt;</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>TRAIN_3495</td>\n",
       "      <td>CCOC(=O)CCCc1nc2cc(N)ccc2n1C</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000271C7A16890&gt;</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>TRAIN_3496</td>\n",
       "      <td>Nc1cc(C(=O)OCCC2CCOC2=O)cnc1Cl</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000271C7A16900&gt;</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>TRAIN_3497</td>\n",
       "      <td>COc1ccc(-c2nc(Cc3ccccc3)sc2C)cc1</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000271C7A16970&gt;</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3498 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  \\\n",
       "0     TRAIN_0000   \n",
       "1     TRAIN_0001   \n",
       "2     TRAIN_0002   \n",
       "3     TRAIN_0003   \n",
       "4     TRAIN_0004   \n",
       "...          ...   \n",
       "3493  TRAIN_3493   \n",
       "3494  TRAIN_3494   \n",
       "3495  TRAIN_3495   \n",
       "3496  TRAIN_3496   \n",
       "3497  TRAIN_3497   \n",
       "\n",
       "                                                               SMILES  \\\n",
       "0                     CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC   \n",
       "1                                Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1   \n",
       "2                                    CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1   \n",
       "3     Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC5)CC4)c3C)nn2)cc1   \n",
       "4                                 Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2   \n",
       "...                                                               ...   \n",
       "3493                   Cn1nc(CNC(=O)Cn2nc(C(F)(F)F)c3c2CCC3)c(Cl)c1Cl   \n",
       "3494               CCn1[nH]cc/c1=N\\C(=O)c1nn(-c2ccccc2)c(=O)c2ccccc12   \n",
       "3495                                     CCOC(=O)CCCc1nc2cc(N)ccc2n1C   \n",
       "3496                                   Nc1cc(C(=O)OCCC2CCOC2=O)cnc1Cl   \n",
       "3497                                 COc1ccc(-c2nc(Cc3ccccc3)sc2C)cc1   \n",
       "\n",
       "                                                     ROMol  \\\n",
       "0     <rdkit.Chem.rdchem.Mol object at 0x00000271C82B75F0>   \n",
       "1     <rdkit.Chem.rdchem.Mol object at 0x00000271C82B7430>   \n",
       "2     <rdkit.Chem.rdchem.Mol object at 0x00000271C82B7900>   \n",
       "3     <rdkit.Chem.rdchem.Mol object at 0x00000271C82B7970>   \n",
       "4     <rdkit.Chem.rdchem.Mol object at 0x00000271C82B79E0>   \n",
       "...                                                    ...   \n",
       "3493  <rdkit.Chem.rdchem.Mol object at 0x00000271C7A167B0>   \n",
       "3494  <rdkit.Chem.rdchem.Mol object at 0x00000271C7A16820>   \n",
       "3495  <rdkit.Chem.rdchem.Mol object at 0x00000271C7A16890>   \n",
       "3496  <rdkit.Chem.rdchem.Mol object at 0x00000271C7A16900>   \n",
       "3497  <rdkit.Chem.rdchem.Mol object at 0x00000271C7A16970>   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                     FP  \n",
       "0     [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, ...]  \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...]  \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]  \n",
       "3     [0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...]  \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]  \n",
       "...                                                                                                                                                                                                                                                                                                                 ...  \n",
       "3493  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]  \n",
       "3494  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]  \n",
       "3495  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]  \n",
       "3496  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]  \n",
       "3497  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]  \n",
       "\n",
       "[3498 rows x 4 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(include='object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c8ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "1f70f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['id','SMILES', 'ROMol', 'FP'], axis = 1)\n",
    "test = test.drop(['id', 'SMILES', 'ROMol', 'FP'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "1bd01f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLM</th>\n",
       "      <th>HLM</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>Molecular_Weight</th>\n",
       "      <th>Num_H_Acceptors</th>\n",
       "      <th>Num_H_Donors</th>\n",
       "      <th>Num_RotatableBonds</th>\n",
       "      <th>LogD</th>\n",
       "      <th>Molecular_PolarSurfaceArea</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.010</td>\n",
       "      <td>50.680</td>\n",
       "      <td>3.259</td>\n",
       "      <td>400.495</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3.259</td>\n",
       "      <td>117.37</td>\n",
       "      <td>12.482330</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.270</td>\n",
       "      <td>50.590</td>\n",
       "      <td>2.169</td>\n",
       "      <td>301.407</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.172</td>\n",
       "      <td>73.47</td>\n",
       "      <td>12.098337</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.586</td>\n",
       "      <td>80.892</td>\n",
       "      <td>1.593</td>\n",
       "      <td>297.358</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.585</td>\n",
       "      <td>62.45</td>\n",
       "      <td>4.646025</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.710</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.771</td>\n",
       "      <td>494.652</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.475</td>\n",
       "      <td>92.60</td>\n",
       "      <td>13.641142</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.270</td>\n",
       "      <td>99.990</td>\n",
       "      <td>2.335</td>\n",
       "      <td>268.310</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.337</td>\n",
       "      <td>42.43</td>\n",
       "      <td>12.661906</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>1.556</td>\n",
       "      <td>3.079</td>\n",
       "      <td>3.409</td>\n",
       "      <td>396.195</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.409</td>\n",
       "      <td>64.74</td>\n",
       "      <td>13.033764</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>35.560</td>\n",
       "      <td>47.630</td>\n",
       "      <td>1.912</td>\n",
       "      <td>359.381</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.844</td>\n",
       "      <td>77.37</td>\n",
       "      <td>12.917253</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>56.150</td>\n",
       "      <td>1.790</td>\n",
       "      <td>1.941</td>\n",
       "      <td>261.320</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.124</td>\n",
       "      <td>70.14</td>\n",
       "      <td>11.269030</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>0.030</td>\n",
       "      <td>2.770</td>\n",
       "      <td>0.989</td>\n",
       "      <td>284.696</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.989</td>\n",
       "      <td>91.51</td>\n",
       "      <td>11.686457</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>0.450</td>\n",
       "      <td>2.650</td>\n",
       "      <td>4.321</td>\n",
       "      <td>295.399</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.321</td>\n",
       "      <td>50.36</td>\n",
       "      <td>5.201697</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3498 rows × 1242 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MLM     HLM  AlogP  Molecular_Weight  Num_H_Acceptors  Num_H_Donors  \\\n",
       "0     26.010  50.680  3.259           400.495                5             2   \n",
       "1     29.270  50.590  2.169           301.407                2             1   \n",
       "2      5.586  80.892  1.593           297.358                5             0   \n",
       "3      5.710   2.000  4.771           494.652                6             0   \n",
       "4     93.270  99.990  2.335           268.310                3             0   \n",
       "...      ...     ...    ...               ...              ...           ...   \n",
       "3493   1.556   3.079  3.409           396.195                3             1   \n",
       "3494  35.560  47.630  1.912           359.381                4             1   \n",
       "3495  56.150   1.790  1.941           261.320                3             1   \n",
       "3496   0.030   2.770  0.989           284.696                5             1   \n",
       "3497   0.450   2.650  4.321           295.399                2             0   \n",
       "\n",
       "      Num_RotatableBonds   LogD  Molecular_PolarSurfaceArea  \\\n",
       "0                      8  3.259                      117.37   \n",
       "1                      2  2.172                       73.47   \n",
       "2                      3  1.585                       62.45   \n",
       "3                      5  3.475                       92.60   \n",
       "4                      1  2.337                       42.43   \n",
       "...                  ...    ...                         ...   \n",
       "3493                   5  3.409                       64.74   \n",
       "3494                   3  1.844                       77.37   \n",
       "3495                   6  2.124                       70.14   \n",
       "3496                   5  0.989                       91.51   \n",
       "3497                   4  4.321                       50.36   \n",
       "\n",
       "      MaxAbsEStateIndex  ...  1014  1015  1016  1017  1018  1019  1020  1021  \\\n",
       "0             12.482330  ...     0     0     0     0     0     0     0     0   \n",
       "1             12.098337  ...     0     0     0     0     0     1     0     0   \n",
       "2              4.646025  ...     0     0     0     0     0     0     0     0   \n",
       "3             13.641142  ...     0     0     0     0     0     1     0     1   \n",
       "4             12.661906  ...     0     0     0     0     0     1     0     0   \n",
       "...                 ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "3493          13.033764  ...     0     0     0     0     0     0     0     0   \n",
       "3494          12.917253  ...     0     0     0     0     0     0     0     0   \n",
       "3495          11.269030  ...     0     0     0     0     0     0     0     0   \n",
       "3496          11.686457  ...     0     0     0     0     0     1     0     0   \n",
       "3497           5.201697  ...     0     0     0     0     0     0     0     0   \n",
       "\n",
       "      1022  1023  \n",
       "0        0     0  \n",
       "1        0     0  \n",
       "2        0     0  \n",
       "3        0     0  \n",
       "4        0     0  \n",
       "...    ...   ...  \n",
       "3493     0     0  \n",
       "3494     0     0  \n",
       "3495     0     0  \n",
       "3496     0     0  \n",
       "3497     0     0  \n",
       "\n",
       "[3498 rows x 1242 columns]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c29f015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "cb323e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_=train.copy()\n",
    "train_ = train_.drop('HLM', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "19bc2053",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 = TabularDataset(train_)\n",
    "test_data = TabularDataset(test)\n",
    "\n",
    "label = 'MLM'\n",
    "eval_metric = 'root_mean_squared_error'\n",
    "time_limit = 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "a69b1ec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230910_115534\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230910_115534\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   112.99 GB / 237.11 GB (47.7%)\n",
      "Train Data Rows:    3498\n",
      "Train Data Columns: 1242\n",
      "Label Column: MLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (131.72, 0.0, 37.38474, 35.69599)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2678.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 20.43 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1036 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 18): ['NumRadicalElectrons', 'SMR_VSA8', 'SlogP_VSA9', 'fr_SH', 'fr_azide', 'fr_azo', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitroso', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_term_acetylene', 'fr_thiocyan']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 5): ['MaxEStateIndex', 'fr_COO2', 'fr_Nhpyrrole', 'fr_benzene', 'fr_quatN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['MaxEStateIndex']\n",
      "\t\t('int', [])   : 4 | ['fr_COO2', 'fr_Nhpyrrole', 'fr_benzene', 'fr_quatN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  108 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea', 'MaxAbsEStateIndex', ...]\n",
      "\t\t('int', [])   : 1111 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds', 'NumValenceElectrons', 'HeavyAtomCount', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  108 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea', 'MaxAbsEStateIndex', ...]\n",
      "\t\t('int', [])       :   76 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds', 'NumValenceElectrons', 'HeavyAtomCount', ...]\n",
      "\t\t('int', ['bool']) : 1035 | ['fr_C_S', 'fr_aldehyde', 'fr_barbitur', 'fr_epoxide', 'fr_hdrzine', ...]\n",
      "\t8.0s = Fit runtime\n",
      "\t1219 features in original data used to generate 1219 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.77 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 8.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 4 stack levels (L1 to L4) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1196.97s of the 3591.79s of remaining time.\n",
      "\tWarning: Potentially not enough memory to safely train model. Estimated to require 0.061 GB out of 2.687 GB available memory (11.425%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.20 to avoid the warning)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\tWarning: Exception caused KNeighborsUnif_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute 'split'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 250, in _fit\n",
      "    self._fit_single(X=X, y=y, model_base=model_base, use_child_oof=use_child_oof, skip_oof=_skip_oof, **kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 416, in _fit_single\n",
      "    self._oof_pred_proba = model_base.get_oof_pred_proba(X=X, y=y)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\tabular\\models\\knn\\knn_model.py\", line 115, in get_oof_pred_proba\n",
      "    y_oof_pred_proba = self._get_oof_pred_proba(X=X, **kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\tabular\\models\\knn\\knn_model.py\", line 129, in _get_oof_pred_proba\n",
      "    y_oof_pred_proba = KNeighborsRegressorLOOMixin.predict_loo(self.model)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\tabular\\models\\knn\\_knn_loo_variants.py\", line 115, in predict_loo\n",
      "    neigh_dist, neigh_ind = self.kneighbors()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 289, in compute\n",
      "    return ArgKmin32.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 139, in threadpool_limits\n",
      "    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 171, in __init__\n",
      "    self._original_info = self._set_threadpool_limits()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 268, in _set_threadpool_limits\n",
      "    modules = _ThreadpoolInfo(prefixes=self._prefixes,\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 340, in __init__\n",
      "    self._load_modules()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 373, in _load_modules\n",
      "    self._find_modules_with_enum_process_module_ex()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 485, in _find_modules_with_enum_process_module_ex\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1196.59s of the 3591.41s of remaining time.\n",
      "\tWarning: Potentially not enough memory to safely train model. Estimated to require 0.061 GB out of 2.683 GB available memory (11.443%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.20 to avoid the warning)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\tWarning: Exception caused KNeighborsDist_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute 'split'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 250, in _fit\n",
      "    self._fit_single(X=X, y=y, model_base=model_base, use_child_oof=use_child_oof, skip_oof=_skip_oof, **kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 416, in _fit_single\n",
      "    self._oof_pred_proba = model_base.get_oof_pred_proba(X=X, y=y)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\tabular\\models\\knn\\knn_model.py\", line 115, in get_oof_pred_proba\n",
      "    y_oof_pred_proba = self._get_oof_pred_proba(X=X, **kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\tabular\\models\\knn\\knn_model.py\", line 129, in _get_oof_pred_proba\n",
      "    y_oof_pred_proba = KNeighborsRegressorLOOMixin.predict_loo(self.model)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\tabular\\models\\knn\\_knn_loo_variants.py\", line 115, in predict_loo\n",
      "    neigh_dist, neigh_ind = self.kneighbors()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 289, in compute\n",
      "    return ArgKmin32.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 139, in threadpool_limits\n",
      "    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 171, in __init__\n",
      "    self._original_info = self._set_threadpool_limits()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 268, in _set_threadpool_limits\n",
      "    modules = _ThreadpoolInfo(prefixes=self._prefixes,\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 340, in __init__\n",
      "    self._load_modules()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 373, in _load_modules\n",
      "    self._find_modules_with_enum_process_module_ex()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 485, in _find_modules_with_enum_process_module_ex\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1196.23s of the 3591.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.2859\t = Validation score   (-root_mean_squared_error)\n",
      "\t21.27s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1165.55s of the 3560.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.5457\t = Validation score   (-root_mean_squared_error)\n",
      "\t22.58s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1132.93s of the 3527.75s of remaining time.\n",
      "\t-30.6487\t = Validation score   (-root_mean_squared_error)\n",
      "\t100.01s\t = Training   runtime\n",
      "\t2.67s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1029.85s of the 3424.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.4384\t = Validation score   (-root_mean_squared_error)\n",
      "\t361.1s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 658.56s of the 3053.36s of remaining time.\n",
      "\t-30.5452\t = Validation score   (-root_mean_squared_error)\n",
      "\t68.37s\t = Training   runtime\n",
      "\t2.58s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 587.15s of the 2981.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-25295118.0782\t = Validation score   (-root_mean_squared_error)\n",
      "\t38.68s\t = Training   runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 537.46s of the 2932.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.8392\t = Validation score   (-root_mean_squared_error)\n",
      "\t52.79s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 472.97s of the 2867.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-32.9767\t = Validation score   (-root_mean_squared_error)\n",
      "\t35.44s\t = Training   runtime\n",
      "\t1.77s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 426.82s of the 2821.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.7983\t = Validation score   (-root_mean_squared_error)\n",
      "\t75.18s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 2734.71s of remaining time.\n",
      "\t-29.9488\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1214.95s of the 2734.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.2123\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.36s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 1187.6s of the 2706.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.3802\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.84s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 1158.69s of the 2677.96s of remaining time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-30.3957\t = Validation score   (-root_mean_squared_error)\n",
      "\t114.08s\t = Training   runtime\n",
      "\t2.46s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 1041.52s of the 2560.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.0088\t = Validation score   (-root_mean_squared_error)\n",
      "\t96.37s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 934.32s of the 2453.63s of remaining time.\n",
      "\t-30.3242\t = Validation score   (-root_mean_squared_error)\n",
      "\t76.77s\t = Training   runtime\n",
      "\t2.53s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 854.46s of the 2373.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11537730.2544\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.17s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 806.22s of the 2325.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.7035\t = Validation score   (-root_mean_squared_error)\n",
      "\t42.62s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 752.6s of the 2271.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-32.045\t = Validation score   (-root_mean_squared_error)\n",
      "\t33.82s\t = Training   runtime\n",
      "\t1.78s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 707.41s of the 2226.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.7387\t = Validation score   (-root_mean_squared_error)\n",
      "\t112.74s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 2101.39s of remaining time.\n",
      "\t-29.9296\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L3 models ...\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 1400.28s of the 2100.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.3022\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.51s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 1372.58s of the 2073.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.6017\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.17s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L3 ... Training model for up to 1342.46s of the 2043.04s of remaining time.\n",
      "\t-30.5629\t = Validation score   (-root_mean_squared_error)\n",
      "\t115.68s\t = Training   runtime\n",
      "\t2.45s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 1223.77s of the 1924.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.1373\t = Validation score   (-root_mean_squared_error)\n",
      "\t96.69s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L3 ... Training model for up to 1116.22s of the 1816.79s of remaining time.\n",
      "\t-30.5868\t = Validation score   (-root_mean_squared_error)\n",
      "\t76.68s\t = Training   runtime\n",
      "\t2.64s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 1036.31s of the 1736.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-2076733952.8784\t = Validation score   (-root_mean_squared_error)\n",
      "\t35.68s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 989.64s of the 1690.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.4949\t = Validation score   (-root_mean_squared_error)\n",
      "\t47.28s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 931.42s of the 1632.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-32.251\t = Validation score   (-root_mean_squared_error)\n",
      "\t35.11s\t = Training   runtime\n",
      "\t1.73s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 885.45s of the 1585.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.7775\t = Validation score   (-root_mean_squared_error)\n",
      "\t138.21s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.0s of the 1435.34s of remaining time.\n",
      "\t-30.0611\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L4 models ...\n",
      "Fitting model: LightGBMXT_BAG_L4 ... Training model for up to 1434.9s of the 1434.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.436\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.02s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L4 ... Training model for up to 1408.55s of the 1408.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.6653\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.69s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L4 ... Training model for up to 1378.99s of the 1378.9s of remaining time.\n",
      "\t-30.7537\t = Validation score   (-root_mean_squared_error)\n",
      "\t117.79s\t = Training   runtime\n",
      "\t2.48s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L4 ... Training model for up to 1258.18s of the 1258.1s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.2838\t = Validation score   (-root_mean_squared_error)\n",
      "\t101.48s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L4 ... Training model for up to 1146.0s of the 1145.93s of remaining time.\n",
      "\t-30.731\t = Validation score   (-root_mean_squared_error)\n",
      "\t75.65s\t = Training   runtime\n",
      "\t2.53s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L4 ... Training model for up to 1067.28s of the 1067.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-4305312996.1258\t = Validation score   (-root_mean_squared_error)\n",
      "\t34.04s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L4 ... Training model for up to 1022.23s of the 1022.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.8251\t = Validation score   (-root_mean_squared_error)\n",
      "\t47.37s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L4 ... Training model for up to 963.89s of the 963.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-32.5923\t = Validation score   (-root_mean_squared_error)\n",
      "\t33.94s\t = Training   runtime\n",
      "\t1.69s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L4 ... Training model for up to 918.37s of the 918.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-30.8906\t = Validation score   (-root_mean_squared_error)\n",
      "\t154.76s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L5 ... Training model for up to 360.0s of the 750.6s of remaining time.\n",
      "\t-30.2531\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2849.8s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230910_115534\\\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(\n",
    "    label=label, eval_metric=eval_metric\n",
    ").fit(train_data1,  presets='best_quality', time_limit=time_limit, \n",
    "      num_stack_levels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "81587c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-2.992956e+01</td>\n",
       "      <td>16.976287</td>\n",
       "      <td>1113.251006</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.401389</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-2.994883e+01</td>\n",
       "      <td>8.725274</td>\n",
       "      <td>737.121148</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.366491</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-3.000877e+01</td>\n",
       "      <td>9.899927</td>\n",
       "      <td>871.808294</td>\n",
       "      <td>0.417876</td>\n",
       "      <td>96.372906</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L4</td>\n",
       "      <td>-3.006113e+01</td>\n",
       "      <td>23.608909</td>\n",
       "      <td>1635.915210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.422915</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost_BAG_L3</td>\n",
       "      <td>-3.013729e+01</td>\n",
       "      <td>18.897458</td>\n",
       "      <td>1419.917083</td>\n",
       "      <td>0.385293</td>\n",
       "      <td>96.691997</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>-3.021232e+01</td>\n",
       "      <td>9.782707</td>\n",
       "      <td>791.799095</td>\n",
       "      <td>0.300657</td>\n",
       "      <td>16.363707</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WeightedEnsemble_L5</td>\n",
       "      <td>-3.025312e+01</td>\n",
       "      <td>35.769815</td>\n",
       "      <td>2452.548143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322819</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost_BAG_L4</td>\n",
       "      <td>-3.028377e+01</td>\n",
       "      <td>28.103187</td>\n",
       "      <td>2006.710318</td>\n",
       "      <td>0.439432</td>\n",
       "      <td>101.476405</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-3.028589e+01</td>\n",
       "      <td>0.322187</td>\n",
       "      <td>21.273682</td>\n",
       "      <td>0.322187</td>\n",
       "      <td>21.273682</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMXT_BAG_L3</td>\n",
       "      <td>-3.030219e+01</td>\n",
       "      <td>18.797245</td>\n",
       "      <td>1340.730571</td>\n",
       "      <td>0.285079</td>\n",
       "      <td>17.505485</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2</td>\n",
       "      <td>-3.032424e+01</td>\n",
       "      <td>12.015009</td>\n",
       "      <td>852.208323</td>\n",
       "      <td>2.532959</td>\n",
       "      <td>76.772935</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-3.038022e+01</td>\n",
       "      <td>9.723070</td>\n",
       "      <td>793.278662</td>\n",
       "      <td>0.241019</td>\n",
       "      <td>17.843274</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestMSE_BAG_L2</td>\n",
       "      <td>-3.039566e+01</td>\n",
       "      <td>11.942874</td>\n",
       "      <td>889.517226</td>\n",
       "      <td>2.460824</td>\n",
       "      <td>114.081838</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBMXT_BAG_L4</td>\n",
       "      <td>-3.043598e+01</td>\n",
       "      <td>27.918222</td>\n",
       "      <td>1921.251431</td>\n",
       "      <td>0.254467</td>\n",
       "      <td>16.017519</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-3.043835e+01</td>\n",
       "      <td>0.455359</td>\n",
       "      <td>361.102080</td>\n",
       "      <td>0.455359</td>\n",
       "      <td>361.102080</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost_BAG_L3</td>\n",
       "      <td>-3.049489e+01</td>\n",
       "      <td>18.763042</td>\n",
       "      <td>1370.503951</td>\n",
       "      <td>0.250876</td>\n",
       "      <td>47.278865</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-3.054517e+01</td>\n",
       "      <td>2.579462</td>\n",
       "      <td>68.374632</td>\n",
       "      <td>2.579462</td>\n",
       "      <td>68.374632</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-3.054572e+01</td>\n",
       "      <td>0.274830</td>\n",
       "      <td>22.584905</td>\n",
       "      <td>0.274830</td>\n",
       "      <td>22.584905</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForestMSE_BAG_L3</td>\n",
       "      <td>-3.056293e+01</td>\n",
       "      <td>20.960976</td>\n",
       "      <td>1438.909524</td>\n",
       "      <td>2.448810</td>\n",
       "      <td>115.684439</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ExtraTreesMSE_BAG_L3</td>\n",
       "      <td>-3.058682e+01</td>\n",
       "      <td>21.155148</td>\n",
       "      <td>1399.903816</td>\n",
       "      <td>2.642982</td>\n",
       "      <td>76.678730</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LightGBM_BAG_L3</td>\n",
       "      <td>-3.060167e+01</td>\n",
       "      <td>18.757785</td>\n",
       "      <td>1342.397973</td>\n",
       "      <td>0.245620</td>\n",
       "      <td>19.172887</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-3.064872e+01</td>\n",
       "      <td>2.671731</td>\n",
       "      <td>100.007344</td>\n",
       "      <td>2.671731</td>\n",
       "      <td>100.007344</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LightGBM_BAG_L4</td>\n",
       "      <td>-3.066535e+01</td>\n",
       "      <td>27.910098</td>\n",
       "      <td>1923.922909</td>\n",
       "      <td>0.246343</td>\n",
       "      <td>18.688996</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>-3.070351e+01</td>\n",
       "      <td>9.827667</td>\n",
       "      <td>818.058735</td>\n",
       "      <td>0.345617</td>\n",
       "      <td>42.623347</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ExtraTreesMSE_BAG_L4</td>\n",
       "      <td>-3.073101e+01</td>\n",
       "      <td>30.192093</td>\n",
       "      <td>1980.885180</td>\n",
       "      <td>2.528337</td>\n",
       "      <td>75.651267</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>-3.073872e+01</td>\n",
       "      <td>9.846289</td>\n",
       "      <td>888.175305</td>\n",
       "      <td>0.364239</td>\n",
       "      <td>112.739917</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomForestMSE_BAG_L4</td>\n",
       "      <td>-3.075370e+01</td>\n",
       "      <td>30.140187</td>\n",
       "      <td>2023.020558</td>\n",
       "      <td>2.476431</td>\n",
       "      <td>117.786645</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LightGBMLarge_BAG_L3</td>\n",
       "      <td>-3.077749e+01</td>\n",
       "      <td>18.979216</td>\n",
       "      <td>1461.437074</td>\n",
       "      <td>0.467050</td>\n",
       "      <td>138.211988</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>-3.079826e+01</td>\n",
       "      <td>0.352296</td>\n",
       "      <td>75.179911</td>\n",
       "      <td>0.352296</td>\n",
       "      <td>75.179911</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGBoost_BAG_L4</td>\n",
       "      <td>-3.082512e+01</td>\n",
       "      <td>27.916123</td>\n",
       "      <td>1952.599375</td>\n",
       "      <td>0.252367</td>\n",
       "      <td>47.365462</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>-3.083922e+01</td>\n",
       "      <td>0.294480</td>\n",
       "      <td>52.794030</td>\n",
       "      <td>0.294480</td>\n",
       "      <td>52.794030</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LightGBMLarge_BAG_L4</td>\n",
       "      <td>-3.089065e+01</td>\n",
       "      <td>28.126945</td>\n",
       "      <td>2059.990874</td>\n",
       "      <td>0.463190</td>\n",
       "      <td>154.756961</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NeuralNetTorch_BAG_L2</td>\n",
       "      <td>-3.204501e+01</td>\n",
       "      <td>11.262974</td>\n",
       "      <td>809.258230</td>\n",
       "      <td>1.780924</td>\n",
       "      <td>33.822842</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NeuralNetTorch_BAG_L3</td>\n",
       "      <td>-3.225098e+01</td>\n",
       "      <td>20.238850</td>\n",
       "      <td>1358.331508</td>\n",
       "      <td>1.726684</td>\n",
       "      <td>35.106422</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NeuralNetTorch_BAG_L4</td>\n",
       "      <td>-3.259230e+01</td>\n",
       "      <td>29.355591</td>\n",
       "      <td>1939.171066</td>\n",
       "      <td>1.691836</td>\n",
       "      <td>33.937153</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>-3.297672e+01</td>\n",
       "      <td>1.773932</td>\n",
       "      <td>35.438074</td>\n",
       "      <td>1.773932</td>\n",
       "      <td>35.438074</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>-1.153773e+07</td>\n",
       "      <td>10.068050</td>\n",
       "      <td>812.604318</td>\n",
       "      <td>0.586000</td>\n",
       "      <td>37.168930</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>-2.529512e+07</td>\n",
       "      <td>0.757773</td>\n",
       "      <td>38.680730</td>\n",
       "      <td>0.757773</td>\n",
       "      <td>38.680730</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NeuralNetFastAI_BAG_L3</td>\n",
       "      <td>-2.076734e+09</td>\n",
       "      <td>19.211361</td>\n",
       "      <td>1358.903099</td>\n",
       "      <td>0.699195</td>\n",
       "      <td>35.678013</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NeuralNetFastAI_BAG_L4</td>\n",
       "      <td>-4.305313e+09</td>\n",
       "      <td>28.438627</td>\n",
       "      <td>1939.278008</td>\n",
       "      <td>0.774871</td>\n",
       "      <td>34.044095</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model     score_val  pred_time_val     fit_time  \\\n",
       "0      WeightedEnsemble_L3 -2.992956e+01      16.976287  1113.251006   \n",
       "1      WeightedEnsemble_L2 -2.994883e+01       8.725274   737.121148   \n",
       "2          CatBoost_BAG_L2 -3.000877e+01       9.899927   871.808294   \n",
       "3      WeightedEnsemble_L4 -3.006113e+01      23.608909  1635.915210   \n",
       "4          CatBoost_BAG_L3 -3.013729e+01      18.897458  1419.917083   \n",
       "5        LightGBMXT_BAG_L2 -3.021232e+01       9.782707   791.799095   \n",
       "6      WeightedEnsemble_L5 -3.025312e+01      35.769815  2452.548143   \n",
       "7          CatBoost_BAG_L4 -3.028377e+01      28.103187  2006.710318   \n",
       "8        LightGBMXT_BAG_L1 -3.028589e+01       0.322187    21.273682   \n",
       "9        LightGBMXT_BAG_L3 -3.030219e+01      18.797245  1340.730571   \n",
       "10    ExtraTreesMSE_BAG_L2 -3.032424e+01      12.015009   852.208323   \n",
       "11         LightGBM_BAG_L2 -3.038022e+01       9.723070   793.278662   \n",
       "12  RandomForestMSE_BAG_L2 -3.039566e+01      11.942874   889.517226   \n",
       "13       LightGBMXT_BAG_L4 -3.043598e+01      27.918222  1921.251431   \n",
       "14         CatBoost_BAG_L1 -3.043835e+01       0.455359   361.102080   \n",
       "15          XGBoost_BAG_L3 -3.049489e+01      18.763042  1370.503951   \n",
       "16    ExtraTreesMSE_BAG_L1 -3.054517e+01       2.579462    68.374632   \n",
       "17         LightGBM_BAG_L1 -3.054572e+01       0.274830    22.584905   \n",
       "18  RandomForestMSE_BAG_L3 -3.056293e+01      20.960976  1438.909524   \n",
       "19    ExtraTreesMSE_BAG_L3 -3.058682e+01      21.155148  1399.903816   \n",
       "20         LightGBM_BAG_L3 -3.060167e+01      18.757785  1342.397973   \n",
       "21  RandomForestMSE_BAG_L1 -3.064872e+01       2.671731   100.007344   \n",
       "22         LightGBM_BAG_L4 -3.066535e+01      27.910098  1923.922909   \n",
       "23          XGBoost_BAG_L2 -3.070351e+01       9.827667   818.058735   \n",
       "24    ExtraTreesMSE_BAG_L4 -3.073101e+01      30.192093  1980.885180   \n",
       "25    LightGBMLarge_BAG_L2 -3.073872e+01       9.846289   888.175305   \n",
       "26  RandomForestMSE_BAG_L4 -3.075370e+01      30.140187  2023.020558   \n",
       "27    LightGBMLarge_BAG_L3 -3.077749e+01      18.979216  1461.437074   \n",
       "28    LightGBMLarge_BAG_L1 -3.079826e+01       0.352296    75.179911   \n",
       "29          XGBoost_BAG_L4 -3.082512e+01      27.916123  1952.599375   \n",
       "30          XGBoost_BAG_L1 -3.083922e+01       0.294480    52.794030   \n",
       "31    LightGBMLarge_BAG_L4 -3.089065e+01      28.126945  2059.990874   \n",
       "32   NeuralNetTorch_BAG_L2 -3.204501e+01      11.262974   809.258230   \n",
       "33   NeuralNetTorch_BAG_L3 -3.225098e+01      20.238850  1358.331508   \n",
       "34   NeuralNetTorch_BAG_L4 -3.259230e+01      29.355591  1939.171066   \n",
       "35   NeuralNetTorch_BAG_L1 -3.297672e+01       1.773932    35.438074   \n",
       "36  NeuralNetFastAI_BAG_L2 -1.153773e+07      10.068050   812.604318   \n",
       "37  NeuralNetFastAI_BAG_L1 -2.529512e+07       0.757773    38.680730   \n",
       "38  NeuralNetFastAI_BAG_L3 -2.076734e+09      19.211361  1358.903099   \n",
       "39  NeuralNetFastAI_BAG_L4 -4.305313e+09      28.438627  1939.278008   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.000996           0.401389            3       True   \n",
       "1                 0.000997           0.366491            2       True   \n",
       "2                 0.417876          96.372906            2       True   \n",
       "3                 0.000000           0.422915            4       True   \n",
       "4                 0.385293          96.691997            3       True   \n",
       "5                 0.300657          16.363707            2       True   \n",
       "6                 0.000000           0.322819            5       True   \n",
       "7                 0.439432         101.476405            4       True   \n",
       "8                 0.322187          21.273682            1       True   \n",
       "9                 0.285079          17.505485            3       True   \n",
       "10                2.532959          76.772935            2       True   \n",
       "11                0.241019          17.843274            2       True   \n",
       "12                2.460824         114.081838            2       True   \n",
       "13                0.254467          16.017519            4       True   \n",
       "14                0.455359         361.102080            1       True   \n",
       "15                0.250876          47.278865            3       True   \n",
       "16                2.579462          68.374632            1       True   \n",
       "17                0.274830          22.584905            1       True   \n",
       "18                2.448810         115.684439            3       True   \n",
       "19                2.642982          76.678730            3       True   \n",
       "20                0.245620          19.172887            3       True   \n",
       "21                2.671731         100.007344            1       True   \n",
       "22                0.246343          18.688996            4       True   \n",
       "23                0.345617          42.623347            2       True   \n",
       "24                2.528337          75.651267            4       True   \n",
       "25                0.364239         112.739917            2       True   \n",
       "26                2.476431         117.786645            4       True   \n",
       "27                0.467050         138.211988            3       True   \n",
       "28                0.352296          75.179911            1       True   \n",
       "29                0.252367          47.365462            4       True   \n",
       "30                0.294480          52.794030            1       True   \n",
       "31                0.463190         154.756961            4       True   \n",
       "32                1.780924          33.822842            2       True   \n",
       "33                1.726684          35.106422            3       True   \n",
       "34                1.691836          33.937153            4       True   \n",
       "35                1.773932          35.438074            1       True   \n",
       "36                0.586000          37.168930            2       True   \n",
       "37                0.757773          38.680730            1       True   \n",
       "38                0.699195          35.678013            3       True   \n",
       "39                0.774871          34.044095            4       True   \n",
       "\n",
       "    fit_order  \n",
       "0          20  \n",
       "1          10  \n",
       "2          14  \n",
       "3          30  \n",
       "4          24  \n",
       "5          11  \n",
       "6          40  \n",
       "7          34  \n",
       "8           1  \n",
       "9          21  \n",
       "10         15  \n",
       "11         12  \n",
       "12         13  \n",
       "13         31  \n",
       "14          4  \n",
       "15         27  \n",
       "16          5  \n",
       "17          2  \n",
       "18         23  \n",
       "19         25  \n",
       "20         22  \n",
       "21          3  \n",
       "22         32  \n",
       "23         17  \n",
       "24         35  \n",
       "25         19  \n",
       "26         33  \n",
       "27         29  \n",
       "28          9  \n",
       "29         37  \n",
       "30          7  \n",
       "31         39  \n",
       "32         18  \n",
       "33         28  \n",
       "34         38  \n",
       "35          8  \n",
       "36         16  \n",
       "37          6  \n",
       "38         26  \n",
       "39         36  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(silent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "455dfb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_use = predictor.get_model_best()\n",
    "model_pred= predictor.predict(test_data, model=model_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ea92ffee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      23.822208\n",
       "1      73.787849\n",
       "2      42.253929\n",
       "3      48.650108\n",
       "4      58.813797\n",
       "         ...    \n",
       "478    14.309298\n",
       "479    72.339966\n",
       "480    35.346153\n",
       "481    57.559196\n",
       "482    19.285055\n",
       "Name: MLM, Length: 483, dtype: float32"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc506291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "8d045f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2=train.copy()\n",
    "train_2 = train_2.drop('MLM', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "ddb585c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2 = TabularDataset(train_2)\n",
    "test_data = TabularDataset(test)\n",
    "\n",
    "label = 'HLM'\n",
    "eval_metric = 'root_mean_squared_error'\n",
    "time_limit = 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "ad78a4d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230910_124311\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230910_124311\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   108.89 GB / 237.11 GB (45.9%)\n",
      "Train Data Rows:    3498\n",
      "Train Data Columns: 1242\n",
      "Label Column: HLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (135.336, 0.0, 53.09021, 36.08008)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3620.86 MB\n",
      "\tTrain Data (Original)  Memory Usage: 20.43 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1036 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 18): ['NumRadicalElectrons', 'SMR_VSA8', 'SlogP_VSA9', 'fr_SH', 'fr_azide', 'fr_azo', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitroso', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_term_acetylene', 'fr_thiocyan']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 5): ['MaxEStateIndex', 'fr_COO2', 'fr_Nhpyrrole', 'fr_benzene', 'fr_quatN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['MaxEStateIndex']\n",
      "\t\t('int', [])   : 4 | ['fr_COO2', 'fr_Nhpyrrole', 'fr_benzene', 'fr_quatN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  108 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea', 'MaxAbsEStateIndex', ...]\n",
      "\t\t('int', [])   : 1111 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds', 'NumValenceElectrons', 'HeavyAtomCount', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  108 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea', 'MaxAbsEStateIndex', ...]\n",
      "\t\t('int', [])       :   76 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds', 'NumValenceElectrons', 'HeavyAtomCount', ...]\n",
      "\t\t('int', ['bool']) : 1035 | ['fr_C_S', 'fr_aldehyde', 'fr_barbitur', 'fr_epoxide', 'fr_hdrzine', ...]\n",
      "\t8.0s = Fit runtime\n",
      "\t1219 features in original data used to generate 1219 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.77 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 8.4s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 4 stack levels (L1 to L4) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1196.9s of the 3591.58s of remaining time.\n",
      "\tWarning: Exception caused KNeighborsUnif_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute 'split'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 250, in _fit\n",
      "    self._fit_single(X=X, y=y, model_base=model_base, use_child_oof=use_child_oof, skip_oof=_skip_oof, **kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 416, in _fit_single\n",
      "    self._oof_pred_proba = model_base.get_oof_pred_proba(X=X, y=y)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\tabular\\models\\knn\\knn_model.py\", line 115, in get_oof_pred_proba\n",
      "    y_oof_pred_proba = self._get_oof_pred_proba(X=X, **kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\tabular\\models\\knn\\knn_model.py\", line 129, in _get_oof_pred_proba\n",
      "    y_oof_pred_proba = KNeighborsRegressorLOOMixin.predict_loo(self.model)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\tabular\\models\\knn\\_knn_loo_variants.py\", line 115, in predict_loo\n",
      "    neigh_dist, neigh_ind = self.kneighbors()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 289, in compute\n",
      "    return ArgKmin32.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 139, in threadpool_limits\n",
      "    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 171, in __init__\n",
      "    self._original_info = self._set_threadpool_limits()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 268, in _set_threadpool_limits\n",
      "    modules = _ThreadpoolInfo(prefixes=self._prefixes,\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 340, in __init__\n",
      "    self._load_modules()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 373, in _load_modules\n",
      "    self._find_modules_with_enum_process_module_ex()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 485, in _find_modules_with_enum_process_module_ex\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1196.54s of the 3591.23s of remaining time.\n",
      "\tWarning: Exception caused KNeighborsDist_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute 'split'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 250, in _fit\n",
      "    self._fit_single(X=X, y=y, model_base=model_base, use_child_oof=use_child_oof, skip_oof=_skip_oof, **kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 416, in _fit_single\n",
      "    self._oof_pred_proba = model_base.get_oof_pred_proba(X=X, y=y)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\tabular\\models\\knn\\knn_model.py\", line 115, in get_oof_pred_proba\n",
      "    y_oof_pred_proba = self._get_oof_pred_proba(X=X, **kwargs)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\tabular\\models\\knn\\knn_model.py\", line 129, in _get_oof_pred_proba\n",
      "    y_oof_pred_proba = KNeighborsRegressorLOOMixin.predict_loo(self.model)\n",
      "  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\autogluon\\tabular\\models\\knn\\_knn_loo_variants.py\", line 115, in predict_loo\n",
      "    neigh_dist, neigh_ind = self.kneighbors()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 289, in compute\n",
      "    return ArgKmin32.compute(\n",
      "  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 139, in threadpool_limits\n",
      "    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 171, in __init__\n",
      "    self._original_info = self._set_threadpool_limits()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 268, in _set_threadpool_limits\n",
      "    modules = _ThreadpoolInfo(prefixes=self._prefixes,\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 340, in __init__\n",
      "    self._load_modules()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 373, in _load_modules\n",
      "    self._find_modules_with_enum_process_module_ex()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 485, in _find_modules_with_enum_process_module_ex\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1196.19s of the 3590.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.2292\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.59s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1168.65s of the 3563.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.563\t = Validation score   (-root_mean_squared_error)\n",
      "\t20.29s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1137.78s of the 3532.46s of remaining time.\n",
      "\t-31.6098\t = Validation score   (-root_mean_squared_error)\n",
      "\t89.05s\t = Training   runtime\n",
      "\t2.49s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1045.83s of the 3440.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.3352\t = Validation score   (-root_mean_squared_error)\n",
      "\t189.45s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 845.62s of the 3240.3s of remaining time.\n",
      "\t-31.099\t = Validation score   (-root_mean_squared_error)\n",
      "\t61.23s\t = Training   runtime\n",
      "\t2.49s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 781.41s of the 3176.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-8949287.8309\t = Validation score   (-root_mean_squared_error)\n",
      "\t34.35s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 736.01s of the 3130.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.5802\t = Validation score   (-root_mean_squared_error)\n",
      "\t46.9s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 677.57s of the 3072.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-32.9346\t = Validation score   (-root_mean_squared_error)\n",
      "\t44.16s\t = Training   runtime\n",
      "\t1.72s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 622.47s of the 3017.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.7014\t = Validation score   (-root_mean_squared_error)\n",
      "\t67.75s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 2938.67s of remaining time.\n",
      "\t-30.7938\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1305.55s of the 2938.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.2569\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.96s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 1276.47s of the 2909.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.5165\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.51s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 1245.89s of the 2878.49s of remaining time.\n",
      "\t-31.413\t = Validation score   (-root_mean_squared_error)\n",
      "\t96.69s\t = Training   runtime\n",
      "\t2.52s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 1146.13s of the 2778.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.0238\t = Validation score   (-root_mean_squared_error)\n",
      "\t96.85s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 1038.36s of the 2670.96s of remaining time.\n",
      "\t-31.2371\t = Validation score   (-root_mean_squared_error)\n",
      "\t68.04s\t = Training   runtime\n",
      "\t2.5s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 967.24s of the 2599.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-615920501.822\t = Validation score   (-root_mean_squared_error)\n",
      "\t34.64s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 921.32s of the 2553.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.7036\t = Validation score   (-root_mean_squared_error)\n",
      "\t46.67s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 863.3s of the 2495.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-32.177\t = Validation score   (-root_mean_squared_error)\n",
      "\t31.46s\t = Training   runtime\n",
      "\t1.81s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 820.87s of the 2453.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.6776\t = Validation score   (-root_mean_squared_error)\n",
      "\t67.87s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 2374.05s of remaining time.\n",
      "\t-30.8944\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L3 models ...\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 1581.96s of the 2373.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.4386\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.59s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 1554.37s of the 2345.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.4652\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.42s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L3 ... Training model for up to 1525.06s of the 2316.55s of remaining time.\n",
      "\t-31.4077\t = Validation score   (-root_mean_squared_error)\n",
      "\t99.41s\t = Training   runtime\n",
      "\t2.53s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 1422.65s of the 2214.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.0544\t = Validation score   (-root_mean_squared_error)\n",
      "\t100.49s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L3 ... Training model for up to 1311.32s of the 2102.81s of remaining time.\n",
      "\t-31.3585\t = Validation score   (-root_mean_squared_error)\n",
      "\t74.56s\t = Training   runtime\n",
      "\t2.63s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 1233.51s of the 2024.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-311613374.5969\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.52s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 1184.35s of the 1975.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.6198\t = Validation score   (-root_mean_squared_error)\n",
      "\t44.74s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 1128.36s of the 1919.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-32.28\t = Validation score   (-root_mean_squared_error)\n",
      "\t32.11s\t = Training   runtime\n",
      "\t1.9s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 1085.14s of the 1876.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.7617\t = Validation score   (-root_mean_squared_error)\n",
      "\t275.59s\t = Training   runtime\n",
      "\t1.15s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.0s of the 1585.77s of remaining time.\n",
      "\t-30.9949\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L4 models ...\n",
      "Fitting model: LightGBMXT_BAG_L4 ... Training model for up to 1585.32s of the 1585.2s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.5338\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.76s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L4 ... Training model for up to 1557.65s of the 1557.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.5089\t = Validation score   (-root_mean_squared_error)\n",
      "\t147.63s\t = Training   runtime\n",
      "\t1.6s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L4 ... Training model for up to 1395.51s of the 1395.44s of remaining time.\n",
      "\t-31.5368\t = Validation score   (-root_mean_squared_error)\n",
      "\t95.39s\t = Training   runtime\n",
      "\t2.41s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L4 ... Training model for up to 1297.2s of the 1297.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.2187\t = Validation score   (-root_mean_squared_error)\n",
      "\t102.27s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L4 ... Training model for up to 1184.27s of the 1184.17s of remaining time.\n",
      "\t-31.5886\t = Validation score   (-root_mean_squared_error)\n",
      "\t69.46s\t = Training   runtime\n",
      "\t2.42s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L4 ... Training model for up to 1111.83s of the 1111.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-7278375876.7635\t = Validation score   (-root_mean_squared_error)\n",
      "\t33.13s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L4 ... Training model for up to 1067.61s of the 1067.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.7179\t = Validation score   (-root_mean_squared_error)\n",
      "\t45.45s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L4 ... Training model for up to 1010.75s of the 1010.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-32.3467\t = Validation score   (-root_mean_squared_error)\n",
      "\t31.77s\t = Training   runtime\n",
      "\t1.76s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L4 ... Training model for up to 967.7s of the 967.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.7835\t = Validation score   (-root_mean_squared_error)\n",
      "\t524.57s\t = Training   runtime\n",
      "\t3.51s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L5 ... Training model for up to 360.0s of the 419.03s of remaining time.\n",
      "\t-31.1316\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3181.34s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230910_124311\\\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(\n",
    "    label=label, eval_metric=eval_metric\n",
    ").fit(train_data2,  presets='best_quality', time_limit=time_limit, \n",
    "      num_stack_levels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "720f29a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-3.079380e+01</td>\n",
       "      <td>5.486246</td>\n",
       "      <td>427.477603</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.407850</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-3.089444e+01</td>\n",
       "      <td>13.795841</td>\n",
       "      <td>835.486931</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.502891</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L4</td>\n",
       "      <td>-3.099495e+01</td>\n",
       "      <td>25.518313</td>\n",
       "      <td>1402.194689</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.416661</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-3.102377e+01</td>\n",
       "      <td>9.210119</td>\n",
       "      <td>667.613365</td>\n",
       "      <td>0.408563</td>\n",
       "      <td>96.848867</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost_BAG_L3</td>\n",
       "      <td>-3.105440e+01</td>\n",
       "      <td>18.207913</td>\n",
       "      <td>1150.951809</td>\n",
       "      <td>0.477597</td>\n",
       "      <td>100.494096</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-3.109904e+01</td>\n",
       "      <td>2.487624</td>\n",
       "      <td>61.229360</td>\n",
       "      <td>2.487624</td>\n",
       "      <td>61.229360</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WeightedEnsemble_L5</td>\n",
       "      <td>-3.113157e+01</td>\n",
       "      <td>36.765188</td>\n",
       "      <td>2242.171789</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.303904</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost_BAG_L4</td>\n",
       "      <td>-3.121871e+01</td>\n",
       "      <td>28.288748</td>\n",
       "      <td>1852.170768</td>\n",
       "      <td>0.425475</td>\n",
       "      <td>102.269989</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-3.122923e+01</td>\n",
       "      <td>0.249075</td>\n",
       "      <td>17.588624</td>\n",
       "      <td>0.249075</td>\n",
       "      <td>17.588624</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2</td>\n",
       "      <td>-3.123715e+01</td>\n",
       "      <td>11.302874</td>\n",
       "      <td>638.805577</td>\n",
       "      <td>2.501318</td>\n",
       "      <td>68.041079</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>-3.125688e+01</td>\n",
       "      <td>9.060790</td>\n",
       "      <td>588.721992</td>\n",
       "      <td>0.259234</td>\n",
       "      <td>17.957494</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-3.133521e+01</td>\n",
       "      <td>0.371663</td>\n",
       "      <td>189.448281</td>\n",
       "      <td>0.371663</td>\n",
       "      <td>189.448281</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ExtraTreesMSE_BAG_L3</td>\n",
       "      <td>-3.135853e+01</td>\n",
       "      <td>20.359758</td>\n",
       "      <td>1125.021793</td>\n",
       "      <td>2.629443</td>\n",
       "      <td>74.564080</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestMSE_BAG_L3</td>\n",
       "      <td>-3.140775e+01</td>\n",
       "      <td>20.256931</td>\n",
       "      <td>1149.872455</td>\n",
       "      <td>2.526615</td>\n",
       "      <td>99.414742</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestMSE_BAG_L2</td>\n",
       "      <td>-3.141298e+01</td>\n",
       "      <td>11.318452</td>\n",
       "      <td>667.456179</td>\n",
       "      <td>2.516896</td>\n",
       "      <td>96.691681</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LightGBMXT_BAG_L3</td>\n",
       "      <td>-3.143865e+01</td>\n",
       "      <td>18.037221</td>\n",
       "      <td>1067.046912</td>\n",
       "      <td>0.306906</td>\n",
       "      <td>16.589199</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LightGBM_BAG_L3</td>\n",
       "      <td>-3.146524e+01</td>\n",
       "      <td>17.988756</td>\n",
       "      <td>1068.876045</td>\n",
       "      <td>0.258441</td>\n",
       "      <td>18.418332</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LightGBM_BAG_L4</td>\n",
       "      <td>-3.150891e+01</td>\n",
       "      <td>29.464865</td>\n",
       "      <td>1897.530249</td>\n",
       "      <td>1.601592</td>\n",
       "      <td>147.629471</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-3.151652e+01</td>\n",
       "      <td>9.031328</td>\n",
       "      <td>590.279490</td>\n",
       "      <td>0.229772</td>\n",
       "      <td>19.514992</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LightGBMXT_BAG_L4</td>\n",
       "      <td>-3.153377e+01</td>\n",
       "      <td>28.101719</td>\n",
       "      <td>1767.659230</td>\n",
       "      <td>0.238446</td>\n",
       "      <td>17.758451</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomForestMSE_BAG_L4</td>\n",
       "      <td>-3.153681e+01</td>\n",
       "      <td>30.277808</td>\n",
       "      <td>1845.287449</td>\n",
       "      <td>2.414535</td>\n",
       "      <td>95.386670</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-3.156297e+01</td>\n",
       "      <td>0.245072</td>\n",
       "      <td>20.293583</td>\n",
       "      <td>0.245072</td>\n",
       "      <td>20.293583</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>-3.158017e+01</td>\n",
       "      <td>0.304202</td>\n",
       "      <td>46.896917</td>\n",
       "      <td>0.304202</td>\n",
       "      <td>46.896917</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ExtraTreesMSE_BAG_L4</td>\n",
       "      <td>-3.158862e+01</td>\n",
       "      <td>30.284438</td>\n",
       "      <td>1819.363629</td>\n",
       "      <td>2.421165</td>\n",
       "      <td>69.462850</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-3.160977e+01</td>\n",
       "      <td>2.494472</td>\n",
       "      <td>89.053928</td>\n",
       "      <td>2.494472</td>\n",
       "      <td>89.053928</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>XGBoost_BAG_L3</td>\n",
       "      <td>-3.161977e+01</td>\n",
       "      <td>17.978981</td>\n",
       "      <td>1095.196561</td>\n",
       "      <td>0.248666</td>\n",
       "      <td>44.738848</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>-3.167761e+01</td>\n",
       "      <td>9.076630</td>\n",
       "      <td>638.629500</td>\n",
       "      <td>0.275074</td>\n",
       "      <td>67.865002</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>-3.170139e+01</td>\n",
       "      <td>0.352469</td>\n",
       "      <td>67.748231</td>\n",
       "      <td>0.352469</td>\n",
       "      <td>67.748231</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>-3.170363e+01</td>\n",
       "      <td>9.077095</td>\n",
       "      <td>617.435067</td>\n",
       "      <td>0.275539</td>\n",
       "      <td>46.670569</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGBoost_BAG_L4</td>\n",
       "      <td>-3.171789e+01</td>\n",
       "      <td>28.139564</td>\n",
       "      <td>1795.347018</td>\n",
       "      <td>0.276290</td>\n",
       "      <td>45.446239</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LightGBMLarge_BAG_L3</td>\n",
       "      <td>-3.176166e+01</td>\n",
       "      <td>18.878248</td>\n",
       "      <td>1326.048787</td>\n",
       "      <td>1.147933</td>\n",
       "      <td>275.591074</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LightGBMLarge_BAG_L4</td>\n",
       "      <td>-3.178349e+01</td>\n",
       "      <td>31.373994</td>\n",
       "      <td>2274.470684</td>\n",
       "      <td>3.510720</td>\n",
       "      <td>524.569905</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NeuralNetTorch_BAG_L2</td>\n",
       "      <td>-3.217697e+01</td>\n",
       "      <td>10.609889</td>\n",
       "      <td>602.229092</td>\n",
       "      <td>1.808333</td>\n",
       "      <td>31.464594</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NeuralNetTorch_BAG_L3</td>\n",
       "      <td>-3.227999e+01</td>\n",
       "      <td>19.634990</td>\n",
       "      <td>1082.566262</td>\n",
       "      <td>1.904674</td>\n",
       "      <td>32.108549</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NeuralNetTorch_BAG_L4</td>\n",
       "      <td>-3.234670e+01</td>\n",
       "      <td>29.625059</td>\n",
       "      <td>1781.672667</td>\n",
       "      <td>1.761786</td>\n",
       "      <td>31.771888</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>-3.293457e+01</td>\n",
       "      <td>1.719219</td>\n",
       "      <td>44.158342</td>\n",
       "      <td>1.719219</td>\n",
       "      <td>44.158342</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>-8.949288e+06</td>\n",
       "      <td>0.577759</td>\n",
       "      <td>34.347233</td>\n",
       "      <td>0.577759</td>\n",
       "      <td>34.347233</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NeuralNetFastAI_BAG_L3</td>\n",
       "      <td>-3.116134e+08</td>\n",
       "      <td>18.362998</td>\n",
       "      <td>1087.981858</td>\n",
       "      <td>0.632683</td>\n",
       "      <td>37.524145</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>-6.159205e+08</td>\n",
       "      <td>9.455586</td>\n",
       "      <td>605.403435</td>\n",
       "      <td>0.654030</td>\n",
       "      <td>34.638937</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NeuralNetFastAI_BAG_L4</td>\n",
       "      <td>-7.278376e+09</td>\n",
       "      <td>28.480312</td>\n",
       "      <td>1783.027707</td>\n",
       "      <td>0.617039</td>\n",
       "      <td>33.126928</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model     score_val  pred_time_val     fit_time  \\\n",
       "0      WeightedEnsemble_L2 -3.079380e+01       5.486246   427.477603   \n",
       "1      WeightedEnsemble_L3 -3.089444e+01      13.795841   835.486931   \n",
       "2      WeightedEnsemble_L4 -3.099495e+01      25.518313  1402.194689   \n",
       "3          CatBoost_BAG_L2 -3.102377e+01       9.210119   667.613365   \n",
       "4          CatBoost_BAG_L3 -3.105440e+01      18.207913  1150.951809   \n",
       "5     ExtraTreesMSE_BAG_L1 -3.109904e+01       2.487624    61.229360   \n",
       "6      WeightedEnsemble_L5 -3.113157e+01      36.765188  2242.171789   \n",
       "7          CatBoost_BAG_L4 -3.121871e+01      28.288748  1852.170768   \n",
       "8        LightGBMXT_BAG_L1 -3.122923e+01       0.249075    17.588624   \n",
       "9     ExtraTreesMSE_BAG_L2 -3.123715e+01      11.302874   638.805577   \n",
       "10       LightGBMXT_BAG_L2 -3.125688e+01       9.060790   588.721992   \n",
       "11         CatBoost_BAG_L1 -3.133521e+01       0.371663   189.448281   \n",
       "12    ExtraTreesMSE_BAG_L3 -3.135853e+01      20.359758  1125.021793   \n",
       "13  RandomForestMSE_BAG_L3 -3.140775e+01      20.256931  1149.872455   \n",
       "14  RandomForestMSE_BAG_L2 -3.141298e+01      11.318452   667.456179   \n",
       "15       LightGBMXT_BAG_L3 -3.143865e+01      18.037221  1067.046912   \n",
       "16         LightGBM_BAG_L3 -3.146524e+01      17.988756  1068.876045   \n",
       "17         LightGBM_BAG_L4 -3.150891e+01      29.464865  1897.530249   \n",
       "18         LightGBM_BAG_L2 -3.151652e+01       9.031328   590.279490   \n",
       "19       LightGBMXT_BAG_L4 -3.153377e+01      28.101719  1767.659230   \n",
       "20  RandomForestMSE_BAG_L4 -3.153681e+01      30.277808  1845.287449   \n",
       "21         LightGBM_BAG_L1 -3.156297e+01       0.245072    20.293583   \n",
       "22          XGBoost_BAG_L1 -3.158017e+01       0.304202    46.896917   \n",
       "23    ExtraTreesMSE_BAG_L4 -3.158862e+01      30.284438  1819.363629   \n",
       "24  RandomForestMSE_BAG_L1 -3.160977e+01       2.494472    89.053928   \n",
       "25          XGBoost_BAG_L3 -3.161977e+01      17.978981  1095.196561   \n",
       "26    LightGBMLarge_BAG_L2 -3.167761e+01       9.076630   638.629500   \n",
       "27    LightGBMLarge_BAG_L1 -3.170139e+01       0.352469    67.748231   \n",
       "28          XGBoost_BAG_L2 -3.170363e+01       9.077095   617.435067   \n",
       "29          XGBoost_BAG_L4 -3.171789e+01      28.139564  1795.347018   \n",
       "30    LightGBMLarge_BAG_L3 -3.176166e+01      18.878248  1326.048787   \n",
       "31    LightGBMLarge_BAG_L4 -3.178349e+01      31.373994  2274.470684   \n",
       "32   NeuralNetTorch_BAG_L2 -3.217697e+01      10.609889   602.229092   \n",
       "33   NeuralNetTorch_BAG_L3 -3.227999e+01      19.634990  1082.566262   \n",
       "34   NeuralNetTorch_BAG_L4 -3.234670e+01      29.625059  1781.672667   \n",
       "35   NeuralNetTorch_BAG_L1 -3.293457e+01       1.719219    44.158342   \n",
       "36  NeuralNetFastAI_BAG_L1 -8.949288e+06       0.577759    34.347233   \n",
       "37  NeuralNetFastAI_BAG_L3 -3.116134e+08      18.362998  1087.981858   \n",
       "38  NeuralNetFastAI_BAG_L2 -6.159205e+08       9.455586   605.403435   \n",
       "39  NeuralNetFastAI_BAG_L4 -7.278376e+09      28.480312  1783.027707   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.001993           0.407850            2       True   \n",
       "1                 0.000997           0.502891            3       True   \n",
       "2                 0.001003           0.416661            4       True   \n",
       "3                 0.408563          96.848867            2       True   \n",
       "4                 0.477597         100.494096            3       True   \n",
       "5                 2.487624          61.229360            1       True   \n",
       "6                 0.001073           0.303904            5       True   \n",
       "7                 0.425475         102.269989            4       True   \n",
       "8                 0.249075          17.588624            1       True   \n",
       "9                 2.501318          68.041079            2       True   \n",
       "10                0.259234          17.957494            2       True   \n",
       "11                0.371663         189.448281            1       True   \n",
       "12                2.629443          74.564080            3       True   \n",
       "13                2.526615          99.414742            3       True   \n",
       "14                2.516896          96.691681            2       True   \n",
       "15                0.306906          16.589199            3       True   \n",
       "16                0.258441          18.418332            3       True   \n",
       "17                1.601592         147.629471            4       True   \n",
       "18                0.229772          19.514992            2       True   \n",
       "19                0.238446          17.758451            4       True   \n",
       "20                2.414535          95.386670            4       True   \n",
       "21                0.245072          20.293583            1       True   \n",
       "22                0.304202          46.896917            1       True   \n",
       "23                2.421165          69.462850            4       True   \n",
       "24                2.494472          89.053928            1       True   \n",
       "25                0.248666          44.738848            3       True   \n",
       "26                0.275074          67.865002            2       True   \n",
       "27                0.352469          67.748231            1       True   \n",
       "28                0.275539          46.670569            2       True   \n",
       "29                0.276290          45.446239            4       True   \n",
       "30                1.147933         275.591074            3       True   \n",
       "31                3.510720         524.569905            4       True   \n",
       "32                1.808333          31.464594            2       True   \n",
       "33                1.904674          32.108549            3       True   \n",
       "34                1.761786          31.771888            4       True   \n",
       "35                1.719219          44.158342            1       True   \n",
       "36                0.577759          34.347233            1       True   \n",
       "37                0.632683          37.524145            3       True   \n",
       "38                0.654030          34.638937            2       True   \n",
       "39                0.617039          33.126928            4       True   \n",
       "\n",
       "    fit_order  \n",
       "0          10  \n",
       "1          20  \n",
       "2          30  \n",
       "3          14  \n",
       "4          24  \n",
       "5           5  \n",
       "6          40  \n",
       "7          34  \n",
       "8           1  \n",
       "9          15  \n",
       "10         11  \n",
       "11          4  \n",
       "12         25  \n",
       "13         23  \n",
       "14         13  \n",
       "15         21  \n",
       "16         22  \n",
       "17         32  \n",
       "18         12  \n",
       "19         31  \n",
       "20         33  \n",
       "21          2  \n",
       "22          7  \n",
       "23         35  \n",
       "24          3  \n",
       "25         27  \n",
       "26         19  \n",
       "27          9  \n",
       "28         17  \n",
       "29         37  \n",
       "30         29  \n",
       "31         39  \n",
       "32         18  \n",
       "33         28  \n",
       "34         38  \n",
       "35          8  \n",
       "36          6  \n",
       "37         26  \n",
       "38         16  \n",
       "39         36  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(silent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "e0316f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_use2 = predictor.get_model_best()\n",
    "model_pred2= predictor.predict(test_data, model=model_to_use2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "21648620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      50.388046\n",
       "1      83.939453\n",
       "2      50.138241\n",
       "3      73.569153\n",
       "4      75.254433\n",
       "         ...    \n",
       "478    30.239071\n",
       "479    77.045631\n",
       "480    63.704082\n",
       "481    68.682076\n",
       "482    63.780975\n",
       "Name: HLM, Length: 483, dtype: float32"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "96d5b788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MLM</th>\n",
       "      <th>HLM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>23.822208</td>\n",
       "      <td>50.388046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>73.787849</td>\n",
       "      <td>83.939453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>42.253929</td>\n",
       "      <td>50.138241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>48.650108</td>\n",
       "      <td>73.569153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>58.813797</td>\n",
       "      <td>75.254433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>TEST_478</td>\n",
       "      <td>14.309298</td>\n",
       "      <td>30.239071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>TEST_479</td>\n",
       "      <td>72.339966</td>\n",
       "      <td>77.045631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>TEST_480</td>\n",
       "      <td>35.346153</td>\n",
       "      <td>63.704082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>TEST_481</td>\n",
       "      <td>57.559196</td>\n",
       "      <td>68.682076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>TEST_482</td>\n",
       "      <td>19.285055</td>\n",
       "      <td>63.780975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        MLM        HLM\n",
       "0    TEST_000  23.822208  50.388046\n",
       "1    TEST_001  73.787849  83.939453\n",
       "2    TEST_002  42.253929  50.138241\n",
       "3    TEST_003  48.650108  73.569153\n",
       "4    TEST_004  58.813797  75.254433\n",
       "..        ...        ...        ...\n",
       "478  TEST_478  14.309298  30.239071\n",
       "479  TEST_479  72.339966  77.045631\n",
       "480  TEST_480  35.346153  63.704082\n",
       "481  TEST_481  57.559196  68.682076\n",
       "482  TEST_482  19.285055  63.780975\n",
       "\n",
       "[483 rows x 3 columns]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=pd.read_csv(\"C:/Users/user/Desktop/데이콘 신약대회/open/sample_submission.csv\")\n",
    "\n",
    "sample['MLM']=model_pred\n",
    "sample['HLM']=model_pred2\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "156cbce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"C:/Users/user/Desktop/데이콘 신약대회/open/파생1hourstack3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6ee39b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"C:/Users/user/Desktop/데이콘 신약대회/open/4housstack3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da3e2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2b50d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"C:/Users/user/Desktop/데이콘 신약대회/open/20minstack3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "74e82b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"C:/Users/user/Desktop/데이콘 신약대회/open/20minstack5.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbaab87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb271a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd837d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95d555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d223ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'MLM'\n",
    "eval_metric = 'root_mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4e3e6793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115445\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115445\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   21.13 GB / 237.11 GB (8.9%)\n",
      "Train Data Rows:    3264\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    234\n",
      "Tuning Data Columns: 7\n",
      "Label Column: MLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (131.72, 0.0, 37.22306, 35.62323)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2724.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-37.5478\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-37.2688\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========1fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-33.1902\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-33.8397\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-34.1789\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.55s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-32.9673\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.78s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-34.2625\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 2: early stopping\n",
      "\t-32.8829\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.96s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-33.9704\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-36.3077\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.69s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-34.48\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-32.7486\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 17.69s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115445\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115503\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115503\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   20.97 GB / 237.11 GB (8.8%)\n",
      "Train Data Rows:    3264\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    234\n",
      "Tuning Data Columns: 7\n",
      "Label Column: MLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (131.72, 0.0, 37.44767, 35.74842)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2627.36 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.0s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-35.8786\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-35.8172\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========2fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-30.8522\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-30.9446\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-31.8744\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.64s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-30.7525\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.83s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-32.2266\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-29.9652\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.64s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-31.3205\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-32.3088\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.34s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-31.3025\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-29.9034\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 23.43s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115503\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115527\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115527\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   20.81 GB / 237.11 GB (8.8%)\n",
      "Train Data Rows:    3264\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    234\n",
      "Tuning Data Columns: 7\n",
      "Label Column: MLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (131.72, 0.0, 37.48246, 35.65159)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2620.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-37.681\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========3fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-37.6016\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-33.1525\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-33.3983\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-34.4115\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.83s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-33.0377\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.5s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-33.9604\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-32.8651\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.48s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-33.2139\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-35.8985\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.22s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-33.259\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-32.6795\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 16.82s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115527\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115544\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115544\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   20.65 GB / 237.11 GB (8.7%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: MLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (131.72, 0.0, 37.26998, 35.63611)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2590.52 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-36.1099\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-36.0146\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========4fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 31.3118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-31.2767\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-31.9044\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-32.347\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.82s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-31.5753\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.49s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-32.5915\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-31.442\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.52s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-32.3181\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-33.519\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.51s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-32.2102\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.99s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-31.1043\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 20.19s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115544\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115604\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115604\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   20.48 GB / 237.11 GB (8.6%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: MLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (131.72, 0.0, 37.40849, 35.69284)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2601.84 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.0s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-38.0735\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-38.9387\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========5fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-32.303\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-32.6875\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-33.8582\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.88s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-32.2321\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-33.6171\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-31.8149\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.58s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-33.1759\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-33.6133\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.46s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-33.318\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-31.6894\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 20.21s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115604\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115624\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115624\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   20.32 GB / 237.11 GB (8.6%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: MLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (131.72, 0.0, 37.08897, 35.63854)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2656.11 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-35.8231\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========6fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-36.2806\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-32.7742\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-32.9949\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-33.6216\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.78s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-32.7823\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-33.7806\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-32.8497\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.45s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-33.6528\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-35.1416\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.41s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-33.5246\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-32.5197\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 19.47s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115624\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115644\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115644\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   20.16 GB / 237.11 GB (8.5%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: MLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (131.72, 0.0, 37.60696, 35.78865)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2632.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-33.9153\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========7fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-33.9728\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-29.8207\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-30.6757\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-30.8913\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-29.7228\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.97s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-30.601\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 5: early stopping\n",
      "\t-29.7429\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.9s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-30.01\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-31.1565\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.53s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-30.9958\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-29.3277\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.04s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115644\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115658\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115658\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   20.00 GB / 237.11 GB (8.4%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: MLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (131.72, 0.0, 37.47711, 35.68588)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2611.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-35.2376\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-35.1533\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========8fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-30.6362\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-30.7236\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-31.718\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.85s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-30.4368\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.57s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-30.9532\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-30.1434\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.79s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-30.9614\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-31.0725\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.31s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-30.8667\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.93s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-29.5862\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 16.85s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115658\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115716\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115716\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   19.84 GB / 237.11 GB (8.4%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: MLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (131.72, 0.0, 37.46612, 35.7312)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2581.05 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-36.3924\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-36.245\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========9fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-31.2692\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-31.1274\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-32.1882\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.77s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-31.1423\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-32.2516\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-30.6658\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.44s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-31.2798\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-32.2455\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.63s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-31.9235\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.92s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-30.5695\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 16.22s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115716\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115732\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115732\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   19.68 GB / 237.11 GB (8.3%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: MLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (131.72, 0.0, 37.41314, 35.68955)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2592.18 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.0s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-36.0035\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-36.2394\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========10fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-31.314\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-31.4155\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-32.7676\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.79s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-31.5042\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-32.1472\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-30.3502\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.45s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-31.7934\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-33.6303\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.9s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-31.8635\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-30.3051\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.54s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115732\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115747\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115747\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   19.51 GB / 237.11 GB (8.2%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: MLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (113.21, 0.0, 37.49025, 35.71373)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2561.72 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-35.3971\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-35.1805\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========11fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-30.3603\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-30.9076\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-31.0748\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.82s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-30.4001\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-31.1829\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 9: early stopping\n",
      "\t-29.8061\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.4s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-31.1919\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-30.8847\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.4s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-31.1469\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-29.5182\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 17.68s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115747\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115805\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115805\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   19.35 GB / 237.11 GB (8.2%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: MLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (131.72, 0.0, 37.03406, 35.56731)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2606.48 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========12fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-38.0976\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-37.8375\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-33.6276\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-33.5385\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-33.8281\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.78s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-33.4842\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-34.0376\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 1: early stopping\n",
      "\t-33.8639\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.53s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-33.9674\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-36.4132\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.8s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-33.0144\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-32.9683\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 17.14s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115805\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115822\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115822\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   19.19 GB / 237.11 GB (8.1%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: MLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (131.72, 0.0, 37.29761, 35.75354)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2612.44 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.0s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-34.6904\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-35.0865\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========13fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-29.8051\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-30.5453\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-31.6999\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-29.7425\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-31.4566\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-29.3675\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.56s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-30.7944\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-31.415\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.87s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-31.3396\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-29.1737\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.17s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115822\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115836\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115836\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   19.03 GB / 237.11 GB (8.0%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: MLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (131.72, 0.0, 37.51621, 35.74332)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2572.15 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-36.3879\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-36.3591\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========14fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-31.1767\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-31.5999\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-33.1087\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.78s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-30.9387\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-33.0157\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 7: early stopping\n",
      "\t-31.0521\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.38s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-31.572\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-32.9809\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.79s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-31.9371\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-30.6942\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 16.01s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115836\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115852\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115852\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   18.87 GB / 237.11 GB (8.0%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: MLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (131.72, 0.0, 37.54904, 35.77515)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2587.95 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-35.9336\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========15fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-36.0989\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-31.5526\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-31.3366\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-31.8865\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.78s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-31.4265\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.64s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-32.1019\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-30.8254\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.74s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-31.6239\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-34.0314\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.36s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-31.4733\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-30.6757\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 19.4s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115852\\\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "test_data = TabularDataset(test)\n",
    "kfold = KFold(n_splits=15, shuffle=True)\n",
    "pres = np.zeros(len(test))\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_)):\n",
    "    print(f'=========={fold+1}fold/15 folds==========')\n",
    "    train_data1 = train_.copy()\n",
    "    train_x = train_data1.iloc[train_idx]\n",
    "    val_x = train_data1.iloc[val_idx]\n",
    "    \n",
    "    train_x =TabularDataset(train_x)\n",
    "    val_x =TabularDataset(val_x)\n",
    "    \n",
    "    predictor = TabularPredictor(\n",
    "        label=label, eval_metric=eval_metric\n",
    "    ).fit(train_x,val_x)  \n",
    "    pre = predictor.predict(test_data)\n",
    "    pres += (pre/15)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0f1e465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'HLM'\n",
    "eval_metric = 'root_mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dae4a29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115912\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115912\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   18.71 GB / 237.11 GB (7.9%)\n",
      "Train Data Rows:    3264\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    234\n",
      "Tuning Data Columns: 7\n",
      "Label Column: HLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (135.336, 0.0, 53.04057, 36.06449)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2597.0 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-38.1894\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========1fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-37.8938\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-32.5529\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-32.1836\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-32.776\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.82s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-32.399\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.57s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-32.5257\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-32.6599\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.54s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-32.8396\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-34.6145\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.24s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-32.9173\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-32.0145\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 17.08s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115912\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115929\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115929\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   18.55 GB / 237.11 GB (7.8%)\n",
      "Train Data Rows:    3264\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    234\n",
      "Tuning Data Columns: 7\n",
      "Label Column: HLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (135.336, 0.0, 53.38071, 36.0737)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2597.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.0s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-38.6414\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-38.3958\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========2fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-32.6446\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-32.8547\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-33.9693\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.75s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-32.6539\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-33.7746\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-32.6782\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.57s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-32.4845\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-33.557\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.24s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-33.4937\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-32.2342\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 15.64s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115929\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_115945\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_115945\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   18.39 GB / 237.11 GB (7.8%)\n",
      "Train Data Rows:    3264\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    234\n",
      "Tuning Data Columns: 7\n",
      "Label Column: HLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (135.336, 0.0, 52.94848, 36.05438)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2578.15 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-36.3166\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========3fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-36.2763\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-31.4437\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-31.4611\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-31.8458\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.78s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-31.0421\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-32.3428\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 3: early stopping\n",
      "\t-31.4903\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.8s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-31.6606\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-31.4927\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.6s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-31.4797\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.87s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-30.6543\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 17.06s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_115945\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_120002\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_120002\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   18.23 GB / 237.11 GB (7.7%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: HLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (135.336, 0.0, 52.86538, 36.08148)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2588.97 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-35.1269\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========4fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-35.1208\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-32.1057\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-32.1407\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-33.1411\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.82s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-31.9317\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.67s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-32.8525\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 8: early stopping\n",
      "\t-31.2674\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.25s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-32.407\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-33.3751\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.39s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-32.7928\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-31.1814\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 15.17s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_120002\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_120018\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_120018\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   18.06 GB / 237.11 GB (7.6%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: HLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (135.336, 0.0, 53.02057, 36.03575)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2580.81 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.0s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-39.3812\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-40.1406\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========5fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-33.5544\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-33.9972\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-35.5683\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.77s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-33.4751\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-35.0762\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 8: early stopping\n",
      "\t-32.8437\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.43s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-34.1745\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-33.1857\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.64s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-34.9807\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-32.5063\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 13.7s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_120018\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_120031\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_120031\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   17.91 GB / 237.11 GB (7.6%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: HLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (135.336, 0.0, 52.86178, 36.06709)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2580.76 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.0s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-35.3796\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-35.7205\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========6fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-33.0901\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-33.4402\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-34.2637\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.83s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-32.8487\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-34.3077\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-33.1151\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.5s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-33.8166\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-33.7784\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.85s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-33.7895\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-32.5773\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.95s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_120031\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_120047\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_120047\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   17.75 GB / 237.11 GB (7.5%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: HLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (135.336, 0.0, 53.30107, 36.14715)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2589.56 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-36.4162\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========7fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-36.2122\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-32.2899\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-32.5807\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-32.7623\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.78s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-32.3242\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-33.0045\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-32.591\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.56s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-32.1728\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-33.7657\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.82s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-32.5889\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-31.9347\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.07s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_120047\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_120101\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_120101\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   17.59 GB / 237.11 GB (7.4%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: HLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (135.336, 0.0, 53.01414, 35.99937)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2666.58 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.0s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-37.2525\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========8fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-36.4793\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-32.5019\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-32.8894\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-33.2912\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.81s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-32.085\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-33.147\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-32.2407\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.5s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-33.1265\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-32.2911\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.41s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-33.2853\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.24s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-31.7955\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 15.52s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_120101\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_120117\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_120117\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   17.43 GB / 237.11 GB (7.3%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: HLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (135.336, 0.0, 53.12592, 36.09354)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2574.43 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-35.401\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-35.7403\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========9fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-31.0528\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-31.158\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-32.1388\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.83s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-30.8474\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-32.8825\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 7: early stopping\n",
      "\t-30.8544\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.21s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-30.893\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-31.2999\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.12s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-31.7678\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-30.4075\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 18.57s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_120117\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_120136\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_120136\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   17.27 GB / 237.11 GB (7.3%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: HLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (135.336, 0.0, 53.1431, 36.14189)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2561.84 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.0s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-34.2265\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-33.9142\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========10fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-31.0518\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-31.1043\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-31.7321\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.85s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-30.9559\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-32.049\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 7: early stopping\n",
      "\t-30.7413\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-31.4034\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-31.6338\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-31.1139\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-30.3912\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.2s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_120136\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_120150\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_120150\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   17.11 GB / 237.11 GB (7.2%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: HLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (135.336, 0.0, 53.25281, 36.1324)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2552.56 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.0s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-36.1642\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-35.8848\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========11fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-30.2382\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-30.8841\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-30.7012\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.84s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-30.3811\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.51s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-30.5883\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 8: early stopping\n",
      "\t-30.1828\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.26s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-30.5253\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-30.8059\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.83s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-31.1816\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-29.6686\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 17.22s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_120150\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_120208\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_120208\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   16.95 GB / 237.11 GB (7.1%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: HLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (107.323, 0.0, 52.8129, 36.10416)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2600.2 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========12fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-37.8614\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-37.6509\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-32.777\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-32.912\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-32.521\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.83s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-32.6729\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.76s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-32.331\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 5: early stopping\n",
      "\t-32.491\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.07s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-33.2191\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-33.6577\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.34s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-33.0381\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-31.996\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 13.15s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_120208\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_120222\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_120222\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   16.78 GB / 237.11 GB (7.1%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: HLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (135.336, 0.0, 52.99282, 36.10414)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2621.9 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========13fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-35.3425\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-35.4477\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-32.6924\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-32.9933\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-34.1337\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.81s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-32.7042\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.52s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-34.119\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 2: early stopping\n",
      "\t-32.4414\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.66s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-33.0447\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-33.2043\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.66s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-33.6223\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-31.9047\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.38s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_120222\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_120236\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_120236\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   16.63 GB / 237.11 GB (7.0%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: HLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (135.336, 0.0, 53.27982, 36.06757)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2611.02 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.0s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-37.6503\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-37.832\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========14fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-32.465\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-32.4481\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-32.7066\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.87s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-32.3768\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.87s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-33.2641\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-32.9661\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.48s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-33.1084\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-33.4072\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.15s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-33.2201\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.82s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-32.1543\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 18.57s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_120236\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230829_120255\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230829_120255\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   16.47 GB / 237.11 GB (6.9%)\n",
      "Train Data Rows:    3265\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    233\n",
      "Tuning Data Columns: 7\n",
      "Label Column: HLM\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (135.336, 0.0, 53.31304, 36.0328)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2635.09 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])   : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-37.6853\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========15fold/15 folds==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-37.859\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-33.5317\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-33.6986\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-34.9812\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.83s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-33.4797\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.51s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-34.9504\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-33.6317\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.39s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-34.1057\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-35.2508\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.3s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-34.0338\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-33.3193\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 19.99s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230829_120255\\\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "test_data = TabularDataset(test)\n",
    "kfold = KFold(n_splits=15, shuffle=True)\n",
    "pres2 = np.zeros(len(test))\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_2)):\n",
    "    print(f'=========={fold+1}fold/15 folds==========')\n",
    "    train_data2 = train_2.copy()\n",
    "    train_x = train_data2.iloc[train_idx]\n",
    "    val_x = train_data2.iloc[val_idx]\n",
    "    \n",
    "    train_x =TabularDataset(train_x)\n",
    "    val_x =TabularDataset(val_x)\n",
    "    \n",
    "    predictor = TabularPredictor(\n",
    "        label=label, eval_metric=eval_metric\n",
    "    ).fit(train_x,val_x)  \n",
    "    pre2 = predictor.predict(test_data)\n",
    "    pres2 += (pre2/15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1a06ddf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MLM</th>\n",
       "      <th>HLM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>26.040536</td>\n",
       "      <td>46.416742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>64.226667</td>\n",
       "      <td>78.869173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>30.357535</td>\n",
       "      <td>54.715568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>46.323999</td>\n",
       "      <td>65.524218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>60.384765</td>\n",
       "      <td>76.493461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>TEST_478</td>\n",
       "      <td>5.697068</td>\n",
       "      <td>24.946282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>TEST_479</td>\n",
       "      <td>80.455739</td>\n",
       "      <td>86.040176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>TEST_480</td>\n",
       "      <td>45.865274</td>\n",
       "      <td>69.261222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>TEST_481</td>\n",
       "      <td>67.379379</td>\n",
       "      <td>79.656795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>TEST_482</td>\n",
       "      <td>24.907176</td>\n",
       "      <td>61.179127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        MLM        HLM\n",
       "0    TEST_000  26.040536  46.416742\n",
       "1    TEST_001  64.226667  78.869173\n",
       "2    TEST_002  30.357535  54.715568\n",
       "3    TEST_003  46.323999  65.524218\n",
       "4    TEST_004  60.384765  76.493461\n",
       "..        ...        ...        ...\n",
       "478  TEST_478   5.697068  24.946282\n",
       "479  TEST_479  80.455739  86.040176\n",
       "480  TEST_480  45.865274  69.261222\n",
       "481  TEST_481  67.379379  79.656795\n",
       "482  TEST_482  24.907176  61.179127\n",
       "\n",
       "[483 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['MLM']=pres\n",
    "sample['HLM']=pres2\n",
    "sample.to_csv(\"C:/Users/user/Desktop/데이콘 신약대회/open/15fold.csv\",index=False)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbcb2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7ed0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a26b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b6d754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b19198f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91de7549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa802f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d11a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
