{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed98bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>cloud</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>ground_press</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>...</th>\n",
       "      <th>예측오차율_2</th>\n",
       "      <th>pred_amount_3</th>\n",
       "      <th>예측오차율_3</th>\n",
       "      <th>pred_amount_4</th>\n",
       "      <th>예측오차율_4</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>계절</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-19 01:00:00+09:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.03</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>3.01</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-19 02:00:00+09:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.88</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>3.16</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-19 03:00:00+09:00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.99</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-19 04:00:00+09:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.19</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>2.79</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-19 05:00:00+09:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.34</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>2.74</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23179</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-10-15 20:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.51</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>5.56</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23180</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-10-15 21:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.59</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>317.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23181</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-10-15 22:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.68</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>5.58</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23182</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-10-15 23:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.77</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>306.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23183</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-10-16 00:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.71</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>5.85</td>\n",
       "      <td>306.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23184 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       round                       time  cloud   temp  humidity  ground_press  \\\n",
       "0          1  2022-06-19 01:00:00+09:00    6.0  20.03      93.0        1009.0   \n",
       "1          1  2022-06-19 02:00:00+09:00    7.0  19.88      95.0        1009.0   \n",
       "2          1  2022-06-19 03:00:00+09:00   17.0  19.99      96.0        1008.0   \n",
       "3          1  2022-06-19 04:00:00+09:00  100.0  20.19      96.0        1008.0   \n",
       "4          1  2022-06-19 05:00:00+09:00  100.0  20.34      95.0        1008.0   \n",
       "...      ...                        ...    ...    ...       ...           ...   \n",
       "23179      2  2023-10-15 20:00:00+09:00    0.0  18.51      69.0        1015.0   \n",
       "23180      2  2023-10-15 21:00:00+09:00    0.0  18.59      70.0        1015.0   \n",
       "23181      2  2023-10-15 22:00:00+09:00    0.0  18.68      69.0        1015.0   \n",
       "23182      2  2023-10-15 23:00:00+09:00    0.0  18.77      66.0        1015.0   \n",
       "23183      2  2023-10-16 00:00:00+09:00    0.0  18.71      66.0        1015.0   \n",
       "\n",
       "       wind_speed  wind_dir  rain  snow  ...  예측오차율_2  pred_amount_3  예측오차율_3  \\\n",
       "0            3.01     162.0   0.0   0.0  ...      0.0            0.0      0.0   \n",
       "1            3.16     159.0   0.0   0.0  ...      0.0            0.0      0.0   \n",
       "2            2.92     161.0   0.0   0.0  ...      0.0            0.0      0.0   \n",
       "3            2.79     157.0   0.0   0.0  ...      0.0            0.0      0.0   \n",
       "4            2.74     156.0   0.0   0.0  ...      0.0            0.0      0.0   \n",
       "...           ...       ...   ...   ...  ...      ...            ...      ...   \n",
       "23179        5.56     328.0   0.0   0.0  ...      0.0            0.0      0.0   \n",
       "23180        5.25     317.0   0.0   0.0  ...      0.0            0.0      0.0   \n",
       "23181        5.58     310.0   0.0   0.0  ...      0.0            0.0      0.0   \n",
       "23182        5.75     306.0   0.0   0.0  ...      0.0            0.0      0.0   \n",
       "23183        5.85     306.0   0.0   0.0  ...      0.0            0.0      0.0   \n",
       "\n",
       "       pred_amount_4  예측오차율_4  month  week  weekday  hour  계절  \n",
       "0                0.0      0.0      6    24        6     1   2  \n",
       "1                0.0      0.0      6    24        6     2   2  \n",
       "2                0.0      0.0      6    24        6     3   2  \n",
       "3                0.0      0.0      6    24        6     4   2  \n",
       "4                0.0      0.0      6    24        6     5   2  \n",
       "...              ...      ...    ...   ...      ...   ...  ..  \n",
       "23179            0.0      0.0     10    41        6    20   3  \n",
       "23180            0.0      0.0     10    41        6    21   3  \n",
       "23181            0.0      0.0     10    41        6    22   3  \n",
       "23182            0.0      0.0     10    41        6    23   3  \n",
       "23183            0.0      0.0     10    42        0     0   3  \n",
       "\n",
       "[23184 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "merged_data_combined = pd.read_csv(\"C:/Users/user/Desktop/OIBC2023_data/시간대별스태킹모델.csv\")\n",
    "merged_data_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473e5194",
   "metadata": {},
   "source": [
    "# 7시 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad80b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_combined_7 = merged_data_combined[(merged_data_combined['계절']==3) & ((merged_data_combined['hour']==6) | (merged_data_combined['hour']==7) | (merged_data_combined['hour']==8))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1331e915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "1    385\n",
      "2    304\n",
      "0    124\n",
      "Name: count, dtype: int64\n",
      "Mean Squared Error on Test Data: 2.203740310559891\n",
      "Mean Squared Error on Test Data: 2.8026160472836037\n",
      "Mean Squared Error on Test Data: 6.585225755222267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "<ipython-input-3-11605635fd23>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data_combined_7['Cluster'] = kmeans_7.labels_\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 예시 데이터, 실제 데이터에 맞게 수정 필요\n",
    "# merged_data_combined_1r = ...\n",
    "\n",
    "# 필요한 특성 선택 (예시로 모든 열 사용)\n",
    "features = ['cloud', 'temp', 'humidity', 'ground_press',\n",
    "       'wind_speed', 'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx',\n",
    "       'azimuth', 'elevation']\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler_7 = StandardScaler()\n",
    "scaled_data_7 = scaler_7.fit_transform(merged_data_combined_7[features])\n",
    "\n",
    "# 군집 개수 설정\n",
    "num_clusters = 3  # 적절한 군집 개수로 수정\n",
    "\n",
    "# KMeans 모델 생성\n",
    "kmeans_7 = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "\n",
    "# 모델 피팅\n",
    "kmeans_7.fit(scaled_data_7)\n",
    "\n",
    "# 군집 결과를 데이터프레임에 추가\n",
    "merged_data_combined_7['Cluster'] = kmeans_7.labels_\n",
    "\n",
    "# 결과 출력\n",
    "print(merged_data_combined_7['Cluster'].value_counts())\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "merged_data_combined_7_0 = merged_data_combined_7[merged_data_combined_7['Cluster']==0] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_7_0 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_7_0 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_7_0 = LinearRegression()\n",
    "stacking_model_7_0.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_7_0 = stacking_model_7_0.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_7_0)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_7_1 = merged_data_combined_7[merged_data_combined_7['Cluster']==1] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_7_1 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_7_1 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_7_1 = LinearRegression()\n",
    "stacking_model_7_1.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_7_1 = stacking_model_7_1.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_7_1)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_7_2 = merged_data_combined_7[merged_data_combined_7['Cluster']==2] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_7_2 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_7_2 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_7_2 = LinearRegression()\n",
    "stacking_model_7_2.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_7_2 = stacking_model_7_2.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_7_2)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba8527",
   "metadata": {},
   "source": [
    "# 8시 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a2a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_combined_8 = merged_data_combined[(merged_data_combined['계절']==3) & ((merged_data_combined['hour']==7) | (merged_data_combined['hour']==8) | (merged_data_combined['hour']==9))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82566b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "2    388\n",
      "1    299\n",
      "0    126\n",
      "Name: count, dtype: int64\n",
      "Mean Squared Error on Test Data: 36.6304951513801\n",
      "Mean Squared Error on Test Data: 26.03793765272154\n",
      "Mean Squared Error on Test Data: 21.80273288985895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "<ipython-input-5-83df4fec65a4>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data_combined_8['Cluster'] = kmeans_8.labels_\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 예시 데이터, 실제 데이터에 맞게 수정 필요\n",
    "# merged_data_combined_1r = ...\n",
    "\n",
    "# 필요한 특성 선택 (예시로 모든 열 사용)\n",
    "features = ['cloud', 'temp', 'humidity', 'ground_press',\n",
    "       'wind_speed', 'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx',\n",
    "       'azimuth', 'elevation']\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler_8 = StandardScaler()\n",
    "scaled_data_8 = scaler_8.fit_transform(merged_data_combined_8[features])\n",
    "\n",
    "# 군집 개수 설정\n",
    "num_clusters = 3  # 적절한 군집 개수로 수정\n",
    "\n",
    "# KMeans 모델 생성\n",
    "kmeans_8 = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "\n",
    "# 모델 피팅\n",
    "kmeans_8.fit(scaled_data_8)\n",
    "\n",
    "# 군집 결과를 데이터프레임에 추가\n",
    "merged_data_combined_8['Cluster'] = kmeans_8.labels_\n",
    "\n",
    "# 결과 출력\n",
    "print(merged_data_combined_8['Cluster'].value_counts())\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "merged_data_combined_8_0 = merged_data_combined_8[merged_data_combined_8['Cluster']==0] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_8_0 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_8_0 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_8_0 = LinearRegression()\n",
    "stacking_model_8_0.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_8_0 = stacking_model_8_0.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_8_0)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_8_1 = merged_data_combined_8[merged_data_combined_8['Cluster']==1] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_8_1 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_8_1 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_8_1 = LinearRegression()\n",
    "stacking_model_8_1.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_8_1 = stacking_model_8_1.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_8_1)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_8_2 = merged_data_combined_8[merged_data_combined_8['Cluster']==2] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_8_2 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_8_2 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_8_2 = LinearRegression()\n",
    "stacking_model_8_2.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_8_2 = stacking_model_8_2.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_8_2)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd954a4c",
   "metadata": {},
   "source": [
    "# 9시 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c508965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_combined_9 = merged_data_combined[(merged_data_combined['계절']==3) & ((merged_data_combined['hour']==8) | (merged_data_combined['hour']==9) | (merged_data_combined['hour']==10))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94d41228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "0    383\n",
      "1    235\n",
      "2    195\n",
      "Name: count, dtype: int64\n",
      "Mean Squared Error on Test Data: 68.50496230035266\n",
      "Mean Squared Error on Test Data: 123.87277303383657\n",
      "Mean Squared Error on Test Data: 68.08852127410428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "<ipython-input-7-8328adc3b7bd>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data_combined_9['Cluster'] = kmeans_9.labels_\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 예시 데이터, 실제 데이터에 맞게 수정 필요\n",
    "# merged_data_combined_1r = ...\n",
    "\n",
    "# 필요한 특성 선택 (예시로 모든 열 사용)\n",
    "features = ['cloud', 'temp', 'humidity', 'ground_press',\n",
    "       'wind_speed', 'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx',\n",
    "       'azimuth', 'elevation']\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler_9 = StandardScaler()\n",
    "scaled_data_9 = scaler_9.fit_transform(merged_data_combined_9[features])\n",
    "\n",
    "# 군집 개수 설정\n",
    "num_clusters = 3  # 적절한 군집 개수로 수정\n",
    "\n",
    "# KMeans 모델 생성\n",
    "kmeans_9 = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "\n",
    "# 모델 피팅\n",
    "kmeans_9.fit(scaled_data_9)\n",
    "\n",
    "# 군집 결과를 데이터프레임에 추가\n",
    "merged_data_combined_9['Cluster'] = kmeans_9.labels_\n",
    "\n",
    "# 결과 출력\n",
    "print(merged_data_combined_9['Cluster'].value_counts())\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "merged_data_combined_9_0 = merged_data_combined_9[merged_data_combined_9['Cluster']==0] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_9_0 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_9_0 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_9_0 = LinearRegression()\n",
    "stacking_model_9_0.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_9_0 = stacking_model_9_0.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_9_0)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_9_1 = merged_data_combined_9[merged_data_combined_9['Cluster']==1] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_9_1 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_9_1 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_9_1 = LinearRegression()\n",
    "stacking_model_9_1.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_9_1 = stacking_model_9_1.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_9_1)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_9_2 = merged_data_combined_9[merged_data_combined_9['Cluster']==2] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_9_2 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_9_2 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_9_2 = LinearRegression()\n",
    "stacking_model_9_2.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_9_2 = stacking_model_9_2.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_9_2)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a97c2d7",
   "metadata": {},
   "source": [
    "# 10시 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f1feedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_combined_10 = merged_data_combined[(merged_data_combined['계절']==3) & ((merged_data_combined['hour']==9) | (merged_data_combined['hour']==10) | (merged_data_combined['hour']==11))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "637decaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "1    392\n",
      "0    259\n",
      "2    162\n",
      "Name: count, dtype: int64\n",
      "Mean Squared Error on Test Data: 135.57048557946445\n",
      "Mean Squared Error on Test Data: 124.91151884800254\n",
      "Mean Squared Error on Test Data: 223.26611936533047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "<ipython-input-9-022a761491f9>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data_combined_10['Cluster'] = kmeans_10.labels_\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 예시 데이터, 실제 데이터에 맞게 수정 필요\n",
    "# merged_data_combined_1r = ...\n",
    "\n",
    "# 필요한 특성 선택 (예시로 모든 열 사용)\n",
    "features = ['cloud', 'temp', 'humidity', 'ground_press',\n",
    "       'wind_speed', 'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx',\n",
    "       'azimuth', 'elevation']\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler_10 = StandardScaler()\n",
    "scaled_data_10 = scaler_10.fit_transform(merged_data_combined_10[features])\n",
    "\n",
    "# 군집 개수 설정\n",
    "num_clusters = 3  # 적절한 군집 개수로 수정\n",
    "\n",
    "# KMeans 모델 생성\n",
    "kmeans_10 = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "\n",
    "# 모델 피팅\n",
    "kmeans_10.fit(scaled_data_10)\n",
    "\n",
    "# 군집 결과를 데이터프레임에 추가\n",
    "merged_data_combined_10['Cluster'] = kmeans_10.labels_\n",
    "\n",
    "# 결과 출력\n",
    "print(merged_data_combined_10['Cluster'].value_counts())\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "merged_data_combined_10_0 = merged_data_combined_10[merged_data_combined_10['Cluster']==0] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_10_0 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_10_0 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_10_0 = LinearRegression()\n",
    "stacking_model_10_0.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_10_0 = stacking_model_10_0.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_10_0)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_10_1 = merged_data_combined_10[merged_data_combined_10['Cluster']==1] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_10_1 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_10_1 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_10_1 = LinearRegression()\n",
    "stacking_model_10_1.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_10_1 = stacking_model_10_1.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_10_1)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_10_2 = merged_data_combined_10[merged_data_combined_10['Cluster']==2] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_10_2 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_10_2 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_10_2 = LinearRegression()\n",
    "stacking_model_10_2.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_10_2 = stacking_model_10_2.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_10_2)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850730fa",
   "metadata": {},
   "source": [
    "# 11시 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd248c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_combined_11 = merged_data_combined[(merged_data_combined['계절']==3) & ((merged_data_combined['hour']==10) | (merged_data_combined['hour']==11) | (merged_data_combined['hour']==12))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e774bf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "0    369\n",
      "1    263\n",
      "2    181\n",
      "Name: count, dtype: int64\n",
      "Mean Squared Error on Test Data: 226.29986337852083\n",
      "Mean Squared Error on Test Data: 144.57969555513174\n",
      "Mean Squared Error on Test Data: 274.95395641455394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "<ipython-input-11-87af1128829d>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data_combined_11['Cluster'] = kmeans_11.labels_\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 예시 데이터, 실제 데이터에 맞게 수정 필요\n",
    "# merged_data_combined_1r = ...\n",
    "\n",
    "# 필요한 특성 선택 (예시로 모든 열 사용)\n",
    "features = ['cloud', 'temp', 'humidity', 'ground_press',\n",
    "       'wind_speed', 'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx',\n",
    "       'azimuth', 'elevation']\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler_11 = StandardScaler()\n",
    "scaled_data_11 = scaler_11.fit_transform(merged_data_combined_11[features])\n",
    "\n",
    "# 군집 개수 설정\n",
    "num_clusters = 3  # 적절한 군집 개수로 수정\n",
    "\n",
    "# KMeans 모델 생성\n",
    "kmeans_11 = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "\n",
    "# 모델 피팅\n",
    "kmeans_11.fit(scaled_data_11)\n",
    "\n",
    "# 군집 결과를 데이터프레임에 추가\n",
    "merged_data_combined_11['Cluster'] = kmeans_11.labels_\n",
    "\n",
    "# 결과 출력\n",
    "print(merged_data_combined_11['Cluster'].value_counts())\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "merged_data_combined_11_0 = merged_data_combined_11[merged_data_combined_11['Cluster']==0] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_11_0 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_11_0 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_11_0 = LinearRegression()\n",
    "stacking_model_11_0.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_11_0 = stacking_model_11_0.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_11_0)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_11_1 = merged_data_combined_11[merged_data_combined_11['Cluster']==1] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_11_1 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_11_1 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_11_1 = LinearRegression()\n",
    "stacking_model_11_1.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_11_1 = stacking_model_11_1.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_11_1)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_11_2 = merged_data_combined_11[merged_data_combined_11['Cluster']==2] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_11_2 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_11_2 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_11_2 = LinearRegression()\n",
    "stacking_model_11_2.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_11_2 = stacking_model_11_2.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_11_2)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b025fabf",
   "metadata": {},
   "source": [
    "# 12시 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f07e35db",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_combined_12 = merged_data_combined[(merged_data_combined['계절']==3) & ((merged_data_combined['hour']==11) | (merged_data_combined['hour']==12) | (merged_data_combined['hour']==13))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "261e6c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "1    372\n",
      "0    274\n",
      "2    167\n",
      "Name: count, dtype: int64\n",
      "Mean Squared Error on Test Data: 213.40742478701208\n",
      "Mean Squared Error on Test Data: 241.97801973968257\n",
      "Mean Squared Error on Test Data: 456.8558298690166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "<ipython-input-13-ad101a408979>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data_combined_12['Cluster'] = kmeans_12.labels_\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 예시 데이터, 실제 데이터에 맞게 수정 필요\n",
    "# merged_data_combined_1r = ...\n",
    "\n",
    "# 필요한 특성 선택 (예시로 모든 열 사용)\n",
    "features = ['cloud', 'temp', 'humidity', 'ground_press',\n",
    "       'wind_speed', 'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx',\n",
    "       'azimuth', 'elevation']\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler_12 = StandardScaler()\n",
    "scaled_data_12 = scaler_12.fit_transform(merged_data_combined_12[features])\n",
    "\n",
    "# 군집 개수 설정\n",
    "num_clusters = 3  # 적절한 군집 개수로 수정\n",
    "\n",
    "# KMeans 모델 생성\n",
    "kmeans_12 = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "\n",
    "# 모델 피팅\n",
    "kmeans_12.fit(scaled_data_12)\n",
    "\n",
    "# 군집 결과를 데이터프레임에 추가\n",
    "merged_data_combined_12['Cluster'] = kmeans_12.labels_\n",
    "\n",
    "# 결과 출력\n",
    "print(merged_data_combined_12['Cluster'].value_counts())\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "merged_data_combined_12_0 = merged_data_combined_12[merged_data_combined_12['Cluster']==0] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_12_0 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_12_0 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_12_0 = LinearRegression()\n",
    "stacking_model_12_0.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_12_0 = stacking_model_12_0.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_12_0)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_12_1 = merged_data_combined_12[merged_data_combined_12['Cluster']==1] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_12_1 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_12_1 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_12_1 = LinearRegression()\n",
    "stacking_model_12_1.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_12_1 = stacking_model_12_1.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_12_1)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_12_2 = merged_data_combined_12[merged_data_combined_12['Cluster']==2] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_12_2 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_12_2 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_12_2 = LinearRegression()\n",
    "stacking_model_12_2.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_12_2 = stacking_model_12_2.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_12_2)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4438758d",
   "metadata": {},
   "source": [
    "# 13시 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ecb15f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_combined_13 = merged_data_combined[(merged_data_combined['계절']==3) & ((merged_data_combined['hour']==12) | (merged_data_combined['hour']==13) | (merged_data_combined['hour']==14))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "058f0b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "0    371\n",
      "2    299\n",
      "1    143\n",
      "Name: count, dtype: int64\n",
      "Mean Squared Error on Test Data: 237.1786020985669\n",
      "Mean Squared Error on Test Data: 372.27100937016377\n",
      "Mean Squared Error on Test Data: 281.9847438457507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "<ipython-input-15-de02d9395d32>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data_combined_13['Cluster'] = kmeans_13.labels_\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 예시 데이터, 실제 데이터에 맞게 수정 필요\n",
    "# merged_data_combined_1r = ...\n",
    "\n",
    "# 필요한 특성 선택 (예시로 모든 열 사용)\n",
    "features = ['cloud', 'temp', 'humidity', 'ground_press',\n",
    "       'wind_speed', 'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx',\n",
    "       'azimuth', 'elevation']\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler_13 = StandardScaler()\n",
    "scaled_data_13 = scaler_13.fit_transform(merged_data_combined_13[features])\n",
    "\n",
    "# 군집 개수 설정\n",
    "num_clusters = 3  # 적절한 군집 개수로 수정\n",
    "\n",
    "# KMeans 모델 생성\n",
    "kmeans_13 = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "\n",
    "# 모델 피팅\n",
    "kmeans_13.fit(scaled_data_13)\n",
    "\n",
    "# 군집 결과를 데이터프레임에 추가\n",
    "merged_data_combined_13['Cluster'] = kmeans_13.labels_\n",
    "\n",
    "# 결과 출력\n",
    "print(merged_data_combined_13['Cluster'].value_counts())\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "merged_data_combined_13_0 = merged_data_combined_13[merged_data_combined_13['Cluster']==0] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_13_0 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_13_0 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_13_0 = LinearRegression()\n",
    "stacking_model_13_0.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_13_0 = stacking_model_13_0.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_13_0)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_13_1 = merged_data_combined_13[merged_data_combined_13['Cluster']==1] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_13_1 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_13_1 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_13_1 = LinearRegression()\n",
    "stacking_model_13_1.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_13_1 = stacking_model_13_1.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_13_1)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_13_2 = merged_data_combined_13[merged_data_combined_13['Cluster']==2] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_13_2 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_13_2 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_13_2 = LinearRegression()\n",
    "stacking_model_13_2.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_13_2 = stacking_model_13_2.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_13_2)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5f9059",
   "metadata": {},
   "source": [
    "# 14시 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13c88cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '계절' 변수를 만들어서 조건에 따라 할당\n",
    "merged_data_combined_14 = merged_data_combined[(merged_data_combined['계절']==3) & ((merged_data_combined['hour']==13) | (merged_data_combined['hour']==14) | (merged_data_combined['hour']==15))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4e3b37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "1    347\n",
      "0    291\n",
      "2    175\n",
      "Name: count, dtype: int64\n",
      "Mean Squared Error on Test Data: 273.7924789554793\n",
      "Mean Squared Error on Test Data: 172.6144947079022\n",
      "Mean Squared Error on Test Data: 259.0801592163142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "<ipython-input-17-90d837155e45>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data_combined_14['Cluster'] = kmeans_14.labels_\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = ['cloud', 'temp', 'humidity', 'ground_press',\n",
    "       'wind_speed', 'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx',\n",
    "       'azimuth', 'elevation']\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler_14 = StandardScaler()\n",
    "scaled_data_14 = scaler_14.fit_transform(merged_data_combined_14[features])\n",
    "\n",
    "# 군집 개수 설정\n",
    "num_clusters = 3  # 적절한 군집 개수로 수정\n",
    "\n",
    "# KMeans 모델 생성\n",
    "kmeans_14 = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "\n",
    "# 모델 피팅\n",
    "kmeans_14.fit(scaled_data_14)\n",
    "\n",
    "# 군집 결과를 데이터프레임에 추가\n",
    "merged_data_combined_14['Cluster'] = kmeans_14.labels_\n",
    "\n",
    "# 결과 출력\n",
    "print(merged_data_combined_14['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_14_0 = merged_data_combined_14[merged_data_combined_14['Cluster']==0] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_14_0 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_14_0 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_14_0 = LinearRegression()\n",
    "stacking_model_14_0.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_14_0 = stacking_model_14_0.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_14_0)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_14_1 = merged_data_combined_14[merged_data_combined_14['Cluster']==1] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_14_1 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_14_1 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_14_1 = LinearRegression()\n",
    "stacking_model_14_1.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_14_1 = stacking_model_14_1.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_14_1)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_14_2 = merged_data_combined_14[merged_data_combined_14['Cluster']==2] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_14_2 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_14_2 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_14_2 = LinearRegression()\n",
    "stacking_model_14_2.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_14_2 = stacking_model_14_2.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_14_2)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3becf26",
   "metadata": {},
   "source": [
    "# 15시 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0697a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '계절' 변수를 만들어서 조건에 따라 할당\n",
    "merged_data_combined_15 = merged_data_combined[(merged_data_combined['계절']==3) & ((merged_data_combined['hour']==14) | (merged_data_combined['hour']==15) | (merged_data_combined['hour']==16))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cdf19d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "2    356\n",
      "1    311\n",
      "0    146\n",
      "Name: count, dtype: int64\n",
      "Mean Squared Error on Test Data: 196.7636308178463\n",
      "Mean Squared Error on Test Data: 204.76987352850887\n",
      "Mean Squared Error on Test Data: 133.0574861786082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "<ipython-input-19-2f97fa886f9a>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data_combined_15['Cluster'] = kmeans_15.labels_\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = ['cloud', 'temp', 'humidity', 'ground_press',\n",
    "       'wind_speed', 'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx',\n",
    "       'azimuth', 'elevation']\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler_15 = StandardScaler()\n",
    "scaled_data_15 = scaler_15.fit_transform(merged_data_combined_15[features])\n",
    "\n",
    "# 군집 개수 설정\n",
    "num_clusters = 3  # 적절한 군집 개수로 수정\n",
    "\n",
    "# KMeans 모델 생성\n",
    "kmeans_15 = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "\n",
    "# 모델 피팅\n",
    "kmeans_15.fit(scaled_data_15)\n",
    "\n",
    "# 군집 결과를 데이터프레임에 추가\n",
    "merged_data_combined_15['Cluster'] = kmeans_15.labels_\n",
    "\n",
    "# 결과 출력\n",
    "print(merged_data_combined_15['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_15_0 = merged_data_combined_15[merged_data_combined_15['Cluster']==0] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_15_0 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_15_0 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_15_0 = LinearRegression()\n",
    "stacking_model_15_0.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_15_0 = stacking_model_15_0.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_15_0)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_15_1 = merged_data_combined_15[merged_data_combined_15['Cluster']==1] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_15_1 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_15_1 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_15_1 = LinearRegression()\n",
    "stacking_model_15_1.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_15_1 = stacking_model_15_1.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_15_1)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_15_2 = merged_data_combined_15[merged_data_combined_15['Cluster']==2] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_15_2 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_15_2 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_15_2 = LinearRegression()\n",
    "stacking_model_15_2.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_15_2 = stacking_model_15_2.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_15_2)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3394524",
   "metadata": {},
   "source": [
    "# 16시 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "212c7d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '계절' 변수를 만들어서 조건에 따라 할당\n",
    "merged_data_combined_16 = merged_data_combined[(merged_data_combined['계절']==3) & ((merged_data_combined['hour']==15) | (merged_data_combined['hour']==16) | (merged_data_combined['hour']==17))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38ca76f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "2    341\n",
      "0    326\n",
      "1    146\n",
      "Name: count, dtype: int64\n",
      "Mean Squared Error on Test Data: 169.5496826151477\n",
      "Mean Squared Error on Test Data: 164.22544510303754\n",
      "Mean Squared Error on Test Data: 126.12910811013398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "<ipython-input-21-ac1e0acd5e4c>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data_combined_16['Cluster'] = kmeans_16.labels_\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = ['cloud', 'temp', 'humidity', 'ground_press',\n",
    "       'wind_speed', 'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx',\n",
    "       'azimuth', 'elevation']\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler_16 = StandardScaler()\n",
    "scaled_data_16 = scaler_16.fit_transform(merged_data_combined_16[features])\n",
    "\n",
    "# 군집 개수 설정\n",
    "num_clusters = 3  # 적절한 군집 개수로 수정\n",
    "\n",
    "# KMeans 모델 생성\n",
    "kmeans_16 = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "\n",
    "# 모델 피팅\n",
    "kmeans_16.fit(scaled_data_16)\n",
    "\n",
    "# 군집 결과를 데이터프레임에 추가\n",
    "merged_data_combined_16['Cluster'] = kmeans_16.labels_\n",
    "\n",
    "# 결과 출력\n",
    "print(merged_data_combined_16['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_16_0 = merged_data_combined_16[merged_data_combined_16['Cluster']==0] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_16_0 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_16_0 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_16_0 = LinearRegression()\n",
    "stacking_model_16_0.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_16_0 = stacking_model_16_0.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_16_0)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_16_1 = merged_data_combined_16[merged_data_combined_16['Cluster']==1] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_16_1 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_16_1 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_16_1 = LinearRegression()\n",
    "stacking_model_16_1.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_16_1 = stacking_model_16_1.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_16_1)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_16_2 = merged_data_combined_16[merged_data_combined_16['Cluster']==2] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_16_2 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_16_2 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_16_2 = LinearRegression()\n",
    "stacking_model_16_2.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_16_2 = stacking_model_16_2.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_16_2)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058934b",
   "metadata": {},
   "source": [
    "# 17시 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fa96614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '계절' 변수를 만들어서 조건에 따라 할당\n",
    "merged_data_combined_17 = merged_data_combined[(merged_data_combined['계절']==3) & ((merged_data_combined['hour']==16) | (merged_data_combined['hour']==17) | (merged_data_combined['hour']==18))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3b2efde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "1    361\n",
      "0    227\n",
      "2    225\n",
      "Name: count, dtype: int64\n",
      "Mean Squared Error on Test Data: 69.47392969339272\n",
      "Mean Squared Error on Test Data: 34.66181741111246\n",
      "Mean Squared Error on Test Data: 151.3773525817557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "<ipython-input-23-bfc125fdf909>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data_combined_17['Cluster'] = kmeans_17.labels_\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = ['cloud', 'temp', 'humidity', 'ground_press',\n",
    "       'wind_speed', 'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx',\n",
    "       'azimuth', 'elevation']\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler_17 = StandardScaler()\n",
    "scaled_data_17 = scaler_17.fit_transform(merged_data_combined_17[features])\n",
    "\n",
    "# 군집 개수 설정\n",
    "num_clusters = 3  # 적절한 군집 개수로 수정\n",
    "\n",
    "# KMeans 모델 생성\n",
    "kmeans_17 = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "\n",
    "# 모델 피팅\n",
    "kmeans_17.fit(scaled_data_17)\n",
    "\n",
    "# 군집 결과를 데이터프레임에 추가\n",
    "merged_data_combined_17['Cluster'] = kmeans_17.labels_\n",
    "\n",
    "# 결과 출력\n",
    "print(merged_data_combined_17['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_17_0 = merged_data_combined_17[merged_data_combined_17['Cluster']==0] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_17_0 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_17_0 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_17_0 = LinearRegression()\n",
    "stacking_model_17_0.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_17_0 = stacking_model_17_0.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_17_0)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_17_1 = merged_data_combined_17[merged_data_combined_17['Cluster']==1] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_17_1 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_17_1 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_17_1 = LinearRegression()\n",
    "stacking_model_17_1.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_17_1 = stacking_model_17_1.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_17_1)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_17_2 = merged_data_combined_17[merged_data_combined_17['Cluster']==2] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_17_2 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_17_2 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_17_2 = LinearRegression()\n",
    "stacking_model_17_2.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_17_2 = stacking_model_17_2.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_17_2)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034df007",
   "metadata": {},
   "source": [
    "# 18시 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69887a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '계절' 변수를 만들어서 조건에 따라 할당\n",
    "merged_data_combined_18 = merged_data_combined[(merged_data_combined['계절']==3) & ((merged_data_combined['hour']==17) | (merged_data_combined['hour']==18) | (merged_data_combined['hour']==19))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69cd7a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "1    392\n",
      "2    315\n",
      "0    106\n",
      "Name: count, dtype: int64\n",
      "Mean Squared Error on Test Data: 59.56837079680791\n",
      "Mean Squared Error on Test Data: 12.60930189068993\n",
      "Mean Squared Error on Test Data: 30.839763035058198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "<ipython-input-25-a5b97541aaa5>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data_combined_18['Cluster'] = kmeans_18.labels_\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = ['cloud', 'temp', 'humidity', 'ground_press',\n",
    "       'wind_speed', 'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx',\n",
    "       'azimuth', 'elevation']\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler_18 = StandardScaler()\n",
    "scaled_data_18 = scaler_18.fit_transform(merged_data_combined_18[features])\n",
    "\n",
    "# 군집 개수 설정\n",
    "num_clusters = 3  # 적절한 군집 개수로 수정\n",
    "\n",
    "# KMeans 모델 생성\n",
    "kmeans_18 = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "\n",
    "# 모델 피팅\n",
    "kmeans_18.fit(scaled_data_18)\n",
    "\n",
    "# 군집 결과를 데이터프레임에 추가\n",
    "merged_data_combined_18['Cluster'] = kmeans_18.labels_\n",
    "\n",
    "# 결과 출력\n",
    "print(merged_data_combined_18['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_18_0 = merged_data_combined_18[merged_data_combined_18['Cluster']==0] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_18_0 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_18_0 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_18_0 = LinearRegression()\n",
    "stacking_model_18_0.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_18_0 = stacking_model_18_0.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_18_0)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_18_1 = merged_data_combined_18[merged_data_combined_18['Cluster']==1] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_18_1 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_18_1 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_18_1 = LinearRegression()\n",
    "stacking_model_18_1.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_18_1 = stacking_model_18_1.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_18_1)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_18_2 = merged_data_combined_18[merged_data_combined_18['Cluster']==2] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_18_2 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_18_2 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_18_2 = LinearRegression()\n",
    "stacking_model_18_2.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_18_2 = stacking_model_18_2.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_18_2)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f621b012",
   "metadata": {},
   "source": [
    "# 19시 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "177653eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '계절' 변수를 만들어서 조건에 따라 할당\n",
    "merged_data_combined_19 = merged_data_combined[(merged_data_combined['계절']==3) & ((merged_data_combined['hour']==18) | (merged_data_combined['hour']==19) | (merged_data_combined['hour']==20))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c63a3c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "0    452\n",
      "1    359\n",
      "2      2\n",
      "Name: count, dtype: int64\n",
      "Mean Squared Error on Test Data: 2.47153563052777\n",
      "Mean Squared Error on Test Data: 4.554333498724216\n",
      "Mean Squared Error on Test Data: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "<ipython-input-27-c69bdab37b4e>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data_combined_19['Cluster'] = kmeans_19.labels_\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = ['cloud', 'temp', 'humidity', 'ground_press',\n",
    "       'wind_speed', 'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx',\n",
    "       'azimuth', 'elevation']\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler_19 = StandardScaler()\n",
    "scaled_data_19 = scaler_19.fit_transform(merged_data_combined_19[features])\n",
    "\n",
    "# 군집 개수 설정\n",
    "num_clusters = 3  # 적절한 군집 개수로 수정\n",
    "\n",
    "# KMeans 모델 생성\n",
    "kmeans_19 = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "\n",
    "# 모델 피팅\n",
    "kmeans_19.fit(scaled_data_19)\n",
    "\n",
    "# 군집 결과를 데이터프레임에 추가\n",
    "merged_data_combined_19['Cluster'] = kmeans_19.labels_\n",
    "\n",
    "# 결과 출력\n",
    "print(merged_data_combined_19['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_19_0 = merged_data_combined_19[merged_data_combined_19['Cluster']==0] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_19_0 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_19_0 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_19_0 = LinearRegression()\n",
    "stacking_model_19_0.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_19_0 = stacking_model_19_0.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_19_0)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_19_1 = merged_data_combined_19[merged_data_combined_19['Cluster']==1] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_19_1 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_19_1 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_19_1 = LinearRegression()\n",
    "stacking_model_19_1.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_19_1 = stacking_model_19_1.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_19_1)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "\n",
    "\n",
    "merged_data_combined_19_2 = merged_data_combined_19[merged_data_combined_19['Cluster']==2] \n",
    "\n",
    "\n",
    "# Feature와 Target 분리\n",
    "X = merged_data_combined_19_2 [['pred_amount_0','pred_amount_1','pred_amount_2','pred_amount_3','pred_amount_4']]\n",
    "y = merged_data_combined_19_2 ['amount']\n",
    "X.columns = ['model1','model2','model3','model4','model5']\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Linear Regression 모델 생성 및 훈련\n",
    "stacking_model_19_2 = LinearRegression()\n",
    "stacking_model_19_2.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions_19_2 = stacking_model_19_2.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, predictions_19_2)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6227a0",
   "metadata": {},
   "source": [
    "# test 셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47c27249",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cloud</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>ground_press</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>vis</th>\n",
       "      <th>uv_idx</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>elevation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-10T16:00:00+00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.23</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>10.80</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.555560e-01</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.8725</td>\n",
       "      <td>-70.06400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-10T17:00:00+00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>10.39</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.555560e-01</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.9142</td>\n",
       "      <td>-61.24170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-10T18:00:00+00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.89</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>10.59</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.555560e-01</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.6309</td>\n",
       "      <td>-49.90780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-10T19:00:00+00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.67</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>9.83</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.111110e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.2980</td>\n",
       "      <td>-37.78870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-10T20:00:00+00:00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.54</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>9.92</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.111110e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.9449</td>\n",
       "      <td>-25.48450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-11-10T21:00:00+00:00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>9.68</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.9390</td>\n",
       "      <td>-13.29710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-11-10T22:00:00+00:00</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.46</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>9.49</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0920</td>\n",
       "      <td>-1.46727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-11-10T23:00:00+00:00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.64</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.0570</td>\n",
       "      <td>9.72862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-11-11T00:00:00+00:00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.24</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>8.60</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.4920</td>\n",
       "      <td>19.90720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-11-11T01:00:00+00:00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.111110e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>2.0</td>\n",
       "      <td>142.0670</td>\n",
       "      <td>28.50590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-11-11T02:00:00+00:00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.68</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.684340e-14</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>2.0</td>\n",
       "      <td>157.2300</td>\n",
       "      <td>34.74430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-11-11T03:00:00+00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.22</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.555560e-01</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>1.0</td>\n",
       "      <td>174.6140</td>\n",
       "      <td>37.74720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-11-11T04:00:00+00:00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>9.81</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>9.42</td>\n",
       "      <td>359.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.111110e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>2.0</td>\n",
       "      <td>192.6220</td>\n",
       "      <td>36.95290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-11-11T05:00:00+00:00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.03</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>9.98</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.111110e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>2.0</td>\n",
       "      <td>209.2140</td>\n",
       "      <td>32.52080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-11-11T06:00:00+00:00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.04</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>9.96</td>\n",
       "      <td>357.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>2.0</td>\n",
       "      <td>223.2880</td>\n",
       "      <td>25.20440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-11-11T07:00:00+00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>9.92</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>10.09</td>\n",
       "      <td>358.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>1.0</td>\n",
       "      <td>234.8970</td>\n",
       "      <td>15.87280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-11-11T08:00:00+00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>358.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>244.6320</td>\n",
       "      <td>5.21813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-11-11T09:00:00+00:00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>9.41</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>9.78</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253.1660</td>\n",
       "      <td>-6.27970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-11-11T10:00:00+00:00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>9.27</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>9.60</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.1430</td>\n",
       "      <td>-18.29090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-11-11T11:00:00+00:00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>9.18</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>9.20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>269.2470</td>\n",
       "      <td>-30.56450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-11-11T12:00:00+00:00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>9.12</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>9.08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278.4360</td>\n",
       "      <td>-42.85350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023-11-11T13:00:00+00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.90</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.111110e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290.5410</td>\n",
       "      <td>-54.78710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-11-11T14:00:00+00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.61</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>8.62</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.111110e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>309.9690</td>\n",
       "      <td>-65.48630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-11-11T15:00:00+00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>8.62</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.555560e-01</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>345.8850</td>\n",
       "      <td>-72.24230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time  cloud   temp  humidity  ground_press  \\\n",
       "0   2023-11-10T16:00:00+00:00  100.0   7.23      66.0        1027.0   \n",
       "1   2023-11-10T17:00:00+00:00  100.0   7.10      66.0        1028.0   \n",
       "2   2023-11-10T18:00:00+00:00  100.0   6.89      67.0        1027.0   \n",
       "3   2023-11-10T19:00:00+00:00  100.0   6.67      66.0        1028.0   \n",
       "4   2023-11-10T20:00:00+00:00   80.0   6.54      67.0        1028.0   \n",
       "5   2023-11-10T21:00:00+00:00   55.0   6.44      67.0        1028.0   \n",
       "6   2023-11-10T22:00:00+00:00   41.0   6.46      68.0        1028.0   \n",
       "7   2023-11-10T23:00:00+00:00   34.0   6.64      68.0        1029.0   \n",
       "8   2023-11-11T00:00:00+00:00   30.0   7.24      66.0        1030.0   \n",
       "9   2023-11-11T01:00:00+00:00   17.0   8.00      65.0        1030.0   \n",
       "10  2023-11-11T02:00:00+00:00   25.0   8.68      64.0        1029.0   \n",
       "11  2023-11-11T03:00:00+00:00   45.0   9.22      63.0        1028.0   \n",
       "12  2023-11-11T04:00:00+00:00   37.0   9.81      61.0        1028.0   \n",
       "13  2023-11-11T05:00:00+00:00   35.0  10.03      61.0        1027.0   \n",
       "14  2023-11-11T06:00:00+00:00   37.0  10.04      61.0        1027.0   \n",
       "15  2023-11-11T07:00:00+00:00   97.0   9.92      62.0        1027.0   \n",
       "16  2023-11-11T08:00:00+00:00   97.0   9.66      63.0        1027.0   \n",
       "17  2023-11-11T09:00:00+00:00   98.0   9.41      64.0        1027.0   \n",
       "18  2023-11-11T10:00:00+00:00   99.0   9.27      64.0        1028.0   \n",
       "19  2023-11-11T11:00:00+00:00   99.0   9.18      64.0        1028.0   \n",
       "20  2023-11-11T12:00:00+00:00   99.0   9.12      64.0        1028.0   \n",
       "21  2023-11-11T13:00:00+00:00  100.0   8.90      64.0        1028.0   \n",
       "22  2023-11-11T14:00:00+00:00  100.0   8.61      64.0        1028.0   \n",
       "23  2023-11-11T15:00:00+00:00  100.0   8.20      65.0        1028.0   \n",
       "\n",
       "    wind_speed  wind_dir  rain  snow     dew_point      vis  uv_idx   azimuth  \\\n",
       "0        10.80      11.0   0.0   0.0 -5.555560e-01  16.0934     0.0   30.8725   \n",
       "1        10.39       9.0   0.0   0.0 -5.555560e-01  16.0934     0.0   58.9142   \n",
       "2        10.59      11.0   0.0   0.0 -5.555560e-01  16.0934     0.0   74.6309   \n",
       "3         9.83      10.0   0.0   0.0 -1.111110e+00  16.0934     0.0   85.2980   \n",
       "4         9.92      13.0   0.0   0.0 -1.111110e+00  16.0934     0.0   93.9449   \n",
       "5         9.68      14.0   0.0   0.0 -1.666670e+00  16.0934     0.0  101.9390   \n",
       "6         9.49      13.0   0.0   0.0 -1.666670e+00  16.0934     0.0  110.0920   \n",
       "7         8.91      15.0   0.0   0.0 -1.666670e+00  16.0934     1.0  119.0570   \n",
       "8         8.60      13.0   0.0   0.0 -1.666670e+00  16.0934     2.0  129.4920   \n",
       "9         9.00       9.0   0.0   0.0 -1.111110e+00  16.0934     2.0  142.0670   \n",
       "10        8.88       8.0   0.0   0.0  5.684340e-14  16.0934     2.0  157.2300   \n",
       "11        9.02       5.0   0.0   0.0  5.555560e-01  16.0934     1.0  174.6140   \n",
       "12        9.42     359.0   0.0   0.0  1.111110e+00  16.0934     2.0  192.6220   \n",
       "13        9.98     356.0   0.0   0.0  1.111110e+00  16.0934     2.0  209.2140   \n",
       "14        9.96     357.0   0.0   0.0  1.666670e+00  16.0934     2.0  223.2880   \n",
       "15       10.09     358.0   0.0   0.0  1.666670e+00  16.0934     1.0  234.8970   \n",
       "16       10.06     358.0   0.0   0.0  1.666670e+00  16.0934     0.0  244.6320   \n",
       "17        9.78       5.0   0.0   0.0  1.666670e+00  16.0934     0.0  253.1660   \n",
       "18        9.60       6.0   0.0   0.0  1.666670e+00  16.0934     0.0  261.1430   \n",
       "19        9.20       3.0   0.0   0.0  1.666670e+00  16.0934     0.0  269.2470   \n",
       "20        9.08       3.0   0.0   0.0  1.666670e+00  16.0934     0.0  278.4360   \n",
       "21        9.02       6.0   0.0   0.0  1.111110e+00  16.0934     0.0  290.5410   \n",
       "22        8.62       5.0   0.0   0.0  1.111110e+00  16.0934     0.0  309.9690   \n",
       "23        8.62       5.0   0.0   0.0  5.555560e-01  16.0934     0.0  345.8850   \n",
       "\n",
       "    elevation  \n",
       "0   -70.06400  \n",
       "1   -61.24170  \n",
       "2   -49.90780  \n",
       "3   -37.78870  \n",
       "4   -25.48450  \n",
       "5   -13.29710  \n",
       "6    -1.46727  \n",
       "7     9.72862  \n",
       "8    19.90720  \n",
       "9    28.50590  \n",
       "10   34.74430  \n",
       "11   37.74720  \n",
       "12   36.95290  \n",
       "13   32.52080  \n",
       "14   25.20440  \n",
       "15   15.87280  \n",
       "16    5.21813  \n",
       "17   -6.27970  \n",
       "18  -18.29090  \n",
       "19  -30.56450  \n",
       "20  -42.85350  \n",
       "21  -54.78710  \n",
       "22  -65.48630  \n",
       "23  -72.24230  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 본 코드는 python 3.10에서 테스트 되었습니다.\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "_API_URL = \"https://research-api.solarkim.com\"\n",
    "_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJRdWFXekxUYlVEVEV5cWhwaW9WM2o0IiwiaWF0IjoxNzAwMDk5MDQxLCJleHAiOjE3MDAyMzMyMDAsInR5cGUiOiJhcGlfa2V5In0.2MfkjWgqyo0p5BsCm3yl8XhxiB_tCLLsv2ncIW23Rww\" \n",
    "_AUTH_PARAM = {\"headers\": {\"Authorization\": f\"Bearer {_API_KEY}\"}}\n",
    "\n",
    "\n",
    "def _get(url: str, headers=None):\n",
    "    \"\"\"\n",
    "    주어진 url의 리소스를 조회한다.\n",
    "\n",
    "    Args:\n",
    "        url (str): API url\n",
    "    \"\"\"\n",
    "    response = requests.get(url, **_AUTH_PARAM)\n",
    "    return response.json()\n",
    "\n",
    "def _get_weathers_forecasts():\n",
    "    \"\"\"\n",
    "    기상데이터 일단위 기상예측 데이터 조회 (https://research-api.solarkim.com/docs#tag/Competition-2023/operation/get_weathers_forecasts_date_bid_round_cmpt_2023_weathers_forecasts__date___bid_round__get 참고)\n",
    "    \"\"\"\n",
    "    date = \"2023-11-11\"\n",
    "    bid_round_10 = 1\n",
    "\n",
    "    weather_fcst_10 = _get(\n",
    "        f\"{_API_URL}/cmpt-2023/weathers-forecasts/{date}/{bid_round_10}\", headers={\n",
    "                            'Authorization': f'Bearer {_API_KEY}'})\n",
    "\n",
    "    return weather_fcst_10  # 데이터를 반환\n",
    "\n",
    "# _get_weathers_forecasts 함수를 호출하여 데이터를 받아옴\n",
    "weather_fcst_10 = _get_weathers_forecasts()\n",
    "\n",
    "# weather_fcst_10을 데이터프레임으로 변환\n",
    "weather_fcst_10_df = pd.DataFrame(weather_fcst_10)\n",
    "\n",
    "# 데이터프레임 출력\n",
    "weather_fcst_10_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d82d7d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>model5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-10T16:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-10T17:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-10T18:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-10T19:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-10T20:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-11-10T21:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-11-10T22:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578613</td>\n",
       "      <td>0.190806</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.310970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-11-10T23:00:00+00:00</td>\n",
       "      <td>4.087120</td>\n",
       "      <td>12.593100</td>\n",
       "      <td>2.701040</td>\n",
       "      <td>3.41830</td>\n",
       "      <td>10.086400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-11-11T00:00:00+00:00</td>\n",
       "      <td>21.806500</td>\n",
       "      <td>31.438200</td>\n",
       "      <td>21.419800</td>\n",
       "      <td>30.62620</td>\n",
       "      <td>25.887700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-11-11T01:00:00+00:00</td>\n",
       "      <td>44.561000</td>\n",
       "      <td>47.028700</td>\n",
       "      <td>49.985000</td>\n",
       "      <td>58.25990</td>\n",
       "      <td>31.416100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-11-11T02:00:00+00:00</td>\n",
       "      <td>57.987700</td>\n",
       "      <td>58.941600</td>\n",
       "      <td>67.887100</td>\n",
       "      <td>70.62840</td>\n",
       "      <td>32.809600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-11-11T03:00:00+00:00</td>\n",
       "      <td>55.536700</td>\n",
       "      <td>55.143800</td>\n",
       "      <td>69.763900</td>\n",
       "      <td>70.39260</td>\n",
       "      <td>29.988100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-11-11T04:00:00+00:00</td>\n",
       "      <td>66.022800</td>\n",
       "      <td>66.232100</td>\n",
       "      <td>73.727000</td>\n",
       "      <td>67.86710</td>\n",
       "      <td>33.048300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-11-11T05:00:00+00:00</td>\n",
       "      <td>59.961400</td>\n",
       "      <td>62.038700</td>\n",
       "      <td>69.842300</td>\n",
       "      <td>63.69680</td>\n",
       "      <td>39.450700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-11-11T06:00:00+00:00</td>\n",
       "      <td>54.587300</td>\n",
       "      <td>54.084800</td>\n",
       "      <td>58.722500</td>\n",
       "      <td>53.54720</td>\n",
       "      <td>28.708100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-11-11T07:00:00+00:00</td>\n",
       "      <td>31.580100</td>\n",
       "      <td>28.071800</td>\n",
       "      <td>22.274100</td>\n",
       "      <td>32.35760</td>\n",
       "      <td>22.231800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-11-11T08:00:00+00:00</td>\n",
       "      <td>12.493900</td>\n",
       "      <td>11.192900</td>\n",
       "      <td>4.599420</td>\n",
       "      <td>9.01643</td>\n",
       "      <td>10.218700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-11-11T09:00:00+00:00</td>\n",
       "      <td>0.727951</td>\n",
       "      <td>2.716380</td>\n",
       "      <td>0.303629</td>\n",
       "      <td>5.67469</td>\n",
       "      <td>2.211520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-11-11T10:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106755</td>\n",
       "      <td>3.60557</td>\n",
       "      <td>0.695599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-11-11T11:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-11-11T12:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023-11-11T13:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-11-11T14:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-11-11T15:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time     model1     model2     model3    model4  \\\n",
       "0   2023-11-10T16:00:00+00:00   0.000000   0.000000   0.000000   0.00000   \n",
       "1   2023-11-10T17:00:00+00:00   0.000000   0.000000   0.000000   0.00000   \n",
       "2   2023-11-10T18:00:00+00:00   0.000000   0.000000   0.000000   0.00000   \n",
       "3   2023-11-10T19:00:00+00:00   0.000000   0.000000   0.000000   0.00000   \n",
       "4   2023-11-10T20:00:00+00:00   0.000000   0.000000   0.000000   0.00000   \n",
       "5   2023-11-10T21:00:00+00:00   0.000000   0.000000   0.000000   0.00000   \n",
       "6   2023-11-10T22:00:00+00:00   0.000000   0.578613   0.190806   0.00000   \n",
       "7   2023-11-10T23:00:00+00:00   4.087120  12.593100   2.701040   3.41830   \n",
       "8   2023-11-11T00:00:00+00:00  21.806500  31.438200  21.419800  30.62620   \n",
       "9   2023-11-11T01:00:00+00:00  44.561000  47.028700  49.985000  58.25990   \n",
       "10  2023-11-11T02:00:00+00:00  57.987700  58.941600  67.887100  70.62840   \n",
       "11  2023-11-11T03:00:00+00:00  55.536700  55.143800  69.763900  70.39260   \n",
       "12  2023-11-11T04:00:00+00:00  66.022800  66.232100  73.727000  67.86710   \n",
       "13  2023-11-11T05:00:00+00:00  59.961400  62.038700  69.842300  63.69680   \n",
       "14  2023-11-11T06:00:00+00:00  54.587300  54.084800  58.722500  53.54720   \n",
       "15  2023-11-11T07:00:00+00:00  31.580100  28.071800  22.274100  32.35760   \n",
       "16  2023-11-11T08:00:00+00:00  12.493900  11.192900   4.599420   9.01643   \n",
       "17  2023-11-11T09:00:00+00:00   0.727951   2.716380   0.303629   5.67469   \n",
       "18  2023-11-11T10:00:00+00:00   0.000000   0.000000   0.106755   3.60557   \n",
       "19  2023-11-11T11:00:00+00:00   0.000000   0.000000   0.000000   0.00000   \n",
       "20  2023-11-11T12:00:00+00:00   0.000000   0.000000   0.000000   0.00000   \n",
       "21  2023-11-11T13:00:00+00:00   0.000000   0.000000   0.000000   0.00000   \n",
       "22  2023-11-11T14:00:00+00:00   0.000000   0.000000   0.000000   0.00000   \n",
       "23  2023-11-11T15:00:00+00:00   0.000000   0.000000   0.000000   0.00000   \n",
       "\n",
       "       model5  \n",
       "0    0.000000  \n",
       "1    0.000000  \n",
       "2    0.000000  \n",
       "3    0.000000  \n",
       "4    0.000000  \n",
       "5    0.000000  \n",
       "6    7.310970  \n",
       "7   10.086400  \n",
       "8   25.887700  \n",
       "9   31.416100  \n",
       "10  32.809600  \n",
       "11  29.988100  \n",
       "12  33.048300  \n",
       "13  39.450700  \n",
       "14  28.708100  \n",
       "15  22.231800  \n",
       "16  10.218700  \n",
       "17   2.211520  \n",
       "18   0.695599  \n",
       "19   0.000000  \n",
       "20   0.000000  \n",
       "21   0.000000  \n",
       "22   0.000000  \n",
       "23   0.000000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _get_gen_forecasts():\n",
    "    \"\"\"\n",
    "    더쉐어 예측 모델의 예측 발전량 조회, 입찰대상일의 5가지 예측 모델의 예측 발전량 값을 취득한다 (https://research-api.solarkim.com/docs#tag/Competition-2023/operation/get_gen_forecasts_date_cmpt_2023_gen_forecasts__date___bid_round__get 참고)\n",
    "    \"\"\"\n",
    "    date = \"2023-11-11\"\n",
    "    bid_round_10 = 1\n",
    "\n",
    "    gen_fcst_10 = _get(f\"{_API_URL}/cmpt-2023/gen-forecasts/{date}/{bid_round_10}\", headers={\n",
    "                            'Authorization': f'Bearer {_API_KEY}'})\n",
    "\n",
    "    return gen_fcst_10   # 데이터를 반환ㅇㅇ\n",
    "gen_fcst_10 = _get_gen_forecasts()\n",
    "# gen_fcst_10 데이터프레임으로 변환\n",
    "gen_fcst_10_df = pd.DataFrame(gen_fcst_10)\n",
    "\n",
    "gen_fcst_10_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f27f86ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cloud</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>ground_press</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>vis</th>\n",
       "      <th>uv_idx</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>elevation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-10T16:00:00+00:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>7.23</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>10.26</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.555560e-01</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.8725</td>\n",
       "      <td>-70.06400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-10T17:00:00+00:00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>7.02</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>9.82</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.555560e-01</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.9142</td>\n",
       "      <td>-61.24170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-10T18:00:00+00:00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.555560e-01</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.6309</td>\n",
       "      <td>-49.90780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-10T19:00:00+00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.73</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>9.83</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.111110e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.2980</td>\n",
       "      <td>-37.78870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-10T20:00:00+00:00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6.66</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>9.82</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.111110e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.9449</td>\n",
       "      <td>-25.48450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-11-10T21:00:00+00:00</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.53</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>9.49</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.9390</td>\n",
       "      <td>-13.29710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-11-10T22:00:00+00:00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>8.80</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0920</td>\n",
       "      <td>-1.46727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-11-10T23:00:00+00:00</td>\n",
       "      <td>46.0</td>\n",
       "      <td>6.65</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>8.34</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.0570</td>\n",
       "      <td>9.72862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-11-11T00:00:00+00:00</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.14</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>8.34</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.4920</td>\n",
       "      <td>19.90720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-11-11T01:00:00+00:00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.83</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.111110e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>2.0</td>\n",
       "      <td>142.0670</td>\n",
       "      <td>28.50590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-11-11T02:00:00+00:00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.55</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>8.36</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.684340e-14</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>2.0</td>\n",
       "      <td>157.2300</td>\n",
       "      <td>34.74430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-11-11T03:00:00+00:00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.15</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>8.22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.555560e-01</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>1.0</td>\n",
       "      <td>174.6140</td>\n",
       "      <td>37.74720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-11-11T04:00:00+00:00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.74</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>8.66</td>\n",
       "      <td>358.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.111110e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>2.0</td>\n",
       "      <td>192.6220</td>\n",
       "      <td>36.95290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-11-11T05:00:00+00:00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.06</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>9.61</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.111110e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>2.0</td>\n",
       "      <td>209.2140</td>\n",
       "      <td>32.52080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-11-11T06:00:00+00:00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.09</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>9.54</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>2.0</td>\n",
       "      <td>223.2880</td>\n",
       "      <td>25.20440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-11-11T07:00:00+00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>9.98</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>10.28</td>\n",
       "      <td>349.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>1.0</td>\n",
       "      <td>234.8970</td>\n",
       "      <td>15.87280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-11-11T08:00:00+00:00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>9.60</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>10.57</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>244.6320</td>\n",
       "      <td>5.21813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-11-11T09:00:00+00:00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.63</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>10.91</td>\n",
       "      <td>352.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253.1660</td>\n",
       "      <td>-6.27970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-11-11T10:00:00+00:00</td>\n",
       "      <td>85.0</td>\n",
       "      <td>9.75</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>9.98</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.1430</td>\n",
       "      <td>-18.29090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-11-11T11:00:00+00:00</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9.73</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>10.03</td>\n",
       "      <td>358.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>269.2470</td>\n",
       "      <td>-30.56450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-11-11T12:00:00+00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>9.74</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>10.22</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666670e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278.4360</td>\n",
       "      <td>-42.85350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023-11-11T13:00:00+00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.64</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>9.83</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.111110e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290.5410</td>\n",
       "      <td>-54.78710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-11-11T14:00:00+00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>10.15</td>\n",
       "      <td>355.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.111110e+00</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>309.9690</td>\n",
       "      <td>-65.48630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-11-11T15:00:00+00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.11</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>9.91</td>\n",
       "      <td>359.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.555560e-01</td>\n",
       "      <td>16.0934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>345.8850</td>\n",
       "      <td>-72.24230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time  cloud   temp  humidity  ground_press  \\\n",
       "0   2023-11-10T16:00:00+00:00   97.0   7.23      64.0        1027.0   \n",
       "1   2023-11-10T17:00:00+00:00   98.0   7.02      65.0        1028.0   \n",
       "2   2023-11-10T18:00:00+00:00   98.0   6.80      65.0        1027.0   \n",
       "3   2023-11-10T19:00:00+00:00   52.0   6.73      66.0        1028.0   \n",
       "4   2023-11-10T20:00:00+00:00   70.0   6.66      66.0        1028.0   \n",
       "5   2023-11-10T21:00:00+00:00   59.0   6.53      67.0        1028.0   \n",
       "6   2023-11-10T22:00:00+00:00   48.0   6.44      67.0        1029.0   \n",
       "7   2023-11-10T23:00:00+00:00   46.0   6.65      67.0        1029.0   \n",
       "8   2023-11-11T00:00:00+00:00   47.0   7.14      66.0        1029.0   \n",
       "9   2023-11-11T01:00:00+00:00   24.0   7.83      65.0        1029.0   \n",
       "10  2023-11-11T02:00:00+00:00   21.0   8.55      64.0        1029.0   \n",
       "11  2023-11-11T03:00:00+00:00   22.0   9.15      63.0        1028.0   \n",
       "12  2023-11-11T04:00:00+00:00   24.0   9.74      61.0        1027.0   \n",
       "13  2023-11-11T05:00:00+00:00   25.0  10.06      61.0        1027.0   \n",
       "14  2023-11-11T06:00:00+00:00   26.0  10.09      61.0        1027.0   \n",
       "15  2023-11-11T07:00:00+00:00   52.0   9.98      64.0        1027.0   \n",
       "16  2023-11-11T08:00:00+00:00   70.0   9.60      66.0        1027.0   \n",
       "17  2023-11-11T09:00:00+00:00   80.0   9.63      65.0        1027.0   \n",
       "18  2023-11-11T10:00:00+00:00   85.0   9.75      64.0        1028.0   \n",
       "19  2023-11-11T11:00:00+00:00   88.0   9.73      63.0        1028.0   \n",
       "20  2023-11-11T12:00:00+00:00   90.0   9.74      63.0        1028.0   \n",
       "21  2023-11-11T13:00:00+00:00  100.0   9.64      62.0        1028.0   \n",
       "22  2023-11-11T14:00:00+00:00  100.0   9.45      63.0        1028.0   \n",
       "23  2023-11-11T15:00:00+00:00  100.0   9.11      64.0        1027.0   \n",
       "\n",
       "    wind_speed  wind_dir  rain  snow     dew_point      vis  uv_idx   azimuth  \\\n",
       "0        10.26      11.0   0.0   0.0 -5.555560e-01  16.0934     0.0   30.8725   \n",
       "1         9.82      11.0   0.0   0.0 -5.555560e-01  16.0934     0.0   58.9142   \n",
       "2        10.00      10.0   0.0   0.0 -5.555560e-01  16.0934     0.0   74.6309   \n",
       "3         9.83      12.0   0.0   0.0 -1.111110e+00  16.0934     0.0   85.2980   \n",
       "4         9.82      13.0   0.0   0.0 -1.111110e+00  16.0934     0.0   93.9449   \n",
       "5         9.49      15.0   0.0   0.0 -1.666670e+00  16.0934     0.0  101.9390   \n",
       "6         8.80      15.0   0.0   0.0 -1.666670e+00  16.0934     0.0  110.0920   \n",
       "7         8.34      18.0   0.0   0.0 -1.666670e+00  16.0934     1.0  119.0570   \n",
       "8         8.34      18.0   0.0   0.0 -1.666670e+00  16.0934     2.0  129.4920   \n",
       "9         8.13      16.0   0.0   0.0 -1.111110e+00  16.0934     2.0  142.0670   \n",
       "10        8.36      10.0   0.0   0.0  5.684340e-14  16.0934     2.0  157.2300   \n",
       "11        8.22       2.0   0.0   0.0  5.555560e-01  16.0934     1.0  174.6140   \n",
       "12        8.66     358.0   0.0   0.0  1.111110e+00  16.0934     2.0  192.6220   \n",
       "13        9.61     354.0   0.0   0.0  1.111110e+00  16.0934     2.0  209.2140   \n",
       "14        9.54     353.0   0.0   0.0  1.666670e+00  16.0934     2.0  223.2880   \n",
       "15       10.28     349.0   0.0   0.0  1.666670e+00  16.0934     1.0  234.8970   \n",
       "16       10.57     350.0   0.0   0.0  1.666670e+00  16.0934     0.0  244.6320   \n",
       "17       10.91     352.0   0.0   0.0  1.666670e+00  16.0934     0.0  253.1660   \n",
       "18        9.98     356.0   0.0   0.0  1.666670e+00  16.0934     0.0  261.1430   \n",
       "19       10.03     358.0   0.0   0.0  1.666670e+00  16.0934     0.0  269.2470   \n",
       "20       10.22     356.0   0.0   0.0  1.666670e+00  16.0934     0.0  278.4360   \n",
       "21        9.83     353.0   0.0   0.0  1.111110e+00  16.0934     0.0  290.5410   \n",
       "22       10.15     355.0   0.0   0.0  1.111110e+00  16.0934     0.0  309.9690   \n",
       "23        9.91     359.0   0.0   0.0  5.555560e-01  16.0934     0.0  345.8850   \n",
       "\n",
       "    elevation  \n",
       "0   -70.06400  \n",
       "1   -61.24170  \n",
       "2   -49.90780  \n",
       "3   -37.78870  \n",
       "4   -25.48450  \n",
       "5   -13.29710  \n",
       "6    -1.46727  \n",
       "7     9.72862  \n",
       "8    19.90720  \n",
       "9    28.50590  \n",
       "10   34.74430  \n",
       "11   37.74720  \n",
       "12   36.95290  \n",
       "13   32.52080  \n",
       "14   25.20440  \n",
       "15   15.87280  \n",
       "16    5.21813  \n",
       "17   -6.27970  \n",
       "18  -18.29090  \n",
       "19  -30.56450  \n",
       "20  -42.85350  \n",
       "21  -54.78710  \n",
       "22  -65.48630  \n",
       "23  -72.24230  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 본 코드는 python 3.10에서 테스트 되었습니다.\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "_API_URL = \"https://research-api.solarkim.com\"\n",
    "_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJRdWFXekxUYlVEVEV5cWhwaW9WM2o0IiwiaWF0IjoxNzAwMDk5MDQxLCJleHAiOjE3MDAyMzMyMDAsInR5cGUiOiJhcGlfa2V5In0.2MfkjWgqyo0p5BsCm3yl8XhxiB_tCLLsv2ncIW23Rww\" \n",
    "_AUTH_PARAM = {\"headers\": {\"Authorization\": f\"Bearer {_API_KEY}\"}}\n",
    "\n",
    "\n",
    "def _get(url: str, headers=None):\n",
    "    \"\"\"\n",
    "    주어진 url의 리소스를 조회한다.\n",
    "\n",
    "    Args:\n",
    "        url (str): API url\n",
    "    \"\"\"\n",
    "    response = requests.get(url, **_AUTH_PARAM)\n",
    "    return response.json()\n",
    "\n",
    "def _get_weathers_forecasts():\n",
    "    \"\"\"\n",
    "    기상데이터 일단위 기상예측 데이터 조회 (https://research-api.solarkim.com/docs#tag/Competition-2023/operation/get_weathers_forecasts_date_bid_round_cmpt_2023_weathers_forecasts__date___bid_round__get 참고)\n",
    "    \"\"\"\n",
    "    date = \"2023-11-11\"\n",
    "    bid_round_17 = 2\n",
    "\n",
    "    weather_fcst_17 = _get(\n",
    "        f\"{_API_URL}/cmpt-2023/weathers-forecasts/{date}/{bid_round_17}\", headers={\n",
    "                            'Authorization': f'Bearer {_API_KEY}'})\n",
    "\n",
    "    return weather_fcst_17  # 데이터를 반환\n",
    "\n",
    "# _get_weathers_forecasts 함수를 호출하여 데이터를 받아옴\n",
    "weather_fcst_17 = _get_weathers_forecasts()\n",
    "\n",
    "# weather_fcst_17을 데이터프레임으로 변환\n",
    "weather_fcst_17_df = pd.DataFrame(weather_fcst_17)\n",
    "\n",
    "# 데이터프레임 출력\n",
    "display(weather_fcst_17_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "328e1ad0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>model5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-10T16:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-10T17:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-10T18:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-10T19:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-10T20:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-11-10T21:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-11-10T22:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.064465</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>13.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-11-10T23:00:00+00:00</td>\n",
       "      <td>3.972810</td>\n",
       "      <td>9.90838</td>\n",
       "      <td>3.837710</td>\n",
       "      <td>2.53614</td>\n",
       "      <td>17.8002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-11-11T00:00:00+00:00</td>\n",
       "      <td>21.604900</td>\n",
       "      <td>28.06460</td>\n",
       "      <td>29.369200</td>\n",
       "      <td>18.27420</td>\n",
       "      <td>34.6438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-11-11T01:00:00+00:00</td>\n",
       "      <td>44.180200</td>\n",
       "      <td>46.52180</td>\n",
       "      <td>61.570500</td>\n",
       "      <td>45.93740</td>\n",
       "      <td>40.4068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-11-11T02:00:00+00:00</td>\n",
       "      <td>60.956100</td>\n",
       "      <td>61.09760</td>\n",
       "      <td>77.874700</td>\n",
       "      <td>69.01780</td>\n",
       "      <td>41.5373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-11-11T03:00:00+00:00</td>\n",
       "      <td>62.071600</td>\n",
       "      <td>59.91300</td>\n",
       "      <td>75.887500</td>\n",
       "      <td>80.99910</td>\n",
       "      <td>39.7018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-11-11T04:00:00+00:00</td>\n",
       "      <td>69.392500</td>\n",
       "      <td>71.47290</td>\n",
       "      <td>82.453800</td>\n",
       "      <td>75.10500</td>\n",
       "      <td>50.1564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-11-11T05:00:00+00:00</td>\n",
       "      <td>63.777600</td>\n",
       "      <td>65.72240</td>\n",
       "      <td>76.072600</td>\n",
       "      <td>67.61990</td>\n",
       "      <td>53.8515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-11-11T06:00:00+00:00</td>\n",
       "      <td>56.289000</td>\n",
       "      <td>57.09770</td>\n",
       "      <td>64.703400</td>\n",
       "      <td>54.81880</td>\n",
       "      <td>45.0412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-11-11T07:00:00+00:00</td>\n",
       "      <td>35.829600</td>\n",
       "      <td>31.66150</td>\n",
       "      <td>31.928100</td>\n",
       "      <td>30.80550</td>\n",
       "      <td>38.8325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-11-11T08:00:00+00:00</td>\n",
       "      <td>10.018300</td>\n",
       "      <td>8.81493</td>\n",
       "      <td>8.509800</td>\n",
       "      <td>9.22882</td>\n",
       "      <td>25.7944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-11-11T09:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.57499</td>\n",
       "      <td>0.101610</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>17.4069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-11-11T10:00:00+00:00</td>\n",
       "      <td>0.147353</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>16.2542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-11-11T11:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-11-11T12:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023-11-11T13:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-11-11T14:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-11-11T15:00:00+00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time     model1    model2     model3    model4  \\\n",
       "0   2023-11-10T16:00:00+00:00   0.000000   0.00000   0.000000   0.00000   \n",
       "1   2023-11-10T17:00:00+00:00   0.000000   0.00000   0.000000   0.00000   \n",
       "2   2023-11-10T18:00:00+00:00   0.000000   0.00000   0.000000   0.00000   \n",
       "3   2023-11-10T19:00:00+00:00   0.000000   0.00000   0.000000   0.00000   \n",
       "4   2023-11-10T20:00:00+00:00   0.000000   0.00000   0.000000   0.00000   \n",
       "5   2023-11-10T21:00:00+00:00   0.000000   0.00000   0.000000   0.00000   \n",
       "6   2023-11-10T22:00:00+00:00   0.000000   0.00000   0.064465   0.00000   \n",
       "7   2023-11-10T23:00:00+00:00   3.972810   9.90838   3.837710   2.53614   \n",
       "8   2023-11-11T00:00:00+00:00  21.604900  28.06460  29.369200  18.27420   \n",
       "9   2023-11-11T01:00:00+00:00  44.180200  46.52180  61.570500  45.93740   \n",
       "10  2023-11-11T02:00:00+00:00  60.956100  61.09760  77.874700  69.01780   \n",
       "11  2023-11-11T03:00:00+00:00  62.071600  59.91300  75.887500  80.99910   \n",
       "12  2023-11-11T04:00:00+00:00  69.392500  71.47290  82.453800  75.10500   \n",
       "13  2023-11-11T05:00:00+00:00  63.777600  65.72240  76.072600  67.61990   \n",
       "14  2023-11-11T06:00:00+00:00  56.289000  57.09770  64.703400  54.81880   \n",
       "15  2023-11-11T07:00:00+00:00  35.829600  31.66150  31.928100  30.80550   \n",
       "16  2023-11-11T08:00:00+00:00  10.018300   8.81493   8.509800   9.22882   \n",
       "17  2023-11-11T09:00:00+00:00   0.000000   1.57499   0.101610   0.00000   \n",
       "18  2023-11-11T10:00:00+00:00   0.147353   0.00000   0.000000   0.00000   \n",
       "19  2023-11-11T11:00:00+00:00   0.000000   0.00000   0.000000   0.00000   \n",
       "20  2023-11-11T12:00:00+00:00   0.000000   0.00000   0.000000   0.00000   \n",
       "21  2023-11-11T13:00:00+00:00   0.000000   0.00000   0.000000   0.00000   \n",
       "22  2023-11-11T14:00:00+00:00   0.000000   0.00000   0.000000   0.00000   \n",
       "23  2023-11-11T15:00:00+00:00   0.000000   0.00000   0.000000   0.00000   \n",
       "\n",
       "     model5  \n",
       "0    0.0000  \n",
       "1    0.0000  \n",
       "2    0.0000  \n",
       "3    0.0000  \n",
       "4    0.0000  \n",
       "5    0.0000  \n",
       "6   13.9997  \n",
       "7   17.8002  \n",
       "8   34.6438  \n",
       "9   40.4068  \n",
       "10  41.5373  \n",
       "11  39.7018  \n",
       "12  50.1564  \n",
       "13  53.8515  \n",
       "14  45.0412  \n",
       "15  38.8325  \n",
       "16  25.7944  \n",
       "17  17.4069  \n",
       "18  16.2542  \n",
       "19   0.0000  \n",
       "20   0.0000  \n",
       "21   0.0000  \n",
       "22   0.0000  \n",
       "23   0.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def _get_gen_forecasts():\n",
    "    \"\"\"\n",
    "    더쉐어 예측 모델의 예측 발전량 조회, 입찰대상일의 5가지 예측 모델의 예측 발전량 값을 취득한다 (https://research-api.solarkim.com/docs#tag/Competition-2023/operation/get_gen_forecasts_date_cmpt_2023_gen_forecasts__date___bid_round__get 참고)\n",
    "    \"\"\"\n",
    "    date = \"2023-11-11\"\n",
    "    bid_round_17 = 2\n",
    "\n",
    "    gen_fcst_17 = _get(f\"{_API_URL}/cmpt-2023/gen-forecasts/{date}/{bid_round_17}\", headers={\n",
    "                            'Authorization': f'Bearer {_API_KEY}'})\n",
    "    return gen_fcst_17   # 데이터를 반환\n",
    "gen_fcst_17 = _get_gen_forecasts()\n",
    "\n",
    "# gen_fcst_17 데이터프레임으로 변환\n",
    "gen_fcst_17_df = pd.DataFrame(gen_fcst_17)\n",
    "\n",
    "display(gen_fcst_17_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d60a146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_values_5_1 = [0,0,0,0,0,0,0,2,16,18,16,16,10,6,4,8,4,2,0,0,0,0,0,0]\n",
    "actual_values_11_1 = [0,0,0,0,0,0,0,4,23,55,65,54,53,66,49,23, 17, 0,0,0,0,0,0,0]\n",
    "actual_values_10_1 = [0, 0, 0, 0, 0, 0, 0,2, 18, 50, 46, 60, 39, 40, 44, 23, 17, 11, 6, 0, 0, 0, 0, 0]\n",
    "actual_values_12_1 = [0,0,0,0,0,0,0,2,25,48,52,38,31,34,34,23,6,0,0,0,0,0,0,0]\n",
    "actual_values_13 = [0, 0, 0, 0, 0, 0, 0,5, 33, 53, 79, 81, 56, 82, 38, 42, 22, 1, 0, 0, 0, 0, 0, 0]\n",
    "actual_values_14 = [0, 0, 0, 0, 0, 0, 0,3, 16, 16, 17, 23, 18, 16, 36, 38, 14, 0, 0, 0, 0, 0, 0, 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c8ca9e",
   "metadata": {},
   "source": [
    "# 테스트 셋 군집 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e040c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_fcst_10_df_7 = weather_fcst_10_df.iloc[[6]]\n",
    "weather_fcst_10_df_8 = weather_fcst_10_df.iloc[[7]]\n",
    "weather_fcst_10_df_9 = weather_fcst_10_df.iloc[[8]]\n",
    "weather_fcst_10_df_10 = weather_fcst_10_df.iloc[[9]]\n",
    "weather_fcst_10_df_11 = weather_fcst_10_df.iloc[[10]]\n",
    "weather_fcst_10_df_12 = weather_fcst_10_df.iloc[[11]]\n",
    "weather_fcst_10_df_13 = weather_fcst_10_df.iloc[[12]]\n",
    "weather_fcst_10_df_14 = weather_fcst_10_df.iloc[[13]]\n",
    "weather_fcst_10_df_15 = weather_fcst_10_df.iloc[[14]]\n",
    "weather_fcst_10_df_16 = weather_fcst_10_df.iloc[[15]]\n",
    "weather_fcst_10_df_17 = weather_fcst_10_df.iloc[[16]]\n",
    "weather_fcst_10_df_18 = weather_fcst_10_df.iloc[[17]]\n",
    "weather_fcst_10_df_19 = weather_fcst_10_df.iloc[[18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "109e99e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_fcst_10_df.drop('time',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "833e81d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_fcst_10_df_7 = gen_fcst_10_df.iloc[[6]]\n",
    "gen_fcst_10_df_8 = gen_fcst_10_df.iloc[[7]]\n",
    "gen_fcst_10_df_9 = gen_fcst_10_df.iloc[[8]]\n",
    "gen_fcst_10_df_10 = gen_fcst_10_df.iloc[[9]]\n",
    "gen_fcst_10_df_11 = gen_fcst_10_df.iloc[[10]]\n",
    "gen_fcst_10_df_12 = gen_fcst_10_df.iloc[[11]]\n",
    "gen_fcst_10_df_13 = gen_fcst_10_df.iloc[[12]]\n",
    "gen_fcst_10_df_14 = gen_fcst_10_df.iloc[[13]]\n",
    "gen_fcst_10_df_15 = gen_fcst_10_df.iloc[[14]]\n",
    "gen_fcst_10_df_16 = gen_fcst_10_df.iloc[[15]]\n",
    "gen_fcst_10_df_17 = gen_fcst_10_df.iloc[[16]]\n",
    "gen_fcst_10_df_18 = gen_fcst_10_df.iloc[[17]]\n",
    "gen_fcst_10_df_19 = gen_fcst_10_df.iloc[[18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c928079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "1    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "2    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "0    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "1    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "0    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "1    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "1    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "1    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "2    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "2    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "1    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "1    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "0    1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-52-e23e32fd9d52>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_10_df_7['Cluster'] = kmeans_7.predict(weather_fcst_10_df_7_data)\n",
      "<ipython-input-52-e23e32fd9d52>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_10_df_8['Cluster'] = kmeans_8.predict(weather_fcst_10_df_8_data)\n",
      "<ipython-input-52-e23e32fd9d52>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_10_df_9['Cluster'] = kmeans_9.predict(weather_fcst_10_df_9_data)\n",
      "<ipython-input-52-e23e32fd9d52>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_10_df_10['Cluster'] = kmeans_10.predict(weather_fcst_10_df_10_data)\n",
      "<ipython-input-52-e23e32fd9d52>:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_10_df_11['Cluster'] = kmeans_11.predict(weather_fcst_10_df_11_data)\n",
      "<ipython-input-52-e23e32fd9d52>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_10_df_12['Cluster'] = kmeans_12.predict(weather_fcst_10_df_12_data)\n",
      "<ipython-input-52-e23e32fd9d52>:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_10_df_13['Cluster'] = kmeans_10.predict(weather_fcst_10_df_13_data)\n",
      "<ipython-input-52-e23e32fd9d52>:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_10_df_14['Cluster'] = kmeans_14.predict(weather_fcst_10_df_14_data)\n",
      "<ipython-input-52-e23e32fd9d52>:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_10_df_15['Cluster'] = kmeans_15.predict(weather_fcst_10_df_15_data)\n",
      "<ipython-input-52-e23e32fd9d52>:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_10_df_16['Cluster'] = kmeans_16.predict(weather_fcst_10_df_16_data)\n",
      "<ipython-input-52-e23e32fd9d52>:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_10_df_17['Cluster'] = kmeans_17.predict(weather_fcst_10_df_17_data)\n",
      "<ipython-input-52-e23e32fd9d52>:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_10_df_18['Cluster'] = kmeans_18.predict(weather_fcst_10_df_18_data)\n",
      "<ipython-input-52-e23e32fd9d52>:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_10_df_19['Cluster'] = kmeans_19.predict(weather_fcst_10_df_19_data)\n"
     ]
    }
   ],
   "source": [
    "# 필요한 특성 선택 (features 리스트를 merged_data_combined_12r 데이터와 동일하게 설정)\n",
    "weather_fcst_10_features = ['cloud', 'temp', 'humidity', 'ground_press',\n",
    "                            'wind_speed', 'wind_dir', 'rain', 'snow', 'dew_point',\n",
    "                            'vis', 'uv_idx', 'azimuth', 'elevation']\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_10_df_7_data = scaler_7.transform(weather_fcst_10_df_7[weather_fcst_10_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_10_df_7['Cluster'] = kmeans_7.predict(weather_fcst_10_df_7_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_10_df_7['Cluster'].value_counts())\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_10_df_8_data = scaler_8.transform(weather_fcst_10_df_8[weather_fcst_10_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_10_df_8['Cluster'] = kmeans_8.predict(weather_fcst_10_df_8_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_10_df_8['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_10_df_9_data = scaler_9.transform(weather_fcst_10_df_9[weather_fcst_10_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_10_df_9['Cluster'] = kmeans_9.predict(weather_fcst_10_df_9_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_10_df_9['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_10_df_10_data = scaler_10.transform(weather_fcst_10_df_10[weather_fcst_10_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_10_df_10['Cluster'] = kmeans_10.predict(weather_fcst_10_df_10_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_10_df_10['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_10_df_11_data = scaler_11.transform(weather_fcst_10_df_11[weather_fcst_10_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_10_df_11['Cluster'] = kmeans_11.predict(weather_fcst_10_df_11_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_10_df_11['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_10_df_12_data = scaler_12.transform(weather_fcst_10_df_12[weather_fcst_10_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_10_df_12['Cluster'] = kmeans_12.predict(weather_fcst_10_df_12_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_10_df_12['Cluster'].value_counts())\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_10_df_13_data = scaler_13.transform(weather_fcst_10_df_13[weather_fcst_10_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_10_df_13['Cluster'] = kmeans_10.predict(weather_fcst_10_df_13_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_10_df_13['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_10_df_14_data = scaler_14.transform(weather_fcst_10_df_14[weather_fcst_10_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_10_df_14['Cluster'] = kmeans_14.predict(weather_fcst_10_df_14_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_10_df_14['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_10_df_15_data = scaler_15.transform(weather_fcst_10_df_15[weather_fcst_10_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_10_df_15['Cluster'] = kmeans_15.predict(weather_fcst_10_df_15_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_10_df_15['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_10_df_16_data = scaler_16.transform(weather_fcst_10_df_16[weather_fcst_10_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_10_df_16['Cluster'] = kmeans_16.predict(weather_fcst_10_df_16_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_10_df_16['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_10_df_17_data = scaler_17.transform(weather_fcst_10_df_17[weather_fcst_10_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_10_df_17['Cluster'] = kmeans_17.predict(weather_fcst_10_df_17_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_10_df_17['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_10_df_18_data = scaler_18.transform(weather_fcst_10_df_18[weather_fcst_10_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_10_df_18['Cluster'] = kmeans_18.predict(weather_fcst_10_df_18_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_10_df_18['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_10_df_19_data = scaler_19.transform(weather_fcst_10_df_19[weather_fcst_10_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_10_df_19['Cluster'] = kmeans_19.predict(weather_fcst_10_df_19_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_10_df_19['Cluster'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff90d55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions_test_7 = stacking_model_7_1.predict(gen_fcst_10_df_7)\n",
    "predictions_test_7 = np.clip(predictions_test_7, 0, None)\n",
    "\n",
    "predictions_test_8 = stacking_model_8_0.predict(gen_fcst_10_df_8)\n",
    "predictions_test_8 = np.clip(predictions_test_8, 0, None)\n",
    "\n",
    "predictions_test_9 = stacking_model_9_2.predict(gen_fcst_10_df_9)\n",
    "predictions_test_9 = np.clip(predictions_test_9, 0, None)\n",
    "\n",
    "predictions_test_10 = stacking_model_10_1.predict(gen_fcst_10_df_10)\n",
    "predictions_test_10 = np.clip(predictions_test_10, 0, None)\n",
    "\n",
    "predictions_test_11 = stacking_model_11_2.predict(gen_fcst_10_df_11)\n",
    "predictions_test_11 = np.clip(predictions_test_11, 0, None)\n",
    "\n",
    "predictions_test_12 = stacking_model_12_1.predict(gen_fcst_10_df_12)\n",
    "predictions_test_12 = np.clip(predictions_test_12, 0, None)\n",
    "\n",
    "predictions_test_13 = stacking_model_13_1.predict(gen_fcst_10_df_13)\n",
    "predictions_test_13 = np.clip(predictions_test_13, 0, None)\n",
    "\n",
    "predictions_test_14 = stacking_model_14_1.predict(gen_fcst_10_df_14)\n",
    "predictions_test_14 = np.clip(predictions_test_14, 0, None)\n",
    "\n",
    "predictions_test_15 = stacking_model_15_1.predict(gen_fcst_10_df_15)\n",
    "predictions_test_15 = np.clip(predictions_test_15, 0, None)\n",
    "\n",
    "predictions_test_16 = stacking_model_16_2.predict(gen_fcst_10_df_16)\n",
    "predictions_test_16 = np.clip(predictions_test_16, 0, None)\n",
    "\n",
    "predictions_test_17 = stacking_model_17_1.predict(gen_fcst_10_df_17)\n",
    "predictions_test_17 = np.clip(predictions_test_17, 0, None)\n",
    "\n",
    "predictions_test_18 = stacking_model_18_1.predict(gen_fcst_10_df_18)\n",
    "predictions_test_18 = np.clip(predictions_test_18, 0, None)\n",
    "\n",
    "predictions_test_19 = stacking_model_19_1.predict(gen_fcst_10_df_19)\n",
    "predictions_test_19 = np.clip(predictions_test_19, 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2684dafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " array([0.06702933]),\n",
       " array([2.80649156]),\n",
       " array([22.0437184]),\n",
       " array([49.22226653]),\n",
       " array([59.74120634]),\n",
       " array([59.78614276]),\n",
       " array([64.79342967]),\n",
       " array([66.32328188]),\n",
       " array([53.36096841]),\n",
       " array([32.5637586]),\n",
       " array([12.44101792]),\n",
       " array([1.13721734]),\n",
       " array([0.]),\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0,0,0,0,0,0,predictions_test_7,predictions_test_8,predictions_test_9,\n",
    "predictions_test_10,predictions_test_11,predictions_test_12,predictions_test_13,\n",
    "predictions_test_14,predictions_test_15,predictions_test_16,predictions_test_17,\n",
    "predictions_test_18,predictions_test_19,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a3ab765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0.06702933, 2.80649156, 22.0437184, 49.22226653, 59.74120634, 59.78614276, 64.79342967, 66.32328188, 53.36096841, 32.5637586, 12.44101792, 1.13721734, 0.0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "original_list = [0,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " np.array([0.06702933]),\n",
    " np.array([2.80649156]),\n",
    " np.array([22.0437184]),\n",
    " np.array([49.22226653]),\n",
    " np.array([59.74120634]),\n",
    " np.array([59.78614276]),\n",
    " np.array([64.79342967]),\n",
    " np.array([66.32328188]),\n",
    " np.array([53.36096841]),\n",
    " np.array([32.5637586]),\n",
    " np.array([12.44101792]),\n",
    " np.array([1.13721734]),\n",
    " np.array([0.]),\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 0]\n",
    "\n",
    "# Extract values from arrays and remove 'array' wrapper\n",
    "new_list = [x.item() if isinstance(x, np.ndarray) else x for x in original_list]\n",
    "\n",
    "print(new_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122658be",
   "metadata": {},
   "source": [
    "# 17시거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3024e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_fcst_17_df_7 = weather_fcst_17_df.iloc[[6]]\n",
    "weather_fcst_17_df_8 = weather_fcst_17_df.iloc[[7]]\n",
    "weather_fcst_17_df_9 = weather_fcst_17_df.iloc[[8]]\n",
    "weather_fcst_17_df_10 = weather_fcst_17_df.iloc[[9]]\n",
    "weather_fcst_17_df_11 = weather_fcst_17_df.iloc[[10]]\n",
    "weather_fcst_17_df_12 = weather_fcst_17_df.iloc[[11]]\n",
    "weather_fcst_17_df_13 = weather_fcst_17_df.iloc[[12]]\n",
    "weather_fcst_17_df_14 = weather_fcst_17_df.iloc[[13]]\n",
    "weather_fcst_17_df_15 = weather_fcst_17_df.iloc[[14]]\n",
    "weather_fcst_17_df_16 = weather_fcst_17_df.iloc[[15]]\n",
    "weather_fcst_17_df_17 = weather_fcst_17_df.iloc[[16]]\n",
    "weather_fcst_17_df_18 = weather_fcst_17_df.iloc[[17]]\n",
    "weather_fcst_17_df_19 = weather_fcst_17_df.iloc[[18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5cea8f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_fcst_17_df.drop('time',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9dbfe70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_fcst_17_df_7 = gen_fcst_17_df.iloc[[6]]\n",
    "gen_fcst_17_df_8 = gen_fcst_17_df.iloc[[7]]\n",
    "gen_fcst_17_df_9 = gen_fcst_17_df.iloc[[8]]\n",
    "gen_fcst_17_df_10 = gen_fcst_17_df.iloc[[9]]\n",
    "gen_fcst_17_df_11 = gen_fcst_17_df.iloc[[10]]\n",
    "gen_fcst_17_df_12 = gen_fcst_17_df.iloc[[11]]\n",
    "gen_fcst_17_df_13 = gen_fcst_17_df.iloc[[12]]\n",
    "gen_fcst_17_df_14 = gen_fcst_17_df.iloc[[13]]\n",
    "gen_fcst_17_df_15 = gen_fcst_17_df.iloc[[14]]\n",
    "gen_fcst_17_df_16 = gen_fcst_17_df.iloc[[15]]\n",
    "gen_fcst_17_df_17 = gen_fcst_17_df.iloc[[16]]\n",
    "gen_fcst_17_df_18 = gen_fcst_17_df.iloc[[17]]\n",
    "gen_fcst_17_df_19 = gen_fcst_17_df.iloc[[18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "783c4050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster\n",
      "1    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "2    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "0    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "1    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "0    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "1    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "1    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "1    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "2    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "2    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "1    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "1    1\n",
      "Name: count, dtype: int64\n",
      "Cluster\n",
      "0    1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-63-4f544bc801cd>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_17_df_7['Cluster'] = kmeans_7.predict(weather_fcst_17_df_7_data)\n",
      "<ipython-input-63-4f544bc801cd>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_17_df_8['Cluster'] = kmeans_8.predict(weather_fcst_17_df_8_data)\n",
      "<ipython-input-63-4f544bc801cd>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_17_df_9['Cluster'] = kmeans_9.predict(weather_fcst_17_df_9_data)\n",
      "<ipython-input-63-4f544bc801cd>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_17_df_10['Cluster'] = kmeans_10.predict(weather_fcst_17_df_10_data)\n",
      "<ipython-input-63-4f544bc801cd>:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_17_df_11['Cluster'] = kmeans_11.predict(weather_fcst_17_df_11_data)\n",
      "<ipython-input-63-4f544bc801cd>:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_17_df_12['Cluster'] = kmeans_12.predict(weather_fcst_17_df_12_data)\n",
      "<ipython-input-63-4f544bc801cd>:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_17_df_13['Cluster'] = kmeans_10.predict(weather_fcst_17_df_13_data)\n",
      "<ipython-input-63-4f544bc801cd>:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_17_df_14['Cluster'] = kmeans_14.predict(weather_fcst_17_df_14_data)\n",
      "<ipython-input-63-4f544bc801cd>:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_17_df_15['Cluster'] = kmeans_15.predict(weather_fcst_17_df_15_data)\n",
      "<ipython-input-63-4f544bc801cd>:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_17_df_16['Cluster'] = kmeans_16.predict(weather_fcst_17_df_16_data)\n",
      "<ipython-input-63-4f544bc801cd>:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_17_df_17['Cluster'] = kmeans_17.predict(weather_fcst_17_df_17_data)\n",
      "<ipython-input-63-4f544bc801cd>:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_17_df_18['Cluster'] = kmeans_18.predict(weather_fcst_17_df_18_data)\n",
      "<ipython-input-63-4f544bc801cd>:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_fcst_17_df_19['Cluster'] = kmeans_19.predict(weather_fcst_17_df_19_data)\n"
     ]
    }
   ],
   "source": [
    "# 필요한 특성 선택 (features 리스트를 merged_data_combined_12r 데이터와 동일하게 설정)\n",
    "weather_fcst_17_features = ['cloud', 'temp', 'humidity', 'ground_press',\n",
    "                            'wind_speed', 'wind_dir', 'rain', 'snow', 'dew_point',\n",
    "                            'vis', 'uv_idx', 'azimuth', 'elevation']\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_17_df_7_data = scaler_7.transform(weather_fcst_17_df_7[weather_fcst_17_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_17_df_7['Cluster'] = kmeans_7.predict(weather_fcst_17_df_7_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_17_df_7['Cluster'].value_counts())\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_17_df_8_data = scaler_8.transform(weather_fcst_17_df_8[weather_fcst_17_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_17_df_8['Cluster'] = kmeans_8.predict(weather_fcst_17_df_8_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_17_df_8['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_17_df_9_data = scaler_9.transform(weather_fcst_17_df_9[weather_fcst_17_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_17_df_9['Cluster'] = kmeans_9.predict(weather_fcst_17_df_9_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_17_df_9['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_17_df_10_data = scaler_10.transform(weather_fcst_17_df_10[weather_fcst_17_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_17_df_10['Cluster'] = kmeans_10.predict(weather_fcst_17_df_10_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_17_df_10['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_17_df_11_data = scaler_11.transform(weather_fcst_17_df_11[weather_fcst_17_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_17_df_11['Cluster'] = kmeans_11.predict(weather_fcst_17_df_11_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_17_df_11['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_17_df_12_data = scaler_12.transform(weather_fcst_17_df_12[weather_fcst_17_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_17_df_12['Cluster'] = kmeans_12.predict(weather_fcst_17_df_12_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_17_df_12['Cluster'].value_counts())\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_17_df_13_data = scaler_13.transform(weather_fcst_17_df_13[weather_fcst_17_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_17_df_13['Cluster'] = kmeans_10.predict(weather_fcst_17_df_13_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_17_df_13['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_17_df_14_data = scaler_14.transform(weather_fcst_17_df_14[weather_fcst_17_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_17_df_14['Cluster'] = kmeans_14.predict(weather_fcst_17_df_14_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_17_df_14['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_17_df_15_data = scaler_15.transform(weather_fcst_17_df_15[weather_fcst_17_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_17_df_15['Cluster'] = kmeans_15.predict(weather_fcst_17_df_15_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_17_df_15['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_17_df_16_data = scaler_16.transform(weather_fcst_17_df_16[weather_fcst_17_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_17_df_16['Cluster'] = kmeans_16.predict(weather_fcst_17_df_16_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_17_df_16['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_17_df_17_data = scaler_17.transform(weather_fcst_17_df_17[weather_fcst_17_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_17_df_17['Cluster'] = kmeans_17.predict(weather_fcst_17_df_17_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_17_df_17['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_17_df_18_data = scaler_18.transform(weather_fcst_17_df_18[weather_fcst_17_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_17_df_18['Cluster'] = kmeans_18.predict(weather_fcst_17_df_18_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_17_df_18['Cluster'].value_counts())\n",
    "\n",
    "\n",
    "# weather_fcst_10_df 데이터 표준화\n",
    "weather_fcst_17_df_19_data = scaler_19.transform(weather_fcst_17_df_19[weather_fcst_17_features])\n",
    "\n",
    "# KMeans 모델을 사용하여 군집 예측\n",
    "weather_fcst_17_df_19['Cluster'] = kmeans_19.predict(weather_fcst_17_df_19_data)\n",
    "# 예측된 클러스터 결과 출력\n",
    "print(weather_fcst_17_df_19['Cluster'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc94351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions_test_7 = stacking_model_7_1.predict(gen_fcst_10_df_7)\n",
    "predictions_test_7 = np.clip(predictions_test_7, 0, None)\n",
    "\n",
    "predictions_test_8 = stacking_model_8_0.predict(gen_fcst_10_df_8)\n",
    "predictions_test_8 = np.clip(predictions_test_8, 0, None)\n",
    "\n",
    "predictions_test_9 = stacking_model_9_2.predict(gen_fcst_10_df_9)\n",
    "predictions_test_9 = np.clip(predictions_test_9, 0, None)\n",
    "\n",
    "predictions_test_10 = stacking_model_10_1.predict(gen_fcst_10_df_10)\n",
    "predictions_test_10 = np.clip(predictions_test_10, 0, None)\n",
    "\n",
    "predictions_test_11 = stacking_model_11_2.predict(gen_fcst_10_df_11)\n",
    "predictions_test_11 = np.clip(predictions_test_11, 0, None)\n",
    "\n",
    "predictions_test_12 = stacking_model_12_1.predict(gen_fcst_10_df_12)\n",
    "predictions_test_12 = np.clip(predictions_test_12, 0, None)\n",
    "\n",
    "predictions_test_13 = stacking_model_13_1.predict(gen_fcst_10_df_13)\n",
    "predictions_test_13 = np.clip(predictions_test_13, 0, None)\n",
    "\n",
    "predictions_test_14 = stacking_model_14_1.predict(gen_fcst_10_df_14)\n",
    "predictions_test_14 = np.clip(predictions_test_14, 0, None)\n",
    "\n",
    "predictions_test_15 = stacking_model_15_1.predict(gen_fcst_10_df_15)\n",
    "predictions_test_15 = np.clip(predictions_test_15, 0, None)\n",
    "\n",
    "predictions_test_16 = stacking_model_16_2.predict(gen_fcst_10_df_16)\n",
    "predictions_test_16 = np.clip(predictions_test_16, 0, None)\n",
    "\n",
    "predictions_test_17 = stacking_model_17_1.predict(gen_fcst_10_df_17)\n",
    "predictions_test_17 = np.clip(predictions_test_17, 0, None)\n",
    "\n",
    "predictions_test_18 = stacking_model_18_1.predict(gen_fcst_10_df_18)\n",
    "predictions_test_18 = np.clip(predictions_test_18, 0, None)\n",
    "\n",
    "predictions_test_19 = stacking_model_19_1.predict(gen_fcst_10_df_19)\n",
    "predictions_test_19 = np.clip(predictions_test_19, 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0a5e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6594c26d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54b35a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>실제값</th>\n",
       "      <th>예측값</th>\n",
       "      <th>예측오차율</th>\n",
       "      <th>인센티브</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.067029</td>\n",
       "      <td>0.067706</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>2.806492</td>\n",
       "      <td>1.205564</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>22.043718</td>\n",
       "      <td>0.965941</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55</td>\n",
       "      <td>49.222267</td>\n",
       "      <td>5.836094</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>65</td>\n",
       "      <td>59.741206</td>\n",
       "      <td>5.311913</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>54</td>\n",
       "      <td>59.786143</td>\n",
       "      <td>5.844589</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>53</td>\n",
       "      <td>64.793430</td>\n",
       "      <td>11.912555</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>66</td>\n",
       "      <td>66.323282</td>\n",
       "      <td>0.326547</td>\n",
       "      <td>264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>49</td>\n",
       "      <td>53.360968</td>\n",
       "      <td>4.405019</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>32.563759</td>\n",
       "      <td>9.660362</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>12.441018</td>\n",
       "      <td>4.605032</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1.137217</td>\n",
       "      <td>1.148704</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    실제값        예측값      예측오차율   인센티브\n",
       "0     0   0.000000   0.000000    0.0\n",
       "1     0   0.000000   0.000000    0.0\n",
       "2     0   0.000000   0.000000    0.0\n",
       "3     0   0.000000   0.000000    0.0\n",
       "4     0   0.000000   0.000000    0.0\n",
       "5     0   0.000000   0.000000    0.0\n",
       "6     0   0.067029   0.067706    0.0\n",
       "7     4   2.806492   1.205564   16.0\n",
       "8    23  22.043718   0.965941   92.0\n",
       "9    55  49.222267   5.836094  220.0\n",
       "10   65  59.741206   5.311913  260.0\n",
       "11   54  59.786143   5.844589  216.0\n",
       "12   53  64.793430  11.912555    0.0\n",
       "13   66  66.323282   0.326547  264.0\n",
       "14   49  53.360968   4.405019  196.0\n",
       "15   23  32.563759   9.660362    0.0\n",
       "16   17  12.441018   4.605032   68.0\n",
       "17    0   1.137217   1.148704    0.0\n",
       "18    0   0.000000   0.000000    0.0\n",
       "19    0   0.000000   0.000000    0.0\n",
       "20    0   0.000000   0.000000    0.0\n",
       "21    0   0.000000   0.000000    0.0\n",
       "22    0   0.000000   0.000000    0.0\n",
       "23    0   0.000000   0.000000    0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 주어진 두 개의 리스트\n",
    "actual_values = actual_values_11_1\n",
    "predicted_values = new_list\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame({'실제값': actual_values, '예측값': predicted_values})\n",
    "df['예측오차율'] = (abs(df['예측값'] - df['실제값'])) * 100 / 99\n",
    "\n",
    "\n",
    "# 조건에 따라 '인센티브' 변수 값 설정\n",
    "df.loc[df['예측오차율'] <= 6, '인센티브'] = df['실제값'] * 4\n",
    "df.loc[(df['예측오차율'] > 6) & (df['예측오차율'] <= 8), '인센티브'] = df['실제값'] * 3\n",
    "df.loc[df['예측오차율'] > 8, '인센티브'] = 0\n",
    "\n",
    "# 결과 출력\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d93650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
