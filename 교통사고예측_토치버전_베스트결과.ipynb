{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1gs0g4clSWV3okTX_3c-4qIKhoaA7ZE5u",
      "authorship_tag": "ABX9TyOSlXYL6x5l79wMNkok1TZ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seung-bin99/project/blob/main/%EA%B5%90%ED%86%B5%EC%82%AC%EA%B3%A0%EC%98%88%EC%B8%A1_%ED%86%A0%EC%B9%98%EB%B2%84%EC%A0%84_%EB%B2%A0%EC%8A%A4%ED%8A%B8%EA%B2%B0%EA%B3%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XL3JpTo1oPR",
        "outputId": "ef84c378-4609-4eb8-c31b-8ce6d0769a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDzadR73e4Am"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "\n",
        "seed_everything(99) # Seed 고정"
      ],
      "metadata": {
        "id": "8fi-hKOy16jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps2-7gP8L4DF",
        "outputId": "52d72781-f95f-40d6-b660-6689391fbcb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.4.0-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.0-py3-none-any.whl (230 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.6/230.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.23)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.0 alembic-1.13.0 colorlog-6.8.0 optuna-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import KFold\n",
        "import optuna\n"
      ],
      "metadata": {
        "id": "vwcO-_bCL4FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r5mTHl8pweNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "light_df = pd.read_csv('/content/drive/MyDrive/교통사고/open/open/external_open/대구 보안등 정보.csv', encoding='cp949')[['설치개수', '소재지지번주소']]\n",
        "\n",
        "location_pattern = r'(\\S+) (\\S+) (\\S+) (\\S+)'\n",
        "\n",
        "light_df[['도시', '구', '동', '번지']] = light_df['소재지지번주소'].str.extract(location_pattern)\n",
        "light_df = light_df.drop(columns=['소재지지번주소', '번지'])\n",
        "\n",
        "light_df = light_df.groupby(['도시', '구', '동']).sum().reset_index()\n",
        "light_df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "child_area_df = pd.read_csv('/content/drive/MyDrive/교통사고/open/open/external_open/대구 어린이 보호 구역 정보.csv', encoding='cp949').drop_duplicates()[['소재지지번주소']]\n",
        "# 어린이 보호구역을 의미\n",
        "child_area_df['보호구역'] = 1\n",
        "\n",
        "location_pattern = r'(\\S+) (\\S+) (\\S+) (\\S+)'\n",
        "\n",
        "child_area_df[['도시', '구', '동', '번지']] = child_area_df['소재지지번주소'].str.extract(location_pattern)\n",
        "child_area_df = child_area_df.drop(columns=['소재지지번주소', '번지'])\n",
        "\n",
        "child_area_df = child_area_df.groupby(['도시', '구', '동']).sum().reset_index()\n",
        "child_area_df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "parking_df = pd.read_csv('/content/drive/MyDrive/교통사고/open/open/external_open/대구 주차장 정보.csv', encoding='cp949')[['소재지지번주소', '급지구분']]\n",
        "parking_df = pd.get_dummies(parking_df, columns=['급지구분'])\n",
        "\n",
        "location_pattern = r'(\\S+) (\\S+) (\\S+) (\\S+)'\n",
        "\n",
        "parking_df[['도시', '구', '동', '번지']] = parking_df['소재지지번주소'].str.extract(location_pattern)\n",
        "parking_df = parking_df.drop(columns=['소재지지번주소', '번지'])\n",
        "\n",
        "parking_df = parking_df.groupby(['도시', '구', '동']).sum().reset_index()\n",
        "parking_df.reset_index(inplace=True, drop=True)\n"
      ],
      "metadata": {
        "id": "GJEm3wZPwePU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_org = pd.read_csv('/content/drive/MyDrive/교통사고/open/open/train.csv')\n",
        "test_org = pd.read_csv('/content/drive/MyDrive/교통사고/open/open/test.csv')\n",
        "sample_submission = pd.read_csv('/content/drive/MyDrive/교통사고/open/open/sample_submission.csv')\n"
      ],
      "metadata": {
        "id": "ozYh4kbMM66a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_org.copy()\n",
        "test_df = test_org.copy()"
      ],
      "metadata": {
        "id": "BYgS5rB1QsGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_pattern = r'(\\S+) (\\S+) (\\S+)'\n",
        "\n",
        "train_df[['도시', '구', '동']] = train_org['시군구'].str.extract(location_pattern)\n",
        "train_df = train_df.drop(columns=['시군구'])\n",
        "\n",
        "test_df[['도시', '구', '동']] = test_org['시군구'].str.extract(location_pattern)\n",
        "test_df = test_df.drop(columns=['시군구'])"
      ],
      "metadata": {
        "id": "zvfuWVnXxy-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "road_pattern = r'(.+) - (.+)'\n",
        "\n",
        "train_df[['도로형태1', '도로형태2']] = train_org['도로형태'].str.extract(road_pattern)\n",
        "train_df = train_df.drop(columns=['도로형태'])\n",
        "\n",
        "test_df[['도로형태1', '도로형태2']] = test_org['도로형태'].str.extract(road_pattern)\n",
        "test_df = test_df.drop(columns=['도로형태'])"
      ],
      "metadata": {
        "id": "QIs2x-Hw8YnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df와 test_df에, light_df와 child_area_df, parking_df를 merge하세요.\n",
        "train_df = pd.merge(train_df, light_df, how='left', on=['도시', '구', '동'])\n",
        "train_df = pd.merge(train_df, child_area_df, how='left', on=['도시', '구', '동'])\n",
        "train_df = pd.merge(train_df, parking_df, how='left', on=['도시', '구', '동'])\n",
        "\n",
        "test_df = pd.merge(test_df, light_df, how='left', on=['도시', '구', '동'])\n",
        "test_df = pd.merge(test_df, child_area_df, how='left', on=['도시', '구', '동'])\n",
        "test_df = pd.merge(test_df, parking_df, how='left', on=['도시', '구', '동'])\n"
      ],
      "metadata": {
        "id": "GJzDpP5Bx4U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = test_df.drop(columns=['ID']).copy()\n",
        "train_x = train_df[test_x.columns].copy()\n",
        "train_y = train_df['ECLO'].copy()"
      ],
      "metadata": {
        "id": "bJh4XS3ZQ0s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlJwxmMr2lq6",
        "outputId": "dd643c2a-c21b-4a76-a3d8-193d52d342fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "사고일시          0\n",
              "요일            0\n",
              "기상상태          0\n",
              "노면상태          0\n",
              "사고유형          0\n",
              "도시            0\n",
              "구             0\n",
              "동             0\n",
              "도로형태1         0\n",
              "도로형태2         0\n",
              "설치개수       9513\n",
              "보호구역      18426\n",
              "급지구분_1     6543\n",
              "급지구분_2     6543\n",
              "급지구분_3     6543\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x.isna().sum()"
      ],
      "metadata": {
        "id": "8rwHnE2BquYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "845a2114-046c-474c-8685-5aac3d49fd58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "사고일시         0\n",
              "요일           0\n",
              "기상상태         0\n",
              "노면상태         0\n",
              "사고유형         0\n",
              "도시           0\n",
              "구            0\n",
              "동            0\n",
              "도로형태1        0\n",
              "도로형태2        0\n",
              "설치개수      2771\n",
              "보호구역      4961\n",
              "급지구분_1    1928\n",
              "급지구분_2    1928\n",
              "급지구분_3    1928\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "# IterativeImputer 모델 생성\n",
        "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
        "\n",
        "# '설치개수', '보호구역', '급지구분_1', '급지구분_2', '급지구분_3' 열을 포함한 열들 선택\n",
        "selected_columns = ['설치개수', '보호구역', '급지구분_1', '급지구분_2', '급지구분_3']\n",
        "data_for_imputation = train_x[selected_columns]\n",
        "\n",
        "# IterativeImputer를 사용하여 결측치 채우기\n",
        "imputed_data = imputer.fit_transform(data_for_imputation)\n",
        "\n",
        "# 결과를 기존 데이터프레임에 적용\n",
        "train_x[selected_columns] = imputed_data\n",
        "\n",
        "# train 데이터프레임에 결측치가 없는지 확인\n",
        "train_x.isna().sum()\n"
      ],
      "metadata": {
        "id": "JCaKgNB23dtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8208604a-9d59-44e2-d1e0-3351df8e0c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "사고일시      0\n",
              "요일        0\n",
              "기상상태      0\n",
              "노면상태      0\n",
              "사고유형      0\n",
              "도시        0\n",
              "구         0\n",
              "동         0\n",
              "도로형태1     0\n",
              "도로형태2     0\n",
              "설치개수      0\n",
              "보호구역      0\n",
              "급지구분_1    0\n",
              "급지구분_2    0\n",
              "급지구분_3    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# '설치개수', '보호구역', '급지구분_1', '급지구분_2', '급지구분_3' 열을 포함한 열들 선택\n",
        "selected_columns = ['설치개수', '보호구역', '급지구분_1', '급지구분_2', '급지구분_3']\n",
        "data_for_imputation = test_x[selected_columns]\n",
        "\n",
        "# IterativeImputer를 사용하여 결측치 채우기\n",
        "imputed_data = imputer.transform(data_for_imputation)\n",
        "\n",
        "# 결과를 기존 데이터프레임에 적용\n",
        "test_x[selected_columns] = imputed_data\n",
        "\n",
        "# test 데이터프레임에 결측치가 없는지 확인\n",
        "test_x.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkkZSkd3q0h7",
        "outputId": "b262bc6c-3269-4eae-a46f-938f19f6eee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "사고일시      0\n",
              "요일        0\n",
              "기상상태      0\n",
              "노면상태      0\n",
              "사고유형      0\n",
              "도시        0\n",
              "구         0\n",
              "동         0\n",
              "도로형태1     0\n",
              "도로형태2     0\n",
              "설치개수      0\n",
              "보호구역      0\n",
              "급지구분_1    0\n",
              "급지구분_2    0\n",
              "급지구분_3    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# '사고일시' 열을 datetime 형식으로 변환\n",
        "train_x['사고일시'] = pd.to_datetime(train_x['사고일시'])\n",
        "\n",
        "# datetime에서 year, month, day, hour 추출하여 새로운 열 생성\n",
        "train_x['year'] = train_x['사고일시'].dt.year\n",
        "train_x['month'] = train_x['사고일시'].dt.month\n",
        "train_x['day'] = train_x['사고일시'].dt.day\n",
        "train_x['hour'] = train_x['사고일시'].dt.hour\n",
        "\n",
        "# '사고일시' 열 삭제\n",
        "train_x.drop(columns=['사고일시'], inplace=True)"
      ],
      "metadata": {
        "id": "swE1yIu69RwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '사고일시' 열을 datetime 형식으로 변환\n",
        "test_x['사고일시'] = pd.to_datetime(test_x['사고일시'])\n",
        "\n",
        "# datetime에서 year, month, day, hour 추출하여 새로운 열 생성\n",
        "test_x['year'] = test_x['사고일시'].dt.year\n",
        "test_x['month'] = test_x['사고일시'].dt.month\n",
        "test_x['day'] = test_x['사고일시'].dt.day\n",
        "test_x['hour'] = test_x['사고일시'].dt.hour\n",
        "\n",
        "# '사고일시' 열 삭제\n",
        "test_x.drop(columns=['사고일시'], inplace=True)\n"
      ],
      "metadata": {
        "id": "zHD3V_9z8PFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "56F1jLr-RyhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRpOXkBbeO2S",
        "outputId": "00cc9622-8230-4a65-ac21-138ab062e09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.11.4)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.14.0)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.5.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2023.3.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.2.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (23.2)\n",
            "Installing collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from category_encoders.target_encoder import TargetEncoder\n",
        "\n",
        "categorical_features = list(train_x.dtypes[train_x.dtypes == \"object\"].index)\n",
        "# 추출된 문자열 변수 확인\n",
        "display(categorical_features)\n",
        "\n",
        "for i in categorical_features:\n",
        "    le = TargetEncoder(cols=[i])\n",
        "    train_x[i] = le.fit_transform(train_x[i], train_y)\n",
        "    test_x[i] = le.transform(test_x[i])\n",
        "\n",
        "display(train_x.head())\n",
        "display(test_x.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "2KTVIlHsSCXh",
        "outputId": "f1d54624-f276-4d8e-dda8-46272f0355d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['요일', '기상상태', '노면상태', '사고유형', '도시', '구', '동', '도로형태1', '도로형태2']"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         요일      기상상태      노면상태      사고유형        도시         구         동  \\\n",
              "0  4.627926  4.712888  4.712878  3.817650  4.726704  4.541610  4.282449   \n",
              "1  4.627926  4.779150  4.712878  3.817650  4.726704  4.618441  4.738938   \n",
              "2  4.627926  4.712888  4.712878  3.817650  4.726704  4.727300  4.842715   \n",
              "3  4.627926  4.712888  4.712878  4.944597  4.726704  4.687669  4.208920   \n",
              "4  4.627926  4.712888  4.712878  4.944597  4.726704  4.889534  4.549091   \n",
              "\n",
              "      도로형태1     도로형태2    설치개수       보호구역    급지구분_1    급지구분_2    급지구분_3  year  \\\n",
              "0  4.671841  4.599599   391.0   2.000000  11.00000  0.000000  0.000000  2019   \n",
              "1  4.671841  4.599599   932.0  14.400447   0.00000  1.000000  3.000000  2019   \n",
              "2  4.671841  4.599599   473.0   5.000000   3.71896  4.753207  2.504704  2019   \n",
              "3  4.671841  4.599599   534.0  11.000000   0.00000  9.000000  5.000000  2019   \n",
              "4  4.671841  4.599599  2057.0  22.187096   0.00000  1.000000  0.000000  2019   \n",
              "\n",
              "   month  day  hour  \n",
              "0      1    1     0  \n",
              "1      1    1     0  \n",
              "2      1    1     1  \n",
              "3      1    1     2  \n",
              "4      1    1     4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77d6bdcd-54ff-448f-9ac7-9ff6c9e97557\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>요일</th>\n",
              "      <th>기상상태</th>\n",
              "      <th>노면상태</th>\n",
              "      <th>사고유형</th>\n",
              "      <th>도시</th>\n",
              "      <th>구</th>\n",
              "      <th>동</th>\n",
              "      <th>도로형태1</th>\n",
              "      <th>도로형태2</th>\n",
              "      <th>설치개수</th>\n",
              "      <th>보호구역</th>\n",
              "      <th>급지구분_1</th>\n",
              "      <th>급지구분_2</th>\n",
              "      <th>급지구분_3</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.627926</td>\n",
              "      <td>4.712888</td>\n",
              "      <td>4.712878</td>\n",
              "      <td>3.817650</td>\n",
              "      <td>4.726704</td>\n",
              "      <td>4.541610</td>\n",
              "      <td>4.282449</td>\n",
              "      <td>4.671841</td>\n",
              "      <td>4.599599</td>\n",
              "      <td>391.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>11.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.627926</td>\n",
              "      <td>4.779150</td>\n",
              "      <td>4.712878</td>\n",
              "      <td>3.817650</td>\n",
              "      <td>4.726704</td>\n",
              "      <td>4.618441</td>\n",
              "      <td>4.738938</td>\n",
              "      <td>4.671841</td>\n",
              "      <td>4.599599</td>\n",
              "      <td>932.0</td>\n",
              "      <td>14.400447</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.627926</td>\n",
              "      <td>4.712888</td>\n",
              "      <td>4.712878</td>\n",
              "      <td>3.817650</td>\n",
              "      <td>4.726704</td>\n",
              "      <td>4.727300</td>\n",
              "      <td>4.842715</td>\n",
              "      <td>4.671841</td>\n",
              "      <td>4.599599</td>\n",
              "      <td>473.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.71896</td>\n",
              "      <td>4.753207</td>\n",
              "      <td>2.504704</td>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.627926</td>\n",
              "      <td>4.712888</td>\n",
              "      <td>4.712878</td>\n",
              "      <td>4.944597</td>\n",
              "      <td>4.726704</td>\n",
              "      <td>4.687669</td>\n",
              "      <td>4.208920</td>\n",
              "      <td>4.671841</td>\n",
              "      <td>4.599599</td>\n",
              "      <td>534.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.627926</td>\n",
              "      <td>4.712888</td>\n",
              "      <td>4.712878</td>\n",
              "      <td>4.944597</td>\n",
              "      <td>4.726704</td>\n",
              "      <td>4.889534</td>\n",
              "      <td>4.549091</td>\n",
              "      <td>4.671841</td>\n",
              "      <td>4.599599</td>\n",
              "      <td>2057.0</td>\n",
              "      <td>22.187096</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77d6bdcd-54ff-448f-9ac7-9ff6c9e97557')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-77d6bdcd-54ff-448f-9ac7-9ff6c9e97557 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-77d6bdcd-54ff-448f-9ac7-9ff6c9e97557');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-228efcf0-1ab6-4e43-b9da-dc2b69b21de8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-228efcf0-1ab6-4e43-b9da-dc2b69b21de8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-228efcf0-1ab6-4e43-b9da-dc2b69b21de8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         요일      기상상태      노면상태      사고유형        도시         구         동  \\\n",
              "0  4.920811  4.712888  4.712878  3.817650  4.726704  4.727300  4.881657   \n",
              "1  4.920811  4.712888  4.712878  3.817650  4.726704  4.727300  4.563008   \n",
              "2  4.920811  4.712888  4.712878  4.944597  4.726704  4.727300  4.945578   \n",
              "3  4.920811  4.712888  4.712878  4.944597  4.726704  4.727300  4.438172   \n",
              "4  4.920811  4.712888  4.712878  4.944597  4.726704  4.618441  4.738938   \n",
              "\n",
              "      도로형태1     도로형태2        설치개수       보호구역    급지구분_1    급지구분_2    급지구분_3  \\\n",
              "0  4.882281  5.006142  700.000000   5.000000  4.875551  5.000303  2.443914   \n",
              "1  4.671841  4.599599  278.938689  10.000000  0.000000  0.000000  2.000000   \n",
              "2  4.882281  5.006142 -493.931515   1.000000  0.829591  4.132296  2.324478   \n",
              "3  4.671841  4.599599  -37.623509   7.000000  0.000000  2.000000  1.000000   \n",
              "4  4.882281  5.006142  932.000000  14.400447  0.000000  1.000000  3.000000   \n",
              "\n",
              "   year  month  day  hour  \n",
              "0  2022      1    1     1  \n",
              "1  2022      1    1     1  \n",
              "2  2022      1    1     4  \n",
              "3  2022      1    1     4  \n",
              "4  2022      1    1     6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d48b3284-21d6-45dd-831f-ded4896d8e95\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>요일</th>\n",
              "      <th>기상상태</th>\n",
              "      <th>노면상태</th>\n",
              "      <th>사고유형</th>\n",
              "      <th>도시</th>\n",
              "      <th>구</th>\n",
              "      <th>동</th>\n",
              "      <th>도로형태1</th>\n",
              "      <th>도로형태2</th>\n",
              "      <th>설치개수</th>\n",
              "      <th>보호구역</th>\n",
              "      <th>급지구분_1</th>\n",
              "      <th>급지구분_2</th>\n",
              "      <th>급지구분_3</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.920811</td>\n",
              "      <td>4.712888</td>\n",
              "      <td>4.712878</td>\n",
              "      <td>3.817650</td>\n",
              "      <td>4.726704</td>\n",
              "      <td>4.727300</td>\n",
              "      <td>4.881657</td>\n",
              "      <td>4.882281</td>\n",
              "      <td>5.006142</td>\n",
              "      <td>700.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.875551</td>\n",
              "      <td>5.000303</td>\n",
              "      <td>2.443914</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.920811</td>\n",
              "      <td>4.712888</td>\n",
              "      <td>4.712878</td>\n",
              "      <td>3.817650</td>\n",
              "      <td>4.726704</td>\n",
              "      <td>4.727300</td>\n",
              "      <td>4.563008</td>\n",
              "      <td>4.671841</td>\n",
              "      <td>4.599599</td>\n",
              "      <td>278.938689</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.920811</td>\n",
              "      <td>4.712888</td>\n",
              "      <td>4.712878</td>\n",
              "      <td>4.944597</td>\n",
              "      <td>4.726704</td>\n",
              "      <td>4.727300</td>\n",
              "      <td>4.945578</td>\n",
              "      <td>4.882281</td>\n",
              "      <td>5.006142</td>\n",
              "      <td>-493.931515</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.829591</td>\n",
              "      <td>4.132296</td>\n",
              "      <td>2.324478</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.920811</td>\n",
              "      <td>4.712888</td>\n",
              "      <td>4.712878</td>\n",
              "      <td>4.944597</td>\n",
              "      <td>4.726704</td>\n",
              "      <td>4.727300</td>\n",
              "      <td>4.438172</td>\n",
              "      <td>4.671841</td>\n",
              "      <td>4.599599</td>\n",
              "      <td>-37.623509</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.920811</td>\n",
              "      <td>4.712888</td>\n",
              "      <td>4.712878</td>\n",
              "      <td>4.944597</td>\n",
              "      <td>4.726704</td>\n",
              "      <td>4.618441</td>\n",
              "      <td>4.738938</td>\n",
              "      <td>4.882281</td>\n",
              "      <td>5.006142</td>\n",
              "      <td>932.000000</td>\n",
              "      <td>14.400447</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d48b3284-21d6-45dd-831f-ded4896d8e95')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d48b3284-21d6-45dd-831f-ded4896d8e95 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d48b3284-21d6-45dd-831f-ded4896d8e95');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f4d18699-b7da-4e71-bc79-5ae8ef72c3c0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f4d18699-b7da-4e71-bc79-5ae8ef72c3c0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f4d18699-b7da-4e71-bc79-5ae8ef72c3c0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RMSLELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RMSLELoss, self).__init__()\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        assert len(predictions) == len(targets), \"Predictions and targets must have the same length.\"\n",
        "\n",
        "        predictions = torch.clamp(predictions, 0.0)  # 예측값이 음수이면 0으로 조정\n",
        "        log_diff = torch.log(predictions + 1) - torch.log(targets + 1)\n",
        "        return torch.sqrt(torch.mean(log_diff**2))"
      ],
      "metadata": {
        "id": "sxr9vi-cXsTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qI5zWlb18Hxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Convert training data to PyTorch Tensor\n",
        "train_tensor_x = torch.tensor(train_x.values, dtype=torch.float32)\n",
        "train_tensor_y = torch.tensor(train_y.values, dtype=torch.float32)\n",
        "\n",
        "# Define the number of folds\n",
        "num_folds = 5\n",
        "\n",
        "# Initialize KFold\n",
        "kf = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Lists to store results\n",
        "all_train_dataloaders = []\n",
        "all_val_dataloaders = []\n",
        "\n",
        "# Create k-fold splits and dataloaders\n",
        "for train_index, val_index in kf.split(train_tensor_x):\n",
        "    train_x_fold, val_x_fold = train_tensor_x[train_index], train_tensor_x[val_index]\n",
        "    train_y_fold, val_y_fold = train_tensor_y[train_index], train_tensor_y[val_index]\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset_fold = TensorDataset(train_x_fold, train_y_fold)\n",
        "    val_dataset_fold = TensorDataset(val_x_fold, val_y_fold)\n",
        "\n",
        "    batch_size = 64\n",
        "    # Create dataloaders\n",
        "    train_dataloader_fold = DataLoader(train_dataset_fold, batch_size=batch_size, shuffle=True)\n",
        "    val_dataloader_fold = DataLoader(val_dataset_fold, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Append to lists\n",
        "    all_train_dataloaders.append(train_dataloader_fold)\n",
        "    all_val_dataloaders.append(val_dataloader_fold)\n"
      ],
      "metadata": {
        "id": "5iO8bVe58H0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망 모델 정의\n",
        "class TrafficAccidentPredictorImproved(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(TrafficAccidentPredictorImproved, self).__init__()\n",
        "        self.batch_norm = nn.BatchNorm1d(input_size)\n",
        "        self.fc1 = nn.Linear(input_size, 256)\n",
        "        self.dropout1 = nn.Dropout(0.4)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.2)  # 드롭아웃 비율 설정\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 1)\n",
        "    def forward(self, x):\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2xtCchNmib9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    # 하이퍼파라미터 탐색 범위 지정\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
        "    patience = trial.suggest_int('patience', 5, 50)\n",
        "\n",
        "    # 모델 초기화\n",
        "    input_size = len(train_x.columns)\n",
        "    model = TrafficAccidentPredictorImproved(input_size)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # 손실 함수 및 최적화 알고리즘 정의\n",
        "    criterion = RMSLELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # 훈련 중에 손실을 기록할 리스트\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    # 모델 훈련\n",
        "    epochs = 100\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0.0\n",
        "        for batch_idx, (inputs, labels) in enumerate(train_dataloader_fold):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels.view(-1, 1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "        # 훈련 손실 기록\n",
        "        train_losses.append(total_train_loss / len(train_dataloader_fold))\n",
        "\n",
        "        # 검증 손실 기록\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            total_val_loss = 0.0\n",
        "            for val_batch_idx, (val_inputs, val_labels) in enumerate(val_dataloader_fold):\n",
        "                val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
        "                val_outputs = model(val_inputs)\n",
        "                val_loss = criterion(val_outputs, val_labels.view(-1, 1))\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "            val_losses.append(total_val_loss / len(val_dataloader_fold))\n",
        "\n",
        "        # 에폭마다 손실 출력\n",
        "        print(f'Epoch {epoch + 1}, Training Loss: {train_losses[-1]:.4f}, Validation Loss: {val_losses[-1]:.4f}')\n",
        "\n",
        "        # 조기 종료 체크\n",
        "        if epoch > patience and min(val_losses[-patience:]) >= min(val_losses):\n",
        "            print(\"Early stopping!\")\n",
        "            break\n",
        "\n",
        "    # 최적화하려는 목적 함수 (여기서는 검증 손실의 최솟값을 찾음)\n",
        "    return min(val_losses)\n",
        "\n",
        "# Optuna 스터디 실행\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "print(\"Best trial:\")\n",
        "print(\"  Value: \", study.best_trial.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in study.best_trial.params.items():\n",
        "    print(f\"    {key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9Sp6fpoaMk4",
        "outputId": "84b0c72d-f80b-4706-9795-82cc86e98830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 16:52:13,647] A new study created in memory with name: no-name-bbc955ee-bf49-4e76-98e7-d2738e707eb1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.0160, Validation Loss: 0.4834\n",
            "Epoch 2, Training Loss: 0.4878, Validation Loss: 0.4590\n",
            "Epoch 3, Training Loss: 0.4776, Validation Loss: 0.4535\n",
            "Epoch 4, Training Loss: 0.4730, Validation Loss: 0.4519\n",
            "Epoch 5, Training Loss: 0.4728, Validation Loss: 0.4508\n",
            "Epoch 6, Training Loss: 0.4695, Validation Loss: 0.4490\n",
            "Epoch 7, Training Loss: 0.4696, Validation Loss: 0.4476\n",
            "Epoch 8, Training Loss: 0.4683, Validation Loss: 0.4469\n",
            "Epoch 9, Training Loss: 0.4684, Validation Loss: 0.4457\n",
            "Epoch 10, Training Loss: 0.4651, Validation Loss: 0.4459\n",
            "Epoch 11, Training Loss: 0.4660, Validation Loss: 0.4443\n",
            "Epoch 12, Training Loss: 0.4656, Validation Loss: 0.4440\n",
            "Epoch 13, Training Loss: 0.4641, Validation Loss: 0.4433\n",
            "Epoch 14, Training Loss: 0.4623, Validation Loss: 0.4425\n",
            "Epoch 15, Training Loss: 0.4633, Validation Loss: 0.4425\n",
            "Epoch 16, Training Loss: 0.4614, Validation Loss: 0.4414\n",
            "Epoch 17, Training Loss: 0.4627, Validation Loss: 0.4416\n",
            "Epoch 18, Training Loss: 0.4606, Validation Loss: 0.4411\n",
            "Epoch 19, Training Loss: 0.4609, Validation Loss: 0.4409\n",
            "Epoch 20, Training Loss: 0.4605, Validation Loss: 0.4404\n",
            "Epoch 21, Training Loss: 0.4597, Validation Loss: 0.4399\n",
            "Epoch 22, Training Loss: 0.4592, Validation Loss: 0.4401\n",
            "Epoch 23, Training Loss: 0.4587, Validation Loss: 0.4394\n",
            "Epoch 24, Training Loss: 0.4576, Validation Loss: 0.4390\n",
            "Epoch 25, Training Loss: 0.4586, Validation Loss: 0.4392\n",
            "Epoch 26, Training Loss: 0.4577, Validation Loss: 0.4391\n",
            "Epoch 27, Training Loss: 0.4586, Validation Loss: 0.4393\n",
            "Epoch 28, Training Loss: 0.4567, Validation Loss: 0.4385\n",
            "Epoch 29, Training Loss: 0.4578, Validation Loss: 0.4388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 16:53:08,532] Trial 0 finished with value: 0.43820524023425195 and parameters: {'lr': 3.099041631255458e-05, 'patience': 28}. Best is trial 0 with value: 0.43820524023425195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30, Training Loss: 0.4569, Validation Loss: 0.4382\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 0.8611, Validation Loss: 0.4733\n",
            "Epoch 2, Training Loss: 0.4806, Validation Loss: 0.4539\n",
            "Epoch 3, Training Loss: 0.4735, Validation Loss: 0.4524\n",
            "Epoch 4, Training Loss: 0.4694, Validation Loss: 0.4492\n",
            "Epoch 5, Training Loss: 0.4675, Validation Loss: 0.4471\n",
            "Epoch 6, Training Loss: 0.4692, Validation Loss: 0.4462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 16:53:21,083] Trial 1 finished with value: 0.4445791595405148 and parameters: {'lr': 3.969393784850211e-05, 'patience': 5}. Best is trial 0 with value: 0.43820524023425195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Training Loss: 0.4654, Validation Loss: 0.4446\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 1.6347, Validation Loss: 1.3519\n",
            "Epoch 2, Training Loss: 1.0048, Validation Loss: 0.6982\n",
            "Epoch 3, Training Loss: 0.5836, Validation Loss: 0.4941\n",
            "Epoch 4, Training Loss: 0.5036, Validation Loss: 0.4763\n",
            "Epoch 5, Training Loss: 0.4931, Validation Loss: 0.4678\n",
            "Epoch 6, Training Loss: 0.4879, Validation Loss: 0.4639\n",
            "Epoch 7, Training Loss: 0.4839, Validation Loss: 0.4625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 16:53:35,050] Trial 2 finished with value: 0.4560140296816826 and parameters: {'lr': 1.0214657565608344e-05, 'patience': 6}. Best is trial 0 with value: 0.43820524023425195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Training Loss: 0.4812, Validation Loss: 0.4560\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 1.3569, Validation Loss: 1.0210\n",
            "Epoch 2, Training Loss: 0.7247, Validation Loss: 0.5084\n",
            "Epoch 3, Training Loss: 0.4983, Validation Loss: 0.4701\n",
            "Epoch 4, Training Loss: 0.4835, Validation Loss: 0.4640\n",
            "Epoch 5, Training Loss: 0.4788, Validation Loss: 0.4569\n",
            "Epoch 6, Training Loss: 0.4768, Validation Loss: 0.4543\n",
            "Epoch 7, Training Loss: 0.4732, Validation Loss: 0.4526\n",
            "Epoch 8, Training Loss: 0.4726, Validation Loss: 0.4509\n",
            "Epoch 9, Training Loss: 0.4727, Validation Loss: 0.4493\n",
            "Epoch 10, Training Loss: 0.4711, Validation Loss: 0.4486\n",
            "Epoch 11, Training Loss: 0.4713, Validation Loss: 0.4482\n",
            "Epoch 12, Training Loss: 0.4697, Validation Loss: 0.4472\n",
            "Epoch 13, Training Loss: 0.4664, Validation Loss: 0.4476\n",
            "Epoch 14, Training Loss: 0.4670, Validation Loss: 0.4462\n",
            "Epoch 15, Training Loss: 0.4666, Validation Loss: 0.4453\n",
            "Epoch 16, Training Loss: 0.4660, Validation Loss: 0.4461\n",
            "Epoch 17, Training Loss: 0.4668, Validation Loss: 0.4445\n",
            "Epoch 18, Training Loss: 0.4666, Validation Loss: 0.4448\n",
            "Epoch 19, Training Loss: 0.4644, Validation Loss: 0.4445\n",
            "Epoch 20, Training Loss: 0.4629, Validation Loss: 0.4439\n",
            "Epoch 21, Training Loss: 0.4648, Validation Loss: 0.4435\n",
            "Epoch 22, Training Loss: 0.4648, Validation Loss: 0.4431\n",
            "Epoch 23, Training Loss: 0.4632, Validation Loss: 0.4432\n",
            "Epoch 24, Training Loss: 0.4633, Validation Loss: 0.4434\n",
            "Epoch 25, Training Loss: 0.4640, Validation Loss: 0.4426\n",
            "Epoch 26, Training Loss: 0.4637, Validation Loss: 0.4432\n",
            "Epoch 27, Training Loss: 0.4605, Validation Loss: 0.4425\n",
            "Epoch 28, Training Loss: 0.4622, Validation Loss: 0.4427\n",
            "Epoch 29, Training Loss: 0.4622, Validation Loss: 0.4418\n",
            "Epoch 30, Training Loss: 0.4615, Validation Loss: 0.4420\n",
            "Epoch 31, Training Loss: 0.4616, Validation Loss: 0.4411\n",
            "Epoch 32, Training Loss: 0.4607, Validation Loss: 0.4412\n",
            "Epoch 33, Training Loss: 0.4619, Validation Loss: 0.4409\n",
            "Epoch 34, Training Loss: 0.4605, Validation Loss: 0.4413\n",
            "Epoch 35, Training Loss: 0.4609, Validation Loss: 0.4405\n",
            "Epoch 36, Training Loss: 0.4590, Validation Loss: 0.4403\n",
            "Epoch 37, Training Loss: 0.4583, Validation Loss: 0.4406\n",
            "Epoch 38, Training Loss: 0.4596, Validation Loss: 0.4402\n",
            "Epoch 39, Training Loss: 0.4608, Validation Loss: 0.4403\n",
            "Epoch 40, Training Loss: 0.4601, Validation Loss: 0.4399\n",
            "Epoch 41, Training Loss: 0.4593, Validation Loss: 0.4398\n",
            "Epoch 42, Training Loss: 0.4590, Validation Loss: 0.4397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 16:54:51,972] Trial 3 finished with value: 0.4394993337412034 and parameters: {'lr': 1.2482688474720824e-05, 'patience': 41}. Best is trial 0 with value: 0.43820524023425195.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43, Training Loss: 0.4593, Validation Loss: 0.4395\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 0.6338, Validation Loss: 0.4510\n",
            "Epoch 2, Training Loss: 0.4716, Validation Loss: 0.4482\n",
            "Epoch 3, Training Loss: 0.4679, Validation Loss: 0.4435\n",
            "Epoch 4, Training Loss: 0.4638, Validation Loss: 0.4415\n",
            "Epoch 5, Training Loss: 0.4640, Validation Loss: 0.4404\n",
            "Epoch 6, Training Loss: 0.4624, Validation Loss: 0.4404\n",
            "Epoch 7, Training Loss: 0.4600, Validation Loss: 0.4396\n",
            "Epoch 8, Training Loss: 0.4588, Validation Loss: 0.4382\n",
            "Epoch 9, Training Loss: 0.4577, Validation Loss: 0.4383\n",
            "Epoch 10, Training Loss: 0.4578, Validation Loss: 0.4376\n",
            "Epoch 11, Training Loss: 0.4567, Validation Loss: 0.4379\n",
            "Epoch 12, Training Loss: 0.4550, Validation Loss: 0.4369\n",
            "Epoch 13, Training Loss: 0.4551, Validation Loss: 0.4370\n",
            "Epoch 14, Training Loss: 0.4561, Validation Loss: 0.4369\n",
            "Epoch 15, Training Loss: 0.4535, Validation Loss: 0.4368\n",
            "Epoch 16, Training Loss: 0.4534, Validation Loss: 0.4374\n",
            "Epoch 17, Training Loss: 0.4530, Validation Loss: 0.4364\n",
            "Epoch 18, Training Loss: 0.4536, Validation Loss: 0.4362\n",
            "Epoch 19, Training Loss: 0.4538, Validation Loss: 0.4363\n",
            "Epoch 20, Training Loss: 0.4529, Validation Loss: 0.4365\n",
            "Epoch 21, Training Loss: 0.4519, Validation Loss: 0.4362\n",
            "Epoch 22, Training Loss: 0.4523, Validation Loss: 0.4372\n",
            "Epoch 23, Training Loss: 0.4505, Validation Loss: 0.4367\n",
            "Epoch 24, Training Loss: 0.4494, Validation Loss: 0.4361\n",
            "Epoch 25, Training Loss: 0.4522, Validation Loss: 0.4364\n",
            "Epoch 26, Training Loss: 0.4510, Validation Loss: 0.4378\n",
            "Epoch 27, Training Loss: 0.4516, Validation Loss: 0.4368\n",
            "Epoch 28, Training Loss: 0.4498, Validation Loss: 0.4359\n",
            "Epoch 29, Training Loss: 0.4508, Validation Loss: 0.4361\n",
            "Epoch 30, Training Loss: 0.4494, Validation Loss: 0.4357\n",
            "Epoch 31, Training Loss: 0.4508, Validation Loss: 0.4362\n",
            "Epoch 32, Training Loss: 0.4505, Validation Loss: 0.4358\n",
            "Epoch 33, Training Loss: 0.4501, Validation Loss: 0.4361\n",
            "Epoch 34, Training Loss: 0.4504, Validation Loss: 0.4370\n",
            "Epoch 35, Training Loss: 0.4498, Validation Loss: 0.4360\n",
            "Epoch 36, Training Loss: 0.4491, Validation Loss: 0.4358\n",
            "Epoch 37, Training Loss: 0.4494, Validation Loss: 0.4358\n",
            "Epoch 38, Training Loss: 0.4501, Validation Loss: 0.4363\n",
            "Epoch 39, Training Loss: 0.4483, Validation Loss: 0.4357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 16:56:04,083] Trial 4 finished with value: 0.4357050215044329 and parameters: {'lr': 0.00011862311123673333, 'patience': 38}. Best is trial 4 with value: 0.4357050215044329.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40, Training Loss: 0.4487, Validation Loss: 0.4360\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 0.6635, Validation Loss: 0.4535\n",
            "Epoch 2, Training Loss: 0.4742, Validation Loss: 0.4493\n",
            "Epoch 3, Training Loss: 0.4701, Validation Loss: 0.4459\n",
            "Epoch 4, Training Loss: 0.4660, Validation Loss: 0.4436\n",
            "Epoch 5, Training Loss: 0.4647, Validation Loss: 0.4429\n",
            "Epoch 6, Training Loss: 0.4634, Validation Loss: 0.4411\n",
            "Epoch 7, Training Loss: 0.4632, Validation Loss: 0.4403\n",
            "Epoch 8, Training Loss: 0.4610, Validation Loss: 0.4401\n",
            "Epoch 9, Training Loss: 0.4597, Validation Loss: 0.4396\n",
            "Epoch 10, Training Loss: 0.4588, Validation Loss: 0.4383\n",
            "Epoch 11, Training Loss: 0.4594, Validation Loss: 0.4383\n",
            "Epoch 12, Training Loss: 0.4589, Validation Loss: 0.4384\n",
            "Epoch 13, Training Loss: 0.4571, Validation Loss: 0.4385\n",
            "Epoch 14, Training Loss: 0.4561, Validation Loss: 0.4374\n",
            "Epoch 15, Training Loss: 0.4569, Validation Loss: 0.4373\n",
            "Epoch 16, Training Loss: 0.4550, Validation Loss: 0.4375\n",
            "Epoch 17, Training Loss: 0.4542, Validation Loss: 0.4374\n",
            "Epoch 18, Training Loss: 0.4553, Validation Loss: 0.4370\n",
            "Epoch 19, Training Loss: 0.4541, Validation Loss: 0.4368\n",
            "Epoch 20, Training Loss: 0.4537, Validation Loss: 0.4367\n",
            "Epoch 21, Training Loss: 0.4543, Validation Loss: 0.4377\n",
            "Epoch 22, Training Loss: 0.4528, Validation Loss: 0.4366\n",
            "Epoch 23, Training Loss: 0.4531, Validation Loss: 0.4365\n",
            "Epoch 24, Training Loss: 0.4531, Validation Loss: 0.4364\n",
            "Epoch 25, Training Loss: 0.4523, Validation Loss: 0.4366\n",
            "Epoch 26, Training Loss: 0.4525, Validation Loss: 0.4365\n",
            "Epoch 27, Training Loss: 0.4514, Validation Loss: 0.4362\n",
            "Epoch 28, Training Loss: 0.4513, Validation Loss: 0.4364\n",
            "Epoch 29, Training Loss: 0.4526, Validation Loss: 0.4362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 16:56:57,108] Trial 5 finished with value: 0.4361870964207957 and parameters: {'lr': 8.384841812013964e-05, 'patience': 28}. Best is trial 4 with value: 0.4357050215044329.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30, Training Loss: 0.4505, Validation Loss: 0.4362\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 0.9706, Validation Loss: 0.4613\n",
            "Epoch 2, Training Loss: 0.4776, Validation Loss: 0.4522\n",
            "Epoch 3, Training Loss: 0.4719, Validation Loss: 0.4470\n",
            "Epoch 4, Training Loss: 0.4707, Validation Loss: 0.4447\n",
            "Epoch 5, Training Loss: 0.4661, Validation Loss: 0.4447\n",
            "Epoch 6, Training Loss: 0.4650, Validation Loss: 0.4430\n",
            "Epoch 7, Training Loss: 0.4642, Validation Loss: 0.4424\n",
            "Epoch 8, Training Loss: 0.4627, Validation Loss: 0.4414\n",
            "Epoch 9, Training Loss: 0.4620, Validation Loss: 0.4410\n",
            "Epoch 10, Training Loss: 0.4599, Validation Loss: 0.4399\n",
            "Epoch 11, Training Loss: 0.4584, Validation Loss: 0.4389\n",
            "Epoch 12, Training Loss: 0.4575, Validation Loss: 0.4387\n",
            "Epoch 13, Training Loss: 0.4576, Validation Loss: 0.4387\n",
            "Epoch 14, Training Loss: 0.4573, Validation Loss: 0.4383\n",
            "Epoch 15, Training Loss: 0.4570, Validation Loss: 0.4377\n",
            "Epoch 16, Training Loss: 0.4552, Validation Loss: 0.4381\n",
            "Epoch 17, Training Loss: 0.4563, Validation Loss: 0.4370\n",
            "Epoch 18, Training Loss: 0.4553, Validation Loss: 0.4371\n",
            "Epoch 19, Training Loss: 0.4557, Validation Loss: 0.4373\n",
            "Epoch 20, Training Loss: 0.4559, Validation Loss: 0.4368\n",
            "Epoch 21, Training Loss: 0.4556, Validation Loss: 0.4369\n",
            "Epoch 22, Training Loss: 0.4536, Validation Loss: 0.4369\n",
            "Epoch 23, Training Loss: 0.4559, Validation Loss: 0.4368\n",
            "Epoch 24, Training Loss: 0.4539, Validation Loss: 0.4368\n",
            "Epoch 25, Training Loss: 0.4538, Validation Loss: 0.4366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 16:57:43,705] Trial 6 finished with value: 0.43655625995128383 and parameters: {'lr': 8.001951747004372e-05, 'patience': 24}. Best is trial 4 with value: 0.4357050215044329.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26, Training Loss: 0.4532, Validation Loss: 0.4366\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 1.3182, Validation Loss: 0.9120\n",
            "Epoch 2, Training Loss: 0.6608, Validation Loss: 0.5020\n",
            "Epoch 3, Training Loss: 0.4998, Validation Loss: 0.4733\n",
            "Epoch 4, Training Loss: 0.4875, Validation Loss: 0.4660\n",
            "Epoch 5, Training Loss: 0.4799, Validation Loss: 0.4581\n",
            "Epoch 6, Training Loss: 0.4753, Validation Loss: 0.4561\n",
            "Epoch 7, Training Loss: 0.4737, Validation Loss: 0.4527\n",
            "Epoch 8, Training Loss: 0.4730, Validation Loss: 0.4498\n",
            "Epoch 9, Training Loss: 0.4710, Validation Loss: 0.4485\n",
            "Epoch 10, Training Loss: 0.4705, Validation Loss: 0.4492\n",
            "Epoch 11, Training Loss: 0.4698, Validation Loss: 0.4482\n",
            "Epoch 12, Training Loss: 0.4692, Validation Loss: 0.4474\n",
            "Epoch 13, Training Loss: 0.4681, Validation Loss: 0.4467\n",
            "Epoch 14, Training Loss: 0.4664, Validation Loss: 0.4471\n",
            "Epoch 15, Training Loss: 0.4677, Validation Loss: 0.4460\n",
            "Epoch 16, Training Loss: 0.4659, Validation Loss: 0.4454\n",
            "Epoch 17, Training Loss: 0.4668, Validation Loss: 0.4454\n",
            "Epoch 18, Training Loss: 0.4661, Validation Loss: 0.4446\n",
            "Epoch 19, Training Loss: 0.4655, Validation Loss: 0.4446\n",
            "Epoch 20, Training Loss: 0.4653, Validation Loss: 0.4438\n",
            "Epoch 21, Training Loss: 0.4640, Validation Loss: 0.4435\n",
            "Epoch 22, Training Loss: 0.4628, Validation Loss: 0.4430\n",
            "Epoch 23, Training Loss: 0.4631, Validation Loss: 0.4432\n",
            "Epoch 24, Training Loss: 0.4637, Validation Loss: 0.4426\n",
            "Epoch 25, Training Loss: 0.4627, Validation Loss: 0.4424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 16:58:30,639] Trial 7 finished with value: 0.4419006916784471 and parameters: {'lr': 1.475797086380417e-05, 'patience': 24}. Best is trial 4 with value: 0.4357050215044329.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26, Training Loss: 0.4631, Validation Loss: 0.4419\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 0.4841, Validation Loss: 0.4383\n",
            "Epoch 2, Training Loss: 0.4596, Validation Loss: 0.4451\n",
            "Epoch 3, Training Loss: 0.4507, Validation Loss: 0.4367\n",
            "Epoch 4, Training Loss: 0.4485, Validation Loss: 0.4411\n",
            "Epoch 5, Training Loss: 0.4469, Validation Loss: 0.4450\n",
            "Epoch 6, Training Loss: 0.4469, Validation Loss: 0.4377\n",
            "Epoch 7, Training Loss: 0.4462, Validation Loss: 0.4369\n",
            "Epoch 8, Training Loss: 0.4462, Validation Loss: 0.4378\n",
            "Epoch 9, Training Loss: 0.4457, Validation Loss: 0.4375\n",
            "Epoch 10, Training Loss: 0.4456, Validation Loss: 0.4361\n",
            "Epoch 11, Training Loss: 0.4454, Validation Loss: 0.4371\n",
            "Epoch 12, Training Loss: 0.4453, Validation Loss: 0.4431\n",
            "Epoch 13, Training Loss: 0.4446, Validation Loss: 0.4369\n",
            "Epoch 14, Training Loss: 0.4446, Validation Loss: 0.4373\n",
            "Epoch 15, Training Loss: 0.4449, Validation Loss: 0.4374\n",
            "Epoch 16, Training Loss: 0.4452, Validation Loss: 0.4383\n",
            "Epoch 17, Training Loss: 0.4452, Validation Loss: 0.4374\n",
            "Epoch 18, Training Loss: 0.4453, Validation Loss: 0.4421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 16:59:05,392] Trial 8 finished with value: 0.4360756208339045 and parameters: {'lr': 0.005973794495258252, 'patience': 17}. Best is trial 4 with value: 0.4357050215044329.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Training Loss: 0.4454, Validation Loss: 0.4375\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 0.8525, Validation Loss: 0.4615\n",
            "Epoch 2, Training Loss: 0.4788, Validation Loss: 0.4531\n",
            "Epoch 3, Training Loss: 0.4750, Validation Loss: 0.4490\n",
            "Epoch 4, Training Loss: 0.4707, Validation Loss: 0.4472\n",
            "Epoch 5, Training Loss: 0.4703, Validation Loss: 0.4474\n",
            "Epoch 6, Training Loss: 0.4688, Validation Loss: 0.4462\n",
            "Epoch 7, Training Loss: 0.4678, Validation Loss: 0.4453\n",
            "Epoch 8, Training Loss: 0.4665, Validation Loss: 0.4448\n",
            "Epoch 9, Training Loss: 0.4660, Validation Loss: 0.4432\n",
            "Epoch 10, Training Loss: 0.4644, Validation Loss: 0.4425\n",
            "Epoch 11, Training Loss: 0.4641, Validation Loss: 0.4413\n",
            "Epoch 12, Training Loss: 0.4625, Validation Loss: 0.4412\n",
            "Epoch 13, Training Loss: 0.4636, Validation Loss: 0.4413\n",
            "Epoch 14, Training Loss: 0.4620, Validation Loss: 0.4405\n",
            "Epoch 15, Training Loss: 0.4606, Validation Loss: 0.4406\n",
            "Epoch 16, Training Loss: 0.4595, Validation Loss: 0.4397\n",
            "Epoch 17, Training Loss: 0.4602, Validation Loss: 0.4395\n",
            "Epoch 18, Training Loss: 0.4591, Validation Loss: 0.4387\n",
            "Epoch 19, Training Loss: 0.4591, Validation Loss: 0.4387\n",
            "Epoch 20, Training Loss: 0.4596, Validation Loss: 0.4385\n",
            "Epoch 21, Training Loss: 0.4591, Validation Loss: 0.4384\n",
            "Epoch 22, Training Loss: 0.4581, Validation Loss: 0.4384\n",
            "Epoch 23, Training Loss: 0.4577, Validation Loss: 0.4378\n",
            "Epoch 24, Training Loss: 0.4573, Validation Loss: 0.4378\n",
            "Epoch 25, Training Loss: 0.4565, Validation Loss: 0.4378\n",
            "Epoch 26, Training Loss: 0.4566, Validation Loss: 0.4377\n",
            "Epoch 27, Training Loss: 0.4562, Validation Loss: 0.4379\n",
            "Epoch 28, Training Loss: 0.4557, Validation Loss: 0.4371\n",
            "Epoch 29, Training Loss: 0.4556, Validation Loss: 0.4371\n",
            "Epoch 30, Training Loss: 0.4557, Validation Loss: 0.4373\n",
            "Epoch 31, Training Loss: 0.4547, Validation Loss: 0.4381\n",
            "Epoch 32, Training Loss: 0.4539, Validation Loss: 0.4371\n",
            "Epoch 33, Training Loss: 0.4531, Validation Loss: 0.4378\n",
            "Epoch 34, Training Loss: 0.4556, Validation Loss: 0.4370\n",
            "Epoch 35, Training Loss: 0.4546, Validation Loss: 0.4367\n",
            "Epoch 36, Training Loss: 0.4550, Validation Loss: 0.4366\n",
            "Epoch 37, Training Loss: 0.4547, Validation Loss: 0.4368\n",
            "Epoch 38, Training Loss: 0.4533, Validation Loss: 0.4366\n",
            "Epoch 39, Training Loss: 0.4538, Validation Loss: 0.4365\n",
            "Epoch 40, Training Loss: 0.4540, Validation Loss: 0.4366\n",
            "Epoch 41, Training Loss: 0.4530, Validation Loss: 0.4366\n",
            "Epoch 42, Training Loss: 0.4544, Validation Loss: 0.4364\n",
            "Epoch 43, Training Loss: 0.4528, Validation Loss: 0.4364\n",
            "Epoch 44, Training Loss: 0.4524, Validation Loss: 0.4364\n",
            "Epoch 45, Training Loss: 0.4533, Validation Loss: 0.4367\n",
            "Epoch 46, Training Loss: 0.4525, Validation Loss: 0.4363\n",
            "Epoch 47, Training Loss: 0.4535, Validation Loss: 0.4361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 17:00:31,999] Trial 9 finished with value: 0.43606715144649627 and parameters: {'lr': 4.121796801198951e-05, 'patience': 46}. Best is trial 4 with value: 0.4357050215044329.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48, Training Loss: 0.4531, Validation Loss: 0.4362\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 0.5086, Validation Loss: 0.4436\n",
            "Epoch 2, Training Loss: 0.4637, Validation Loss: 0.4403\n",
            "Epoch 3, Training Loss: 0.4587, Validation Loss: 0.4402\n",
            "Epoch 4, Training Loss: 0.4574, Validation Loss: 0.4383\n",
            "Epoch 5, Training Loss: 0.4557, Validation Loss: 0.4383\n",
            "Epoch 6, Training Loss: 0.4542, Validation Loss: 0.4372\n",
            "Epoch 7, Training Loss: 0.4539, Validation Loss: 0.4384\n",
            "Epoch 8, Training Loss: 0.4527, Validation Loss: 0.4365\n",
            "Epoch 9, Training Loss: 0.4520, Validation Loss: 0.4367\n",
            "Epoch 10, Training Loss: 0.4519, Validation Loss: 0.4374\n",
            "Epoch 11, Training Loss: 0.4505, Validation Loss: 0.4362\n",
            "Epoch 12, Training Loss: 0.4510, Validation Loss: 0.4369\n",
            "Epoch 13, Training Loss: 0.4494, Validation Loss: 0.4370\n",
            "Epoch 14, Training Loss: 0.4494, Validation Loss: 0.4368\n",
            "Epoch 15, Training Loss: 0.4494, Validation Loss: 0.4360\n",
            "Epoch 16, Training Loss: 0.4480, Validation Loss: 0.4374\n",
            "Epoch 17, Training Loss: 0.4485, Validation Loss: 0.4366\n",
            "Epoch 18, Training Loss: 0.4480, Validation Loss: 0.4360\n",
            "Epoch 19, Training Loss: 0.4471, Validation Loss: 0.4361\n",
            "Epoch 20, Training Loss: 0.4471, Validation Loss: 0.4357\n",
            "Epoch 21, Training Loss: 0.4468, Validation Loss: 0.4365\n",
            "Epoch 22, Training Loss: 0.4465, Validation Loss: 0.4375\n",
            "Epoch 23, Training Loss: 0.4470, Validation Loss: 0.4365\n",
            "Epoch 24, Training Loss: 0.4458, Validation Loss: 0.4367\n",
            "Epoch 25, Training Loss: 0.4460, Validation Loss: 0.4381\n",
            "Epoch 26, Training Loss: 0.4462, Validation Loss: 0.4362\n",
            "Epoch 27, Training Loss: 0.4458, Validation Loss: 0.4370\n",
            "Epoch 28, Training Loss: 0.4448, Validation Loss: 0.4363\n",
            "Epoch 29, Training Loss: 0.4447, Validation Loss: 0.4361\n",
            "Epoch 30, Training Loss: 0.4447, Validation Loss: 0.4366\n",
            "Epoch 31, Training Loss: 0.4449, Validation Loss: 0.4368\n",
            "Epoch 32, Training Loss: 0.4438, Validation Loss: 0.4363\n",
            "Epoch 33, Training Loss: 0.4445, Validation Loss: 0.4362\n",
            "Epoch 34, Training Loss: 0.4440, Validation Loss: 0.4359\n",
            "Epoch 35, Training Loss: 0.4444, Validation Loss: 0.4362\n",
            "Epoch 36, Training Loss: 0.4439, Validation Loss: 0.4362\n",
            "Epoch 37, Training Loss: 0.4438, Validation Loss: 0.4376\n",
            "Epoch 38, Training Loss: 0.4433, Validation Loss: 0.4368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 17:01:41,125] Trial 10 finished with value: 0.43574702763749706 and parameters: {'lr': 0.0004704461848118082, 'patience': 37}. Best is trial 4 with value: 0.4357050215044329.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39, Training Loss: 0.4437, Validation Loss: 0.4368\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 0.5248, Validation Loss: 0.4439\n",
            "Epoch 2, Training Loss: 0.4651, Validation Loss: 0.4400\n",
            "Epoch 3, Training Loss: 0.4621, Validation Loss: 0.4413\n",
            "Epoch 4, Training Loss: 0.4584, Validation Loss: 0.4386\n",
            "Epoch 5, Training Loss: 0.4587, Validation Loss: 0.4380\n",
            "Epoch 6, Training Loss: 0.4566, Validation Loss: 0.4373\n",
            "Epoch 7, Training Loss: 0.4543, Validation Loss: 0.4377\n",
            "Epoch 8, Training Loss: 0.4533, Validation Loss: 0.4368\n",
            "Epoch 9, Training Loss: 0.4539, Validation Loss: 0.4379\n",
            "Epoch 10, Training Loss: 0.4530, Validation Loss: 0.4360\n",
            "Epoch 11, Training Loss: 0.4517, Validation Loss: 0.4368\n",
            "Epoch 12, Training Loss: 0.4507, Validation Loss: 0.4393\n",
            "Epoch 13, Training Loss: 0.4514, Validation Loss: 0.4364\n",
            "Epoch 14, Training Loss: 0.4506, Validation Loss: 0.4371\n",
            "Epoch 15, Training Loss: 0.4492, Validation Loss: 0.4377\n",
            "Epoch 16, Training Loss: 0.4496, Validation Loss: 0.4365\n",
            "Epoch 17, Training Loss: 0.4494, Validation Loss: 0.4372\n",
            "Epoch 18, Training Loss: 0.4491, Validation Loss: 0.4358\n",
            "Epoch 19, Training Loss: 0.4487, Validation Loss: 0.4359\n",
            "Epoch 20, Training Loss: 0.4475, Validation Loss: 0.4364\n",
            "Epoch 21, Training Loss: 0.4478, Validation Loss: 0.4364\n",
            "Epoch 22, Training Loss: 0.4484, Validation Loss: 0.4363\n",
            "Epoch 23, Training Loss: 0.4474, Validation Loss: 0.4360\n",
            "Epoch 24, Training Loss: 0.4472, Validation Loss: 0.4357\n",
            "Epoch 25, Training Loss: 0.4466, Validation Loss: 0.4361\n",
            "Epoch 26, Training Loss: 0.4472, Validation Loss: 0.4368\n",
            "Epoch 27, Training Loss: 0.4460, Validation Loss: 0.4366\n",
            "Epoch 28, Training Loss: 0.4463, Validation Loss: 0.4356\n",
            "Epoch 29, Training Loss: 0.4464, Validation Loss: 0.4360\n",
            "Epoch 30, Training Loss: 0.4463, Validation Loss: 0.4369\n",
            "Epoch 31, Training Loss: 0.4455, Validation Loss: 0.4375\n",
            "Epoch 32, Training Loss: 0.4458, Validation Loss: 0.4370\n",
            "Epoch 33, Training Loss: 0.4453, Validation Loss: 0.4363\n",
            "Epoch 34, Training Loss: 0.4448, Validation Loss: 0.4360\n",
            "Epoch 35, Training Loss: 0.4456, Validation Loss: 0.4373\n",
            "Epoch 36, Training Loss: 0.4456, Validation Loss: 0.4361\n",
            "Epoch 37, Training Loss: 0.4444, Validation Loss: 0.4361\n",
            "Epoch 38, Training Loss: 0.4432, Validation Loss: 0.4385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 17:02:51,977] Trial 11 finished with value: 0.43562541589621573 and parameters: {'lr': 0.00046443855591809824, 'patience': 37}. Best is trial 11 with value: 0.43562541589621573.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39, Training Loss: 0.4448, Validation Loss: 0.4363\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 0.5310, Validation Loss: 0.4463\n",
            "Epoch 2, Training Loss: 0.4651, Validation Loss: 0.4406\n",
            "Epoch 3, Training Loss: 0.4620, Validation Loss: 0.4394\n",
            "Epoch 4, Training Loss: 0.4590, Validation Loss: 0.4388\n",
            "Epoch 5, Training Loss: 0.4572, Validation Loss: 0.4374\n",
            "Epoch 6, Training Loss: 0.4554, Validation Loss: 0.4376\n",
            "Epoch 7, Training Loss: 0.4554, Validation Loss: 0.4383\n",
            "Epoch 8, Training Loss: 0.4551, Validation Loss: 0.4369\n",
            "Epoch 9, Training Loss: 0.4536, Validation Loss: 0.4430\n",
            "Epoch 10, Training Loss: 0.4531, Validation Loss: 0.4366\n",
            "Epoch 11, Training Loss: 0.4529, Validation Loss: 0.4362\n",
            "Epoch 12, Training Loss: 0.4531, Validation Loss: 0.4374\n",
            "Epoch 13, Training Loss: 0.4498, Validation Loss: 0.4362\n",
            "Epoch 14, Training Loss: 0.4505, Validation Loss: 0.4364\n",
            "Epoch 15, Training Loss: 0.4508, Validation Loss: 0.4381\n",
            "Epoch 16, Training Loss: 0.4505, Validation Loss: 0.4364\n",
            "Epoch 17, Training Loss: 0.4496, Validation Loss: 0.4363\n",
            "Epoch 18, Training Loss: 0.4495, Validation Loss: 0.4361\n",
            "Epoch 19, Training Loss: 0.4486, Validation Loss: 0.4366\n",
            "Epoch 20, Training Loss: 0.4486, Validation Loss: 0.4365\n",
            "Epoch 21, Training Loss: 0.4485, Validation Loss: 0.4365\n",
            "Epoch 22, Training Loss: 0.4477, Validation Loss: 0.4362\n",
            "Epoch 23, Training Loss: 0.4470, Validation Loss: 0.4372\n",
            "Epoch 24, Training Loss: 0.4488, Validation Loss: 0.4362\n",
            "Epoch 25, Training Loss: 0.4472, Validation Loss: 0.4380\n",
            "Epoch 26, Training Loss: 0.4470, Validation Loss: 0.4369\n",
            "Epoch 27, Training Loss: 0.4467, Validation Loss: 0.4365\n",
            "Epoch 28, Training Loss: 0.4473, Validation Loss: 0.4368\n",
            "Epoch 29, Training Loss: 0.4469, Validation Loss: 0.4364\n",
            "Epoch 30, Training Loss: 0.4469, Validation Loss: 0.4404\n",
            "Epoch 31, Training Loss: 0.4456, Validation Loss: 0.4374\n",
            "Epoch 32, Training Loss: 0.4463, Validation Loss: 0.4360\n",
            "Epoch 33, Training Loss: 0.4462, Validation Loss: 0.4367\n",
            "Epoch 34, Training Loss: 0.4457, Validation Loss: 0.4366\n",
            "Epoch 35, Training Loss: 0.4457, Validation Loss: 0.4365\n",
            "Epoch 36, Training Loss: 0.4451, Validation Loss: 0.4366\n",
            "Epoch 37, Training Loss: 0.4455, Validation Loss: 0.4366\n",
            "Epoch 38, Training Loss: 0.4448, Validation Loss: 0.4363\n",
            "Epoch 39, Training Loss: 0.4456, Validation Loss: 0.4367\n",
            "Epoch 40, Training Loss: 0.4449, Validation Loss: 0.4365\n",
            "Epoch 41, Training Loss: 0.4454, Validation Loss: 0.4377\n",
            "Epoch 42, Training Loss: 0.4450, Validation Loss: 0.4365\n",
            "Epoch 43, Training Loss: 0.4442, Validation Loss: 0.4371\n",
            "Epoch 44, Training Loss: 0.4448, Validation Loss: 0.4373\n",
            "Epoch 45, Training Loss: 0.4446, Validation Loss: 0.4366\n",
            "Epoch 46, Training Loss: 0.4437, Validation Loss: 0.4368\n",
            "Epoch 47, Training Loss: 0.4445, Validation Loss: 0.4377\n",
            "Epoch 48, Training Loss: 0.4445, Validation Loss: 0.4395\n",
            "Epoch 49, Training Loss: 0.4439, Validation Loss: 0.4369\n",
            "Epoch 50, Training Loss: 0.4445, Validation Loss: 0.4378\n",
            "Epoch 51, Training Loss: 0.4438, Validation Loss: 0.4371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 17:04:25,634] Trial 12 finished with value: 0.4360039887889739 and parameters: {'lr': 0.00035706430819153586, 'patience': 50}. Best is trial 11 with value: 0.43562541589621573.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52, Training Loss: 0.4438, Validation Loss: 0.4369\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 0.5049, Validation Loss: 0.4440\n",
            "Epoch 2, Training Loss: 0.4628, Validation Loss: 0.4394\n",
            "Epoch 3, Training Loss: 0.4591, Validation Loss: 0.4417\n",
            "Epoch 4, Training Loss: 0.4580, Validation Loss: 0.4374\n",
            "Epoch 5, Training Loss: 0.4548, Validation Loss: 0.4368\n",
            "Epoch 6, Training Loss: 0.4532, Validation Loss: 0.4364\n",
            "Epoch 7, Training Loss: 0.4519, Validation Loss: 0.4369\n",
            "Epoch 8, Training Loss: 0.4520, Validation Loss: 0.4362\n",
            "Epoch 9, Training Loss: 0.4515, Validation Loss: 0.4372\n",
            "Epoch 10, Training Loss: 0.4495, Validation Loss: 0.4378\n",
            "Epoch 11, Training Loss: 0.4496, Validation Loss: 0.4368\n",
            "Epoch 12, Training Loss: 0.4483, Validation Loss: 0.4361\n",
            "Epoch 13, Training Loss: 0.4485, Validation Loss: 0.4365\n",
            "Epoch 14, Training Loss: 0.4479, Validation Loss: 0.4368\n",
            "Epoch 15, Training Loss: 0.4474, Validation Loss: 0.4359\n",
            "Epoch 16, Training Loss: 0.4468, Validation Loss: 0.4364\n",
            "Epoch 17, Training Loss: 0.4464, Validation Loss: 0.4367\n",
            "Epoch 18, Training Loss: 0.4459, Validation Loss: 0.4364\n",
            "Epoch 19, Training Loss: 0.4447, Validation Loss: 0.4367\n",
            "Epoch 20, Training Loss: 0.4464, Validation Loss: 0.4368\n",
            "Epoch 21, Training Loss: 0.4443, Validation Loss: 0.4358\n",
            "Epoch 22, Training Loss: 0.4454, Validation Loss: 0.4364\n",
            "Epoch 23, Training Loss: 0.4445, Validation Loss: 0.4366\n",
            "Epoch 24, Training Loss: 0.4447, Validation Loss: 0.4364\n",
            "Epoch 25, Training Loss: 0.4446, Validation Loss: 0.4364\n",
            "Epoch 26, Training Loss: 0.4437, Validation Loss: 0.4365\n",
            "Epoch 27, Training Loss: 0.4441, Validation Loss: 0.4368\n",
            "Epoch 28, Training Loss: 0.4443, Validation Loss: 0.4370\n",
            "Epoch 29, Training Loss: 0.4430, Validation Loss: 0.4372\n",
            "Epoch 30, Training Loss: 0.4439, Validation Loss: 0.4369\n",
            "Epoch 31, Training Loss: 0.4440, Validation Loss: 0.4374\n",
            "Epoch 32, Training Loss: 0.4434, Validation Loss: 0.4373\n",
            "Epoch 33, Training Loss: 0.4422, Validation Loss: 0.4383\n",
            "Epoch 34, Training Loss: 0.4420, Validation Loss: 0.4380\n",
            "Epoch 35, Training Loss: 0.4428, Validation Loss: 0.4372\n",
            "Epoch 36, Training Loss: 0.4418, Validation Loss: 0.4374\n",
            "Epoch 37, Training Loss: 0.4414, Validation Loss: 0.4371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 17:05:33,146] Trial 13 finished with value: 0.4357896334221286 and parameters: {'lr': 0.0009744130074279337, 'patience': 36}. Best is trial 11 with value: 0.43562541589621573.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38, Training Loss: 0.4414, Validation Loss: 0.4385\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 0.6054, Validation Loss: 0.4492\n",
            "Epoch 2, Training Loss: 0.4710, Validation Loss: 0.4462\n",
            "Epoch 3, Training Loss: 0.4658, Validation Loss: 0.4432\n",
            "Epoch 4, Training Loss: 0.4623, Validation Loss: 0.4408\n",
            "Epoch 5, Training Loss: 0.4616, Validation Loss: 0.4396\n",
            "Epoch 6, Training Loss: 0.4606, Validation Loss: 0.4397\n",
            "Epoch 7, Training Loss: 0.4586, Validation Loss: 0.4379\n",
            "Epoch 8, Training Loss: 0.4572, Validation Loss: 0.4378\n",
            "Epoch 9, Training Loss: 0.4565, Validation Loss: 0.4373\n",
            "Epoch 10, Training Loss: 0.4551, Validation Loss: 0.4384\n",
            "Epoch 11, Training Loss: 0.4561, Validation Loss: 0.4374\n",
            "Epoch 12, Training Loss: 0.4537, Validation Loss: 0.4366\n",
            "Epoch 13, Training Loss: 0.4537, Validation Loss: 0.4368\n",
            "Epoch 14, Training Loss: 0.4540, Validation Loss: 0.4364\n",
            "Epoch 15, Training Loss: 0.4524, Validation Loss: 0.4366\n",
            "Epoch 16, Training Loss: 0.4523, Validation Loss: 0.4373\n",
            "Epoch 17, Training Loss: 0.4524, Validation Loss: 0.4362\n",
            "Epoch 18, Training Loss: 0.4523, Validation Loss: 0.4365\n",
            "Epoch 19, Training Loss: 0.4515, Validation Loss: 0.4364\n",
            "Epoch 20, Training Loss: 0.4503, Validation Loss: 0.4366\n",
            "Epoch 21, Training Loss: 0.4503, Validation Loss: 0.4364\n",
            "Epoch 22, Training Loss: 0.4509, Validation Loss: 0.4362\n",
            "Epoch 23, Training Loss: 0.4511, Validation Loss: 0.4362\n",
            "Epoch 24, Training Loss: 0.4497, Validation Loss: 0.4373\n",
            "Epoch 25, Training Loss: 0.4498, Validation Loss: 0.4372\n",
            "Epoch 26, Training Loss: 0.4495, Validation Loss: 0.4363\n",
            "Epoch 27, Training Loss: 0.4508, Validation Loss: 0.4363\n",
            "Epoch 28, Training Loss: 0.4507, Validation Loss: 0.4371\n",
            "Epoch 29, Training Loss: 0.4496, Validation Loss: 0.4360\n",
            "Epoch 30, Training Loss: 0.4490, Validation Loss: 0.4366\n",
            "Epoch 31, Training Loss: 0.4488, Validation Loss: 0.4377\n",
            "Epoch 32, Training Loss: 0.4501, Validation Loss: 0.4359\n",
            "Epoch 33, Training Loss: 0.4488, Validation Loss: 0.4362\n",
            "Epoch 34, Training Loss: 0.4485, Validation Loss: 0.4362\n",
            "Epoch 35, Training Loss: 0.4478, Validation Loss: 0.4362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 17:06:37,836] Trial 14 finished with value: 0.43589327003686656 and parameters: {'lr': 0.00015785997887917514, 'patience': 34}. Best is trial 11 with value: 0.43562541589621573.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36, Training Loss: 0.4487, Validation Loss: 0.4359\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 0.4977, Validation Loss: 0.4433\n",
            "Epoch 2, Training Loss: 0.4628, Validation Loss: 0.4385\n",
            "Epoch 3, Training Loss: 0.4583, Validation Loss: 0.4381\n",
            "Epoch 4, Training Loss: 0.4568, Validation Loss: 0.4392\n",
            "Epoch 5, Training Loss: 0.4554, Validation Loss: 0.4374\n",
            "Epoch 6, Training Loss: 0.4536, Validation Loss: 0.4370\n",
            "Epoch 7, Training Loss: 0.4519, Validation Loss: 0.4380\n",
            "Epoch 8, Training Loss: 0.4527, Validation Loss: 0.4397\n",
            "Epoch 9, Training Loss: 0.4508, Validation Loss: 0.4365\n",
            "Epoch 10, Training Loss: 0.4512, Validation Loss: 0.4361\n",
            "Epoch 11, Training Loss: 0.4489, Validation Loss: 0.4377\n",
            "Epoch 12, Training Loss: 0.4490, Validation Loss: 0.4360\n",
            "Epoch 13, Training Loss: 0.4477, Validation Loss: 0.4368\n",
            "Epoch 14, Training Loss: 0.4476, Validation Loss: 0.4363\n",
            "Epoch 15, Training Loss: 0.4479, Validation Loss: 0.4372\n",
            "Epoch 16, Training Loss: 0.4470, Validation Loss: 0.4366\n",
            "Epoch 17, Training Loss: 0.4468, Validation Loss: 0.4367\n",
            "Epoch 18, Training Loss: 0.4463, Validation Loss: 0.4363\n",
            "Epoch 19, Training Loss: 0.4463, Validation Loss: 0.4359\n",
            "Epoch 20, Training Loss: 0.4465, Validation Loss: 0.4374\n",
            "Epoch 21, Training Loss: 0.4461, Validation Loss: 0.4377\n",
            "Epoch 22, Training Loss: 0.4454, Validation Loss: 0.4360\n",
            "Epoch 23, Training Loss: 0.4458, Validation Loss: 0.4361\n",
            "Epoch 24, Training Loss: 0.4449, Validation Loss: 0.4373\n",
            "Epoch 25, Training Loss: 0.4447, Validation Loss: 0.4363\n",
            "Epoch 26, Training Loss: 0.4449, Validation Loss: 0.4362\n",
            "Epoch 27, Training Loss: 0.4446, Validation Loss: 0.4375\n",
            "Epoch 28, Training Loss: 0.4449, Validation Loss: 0.4366\n",
            "Epoch 29, Training Loss: 0.4436, Validation Loss: 0.4366\n",
            "Epoch 30, Training Loss: 0.4441, Validation Loss: 0.4381\n",
            "Epoch 31, Training Loss: 0.4434, Validation Loss: 0.4364\n",
            "Epoch 32, Training Loss: 0.4442, Validation Loss: 0.4364\n",
            "Epoch 33, Training Loss: 0.4438, Validation Loss: 0.4363\n",
            "Epoch 34, Training Loss: 0.4430, Validation Loss: 0.4381\n",
            "Epoch 35, Training Loss: 0.4429, Validation Loss: 0.4370\n",
            "Epoch 36, Training Loss: 0.4421, Validation Loss: 0.4365\n",
            "Epoch 37, Training Loss: 0.4437, Validation Loss: 0.4372\n",
            "Epoch 38, Training Loss: 0.4425, Validation Loss: 0.4367\n",
            "Epoch 39, Training Loss: 0.4424, Validation Loss: 0.4371\n",
            "Epoch 40, Training Loss: 0.4425, Validation Loss: 0.4370\n",
            "Epoch 41, Training Loss: 0.4420, Validation Loss: 0.4370\n",
            "Epoch 42, Training Loss: 0.4417, Validation Loss: 0.4369\n",
            "Epoch 43, Training Loss: 0.4426, Validation Loss: 0.4374\n",
            "Epoch 44, Training Loss: 0.4414, Validation Loss: 0.4386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 17:07:58,346] Trial 15 finished with value: 0.43585837800656596 and parameters: {'lr': 0.0008384060150765523, 'patience': 43}. Best is trial 11 with value: 0.43562541589621573.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45, Training Loss: 0.4415, Validation Loss: 0.4374\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 0.5541, Validation Loss: 0.4467\n",
            "Epoch 2, Training Loss: 0.4658, Validation Loss: 0.4437\n",
            "Epoch 3, Training Loss: 0.4638, Validation Loss: 0.4400\n",
            "Epoch 4, Training Loss: 0.4605, Validation Loss: 0.4387\n",
            "Epoch 5, Training Loss: 0.4570, Validation Loss: 0.4387\n",
            "Epoch 6, Training Loss: 0.4580, Validation Loss: 0.4382\n",
            "Epoch 7, Training Loss: 0.4571, Validation Loss: 0.4369\n",
            "Epoch 8, Training Loss: 0.4548, Validation Loss: 0.4377\n",
            "Epoch 9, Training Loss: 0.4543, Validation Loss: 0.4368\n",
            "Epoch 10, Training Loss: 0.4537, Validation Loss: 0.4364\n",
            "Epoch 11, Training Loss: 0.4533, Validation Loss: 0.4381\n",
            "Epoch 12, Training Loss: 0.4523, Validation Loss: 0.4361\n",
            "Epoch 13, Training Loss: 0.4522, Validation Loss: 0.4364\n",
            "Epoch 14, Training Loss: 0.4508, Validation Loss: 0.4389\n",
            "Epoch 15, Training Loss: 0.4504, Validation Loss: 0.4366\n",
            "Epoch 16, Training Loss: 0.4507, Validation Loss: 0.4364\n",
            "Epoch 17, Training Loss: 0.4501, Validation Loss: 0.4376\n",
            "Epoch 18, Training Loss: 0.4505, Validation Loss: 0.4359\n",
            "Epoch 19, Training Loss: 0.4501, Validation Loss: 0.4369\n",
            "Epoch 20, Training Loss: 0.4496, Validation Loss: 0.4369\n",
            "Epoch 21, Training Loss: 0.4490, Validation Loss: 0.4412\n",
            "Epoch 22, Training Loss: 0.4508, Validation Loss: 0.4372\n",
            "Epoch 23, Training Loss: 0.4488, Validation Loss: 0.4363\n",
            "Epoch 24, Training Loss: 0.4492, Validation Loss: 0.4365\n",
            "Epoch 25, Training Loss: 0.4481, Validation Loss: 0.4370\n",
            "Epoch 26, Training Loss: 0.4492, Validation Loss: 0.4363\n",
            "Epoch 27, Training Loss: 0.4485, Validation Loss: 0.4367\n",
            "Epoch 28, Training Loss: 0.4481, Validation Loss: 0.4363\n",
            "Epoch 29, Training Loss: 0.4482, Validation Loss: 0.4363\n",
            "Epoch 30, Training Loss: 0.4475, Validation Loss: 0.4361\n",
            "Epoch 31, Training Loss: 0.4475, Validation Loss: 0.4380\n",
            "Epoch 32, Training Loss: 0.4471, Validation Loss: 0.4363\n",
            "Epoch 33, Training Loss: 0.4471, Validation Loss: 0.4366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 17:08:59,824] Trial 16 finished with value: 0.4358564670528135 and parameters: {'lr': 0.000225806375143379, 'patience': 32}. Best is trial 11 with value: 0.43562541589621573.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34, Training Loss: 0.4483, Validation Loss: 0.4373\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 0.4909, Validation Loss: 0.4555\n",
            "Epoch 2, Training Loss: 0.4638, Validation Loss: 0.4371\n",
            "Epoch 3, Training Loss: 0.4573, Validation Loss: 0.4368\n",
            "Epoch 4, Training Loss: 0.4552, Validation Loss: 0.4364\n",
            "Epoch 5, Training Loss: 0.4531, Validation Loss: 0.4379\n",
            "Epoch 6, Training Loss: 0.4510, Validation Loss: 0.4373\n",
            "Epoch 7, Training Loss: 0.4502, Validation Loss: 0.4406\n",
            "Epoch 8, Training Loss: 0.4479, Validation Loss: 0.4368\n",
            "Epoch 9, Training Loss: 0.4470, Validation Loss: 0.4361\n",
            "Epoch 10, Training Loss: 0.4476, Validation Loss: 0.4413\n",
            "Epoch 11, Training Loss: 0.4467, Validation Loss: 0.4363\n",
            "Epoch 12, Training Loss: 0.4469, Validation Loss: 0.4374\n",
            "Epoch 13, Training Loss: 0.4468, Validation Loss: 0.4362\n",
            "Epoch 14, Training Loss: 0.4454, Validation Loss: 0.4370\n",
            "Epoch 15, Training Loss: 0.4451, Validation Loss: 0.4369\n",
            "Epoch 16, Training Loss: 0.4456, Validation Loss: 0.4369\n",
            "Epoch 17, Training Loss: 0.4456, Validation Loss: 0.4385\n",
            "Epoch 18, Training Loss: 0.4453, Validation Loss: 0.4364\n",
            "Epoch 19, Training Loss: 0.4446, Validation Loss: 0.4366\n",
            "Epoch 20, Training Loss: 0.4444, Validation Loss: 0.4376\n",
            "Epoch 21, Training Loss: 0.4445, Validation Loss: 0.4372\n",
            "Epoch 22, Training Loss: 0.4439, Validation Loss: 0.4372\n",
            "Epoch 23, Training Loss: 0.4436, Validation Loss: 0.4375\n",
            "Epoch 24, Training Loss: 0.4427, Validation Loss: 0.4366\n",
            "Epoch 25, Training Loss: 0.4431, Validation Loss: 0.4380\n",
            "Epoch 26, Training Loss: 0.4432, Validation Loss: 0.4371\n",
            "Epoch 27, Training Loss: 0.4434, Validation Loss: 0.4369\n",
            "Epoch 28, Training Loss: 0.4425, Validation Loss: 0.4381\n",
            "Epoch 29, Training Loss: 0.4431, Validation Loss: 0.4366\n",
            "Epoch 30, Training Loss: 0.4421, Validation Loss: 0.4371\n",
            "Epoch 31, Training Loss: 0.4429, Validation Loss: 0.4370\n",
            "Epoch 32, Training Loss: 0.4421, Validation Loss: 0.4372\n",
            "Epoch 33, Training Loss: 0.4418, Validation Loss: 0.4375\n",
            "Epoch 34, Training Loss: 0.4421, Validation Loss: 0.4372\n",
            "Epoch 35, Training Loss: 0.4414, Validation Loss: 0.4370\n",
            "Epoch 36, Training Loss: 0.4413, Validation Loss: 0.4380\n",
            "Epoch 37, Training Loss: 0.4418, Validation Loss: 0.4382\n",
            "Epoch 38, Training Loss: 0.4414, Validation Loss: 0.4374\n",
            "Epoch 39, Training Loss: 0.4408, Validation Loss: 0.4389\n",
            "Epoch 40, Training Loss: 0.4410, Validation Loss: 0.4376\n",
            "Epoch 41, Training Loss: 0.4404, Validation Loss: 0.4379\n",
            "Epoch 42, Training Loss: 0.4399, Validation Loss: 0.4386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 17:10:17,813] Trial 17 finished with value: 0.43608679718548254 and parameters: {'lr': 0.0017160592265425133, 'patience': 41}. Best is trial 11 with value: 0.43562541589621573.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43, Training Loss: 0.4404, Validation Loss: 0.4381\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 0.5898, Validation Loss: 0.4517\n",
            "Epoch 2, Training Loss: 0.4706, Validation Loss: 0.4471\n",
            "Epoch 3, Training Loss: 0.4660, Validation Loss: 0.4428\n",
            "Epoch 4, Training Loss: 0.4636, Validation Loss: 0.4407\n",
            "Epoch 5, Training Loss: 0.4611, Validation Loss: 0.4388\n",
            "Epoch 6, Training Loss: 0.4583, Validation Loss: 0.4384\n",
            "Epoch 7, Training Loss: 0.4591, Validation Loss: 0.4380\n",
            "Epoch 8, Training Loss: 0.4565, Validation Loss: 0.4369\n",
            "Epoch 9, Training Loss: 0.4563, Validation Loss: 0.4366\n",
            "Epoch 10, Training Loss: 0.4570, Validation Loss: 0.4373\n",
            "Epoch 11, Training Loss: 0.4551, Validation Loss: 0.4362\n",
            "Epoch 12, Training Loss: 0.4539, Validation Loss: 0.4374\n",
            "Epoch 13, Training Loss: 0.4538, Validation Loss: 0.4366\n",
            "Epoch 14, Training Loss: 0.4536, Validation Loss: 0.4363\n",
            "Epoch 15, Training Loss: 0.4530, Validation Loss: 0.4362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 17:10:46,739] Trial 18 finished with value: 0.43622849593239443 and parameters: {'lr': 0.00015497402923909538, 'patience': 14}. Best is trial 11 with value: 0.43562541589621573.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Training Loss: 0.4524, Validation Loss: 0.4365\n",
            "Early stopping!\n",
            "Epoch 1, Training Loss: 0.5324, Validation Loss: 0.4442\n",
            "Epoch 2, Training Loss: 0.4642, Validation Loss: 0.4408\n",
            "Epoch 3, Training Loss: 0.4608, Validation Loss: 0.4380\n",
            "Epoch 4, Training Loss: 0.4575, Validation Loss: 0.4384\n",
            "Epoch 5, Training Loss: 0.4574, Validation Loss: 0.4373\n",
            "Epoch 6, Training Loss: 0.4552, Validation Loss: 0.4372\n",
            "Epoch 7, Training Loss: 0.4543, Validation Loss: 0.4371\n",
            "Epoch 8, Training Loss: 0.4535, Validation Loss: 0.4366\n",
            "Epoch 9, Training Loss: 0.4522, Validation Loss: 0.4366\n",
            "Epoch 10, Training Loss: 0.4519, Validation Loss: 0.4366\n",
            "Epoch 11, Training Loss: 0.4523, Validation Loss: 0.4365\n",
            "Epoch 12, Training Loss: 0.4502, Validation Loss: 0.4374\n",
            "Epoch 13, Training Loss: 0.4510, Validation Loss: 0.4376\n",
            "Epoch 14, Training Loss: 0.4507, Validation Loss: 0.4366\n",
            "Epoch 15, Training Loss: 0.4501, Validation Loss: 0.4372\n",
            "Epoch 16, Training Loss: 0.4500, Validation Loss: 0.4367\n",
            "Epoch 17, Training Loss: 0.4500, Validation Loss: 0.4373\n",
            "Epoch 18, Training Loss: 0.4495, Validation Loss: 0.4362\n",
            "Epoch 19, Training Loss: 0.4488, Validation Loss: 0.4369\n",
            "Epoch 20, Training Loss: 0.4491, Validation Loss: 0.4363\n",
            "Epoch 21, Training Loss: 0.4494, Validation Loss: 0.4359\n",
            "Epoch 22, Training Loss: 0.4479, Validation Loss: 0.4371\n",
            "Epoch 23, Training Loss: 0.4481, Validation Loss: 0.4363\n",
            "Epoch 24, Training Loss: 0.4479, Validation Loss: 0.4383\n",
            "Epoch 25, Training Loss: 0.4471, Validation Loss: 0.4364\n",
            "Epoch 26, Training Loss: 0.4474, Validation Loss: 0.4419\n",
            "Epoch 27, Training Loss: 0.4465, Validation Loss: 0.4364\n",
            "Epoch 28, Training Loss: 0.4471, Validation Loss: 0.4368\n",
            "Epoch 29, Training Loss: 0.4470, Validation Loss: 0.4364\n",
            "Epoch 30, Training Loss: 0.4471, Validation Loss: 0.4361\n",
            "Epoch 31, Training Loss: 0.4464, Validation Loss: 0.4362\n",
            "Epoch 32, Training Loss: 0.4457, Validation Loss: 0.4365\n",
            "Epoch 33, Training Loss: 0.4465, Validation Loss: 0.4366\n",
            "Epoch 34, Training Loss: 0.4461, Validation Loss: 0.4363\n",
            "Epoch 35, Training Loss: 0.4457, Validation Loss: 0.4369\n",
            "Epoch 36, Training Loss: 0.4454, Validation Loss: 0.4363\n",
            "Epoch 37, Training Loss: 0.4444, Validation Loss: 0.4363\n",
            "Epoch 38, Training Loss: 0.4449, Validation Loss: 0.4378\n",
            "Epoch 39, Training Loss: 0.4447, Validation Loss: 0.4365\n",
            "Epoch 40, Training Loss: 0.4442, Validation Loss: 0.4364\n",
            "Epoch 41, Training Loss: 0.4442, Validation Loss: 0.4379\n",
            "Epoch 42, Training Loss: 0.4451, Validation Loss: 0.4366\n",
            "Epoch 43, Training Loss: 0.4447, Validation Loss: 0.4365\n",
            "Epoch 44, Training Loss: 0.4439, Validation Loss: 0.4375\n",
            "Epoch 45, Training Loss: 0.4451, Validation Loss: 0.4389\n",
            "Epoch 46, Training Loss: 0.4456, Validation Loss: 0.4368\n",
            "Epoch 47, Training Loss: 0.4442, Validation Loss: 0.4375\n",
            "Epoch 48, Training Loss: 0.4436, Validation Loss: 0.4370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-03 17:12:14,169] Trial 19 finished with value: 0.43593017276256313 and parameters: {'lr': 0.0004095603340054647, 'patience': 47}. Best is trial 11 with value: 0.43562541589621573.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49, Training Loss: 0.4432, Validation Loss: 0.4369\n",
            "Early stopping!\n",
            "Best trial:\n",
            "  Value:  0.43562541589621573\n",
            "  Params: \n",
            "    lr: 0.00046443855591809824\n",
            "    patience: 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 제일 좋은 파라미터\n",
        "Best trial:\n",
        "  Value:  0.43562541589621573\n",
        "  Params:\n",
        "    lr: 0.00046443855591809824\n",
        "    patience: 37"
      ],
      "metadata": {
        "id": "j5si5PmbsYCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적의 하이퍼파라미터로 모델 재훈련\n",
        "best_lr = study.best_params['lr']\n",
        "best_patience = study.best_params['patience']\n",
        "\n",
        "# 모델 초기화\n",
        "input_size = len(train_x.columns)\n",
        "model = TrafficAccidentPredictorImproved(input_size)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# 손실 함수 및 최적화 알고리즘 정의\n",
        "criterion = RMSLELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=best_lr)\n",
        "\n",
        "# 훈련 중에 손실을 기록할 리스트\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# 모델 훈련\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_train_loss = 0.0\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_dataloader_fold):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "    # 훈련 손실 기록\n",
        "    train_losses.append(total_train_loss / len(train_dataloader_fold))\n",
        "\n",
        "    # 검증 손실 기록\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_val_loss = 0.0\n",
        "        for val_batch_idx, (val_inputs, val_labels) in enumerate(val_dataloader_fold):\n",
        "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
        "            val_outputs = model(val_inputs)\n",
        "            val_loss = criterion(val_outputs, val_labels.view(-1, 1))\n",
        "            total_val_loss += val_loss.item()\n",
        "\n",
        "        val_losses.append(total_val_loss / len(val_dataloader_fold))\n",
        "\n",
        "    # 에폭마다 손실 출력\n",
        "    print(f'Epoch {epoch + 1}, Training Loss: {train_losses[-1]:.4f}, Validation Loss: {val_losses[-1]:.4f}')\n",
        "\n",
        "    # 조기 종료 체크\n",
        "    if epoch > best_patience and min(val_losses[-best_patience:]) >= min(val_losses):\n",
        "        print(\"Early stopping!\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tI_z-qwq1Qi",
        "outputId": "493cbce5-9ad8-4735-8e77-f3de47a9eefd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 0.5396, Validation Loss: 0.4448\n",
            "Epoch 2, Training Loss: 0.4643, Validation Loss: 0.4409\n",
            "Epoch 3, Training Loss: 0.4614, Validation Loss: 0.4409\n",
            "Epoch 4, Training Loss: 0.4588, Validation Loss: 0.4386\n",
            "Epoch 5, Training Loss: 0.4569, Validation Loss: 0.4366\n",
            "Epoch 6, Training Loss: 0.4569, Validation Loss: 0.4399\n",
            "Epoch 7, Training Loss: 0.4547, Validation Loss: 0.4365\n",
            "Epoch 8, Training Loss: 0.4550, Validation Loss: 0.4377\n",
            "Epoch 9, Training Loss: 0.4531, Validation Loss: 0.4435\n",
            "Epoch 10, Training Loss: 0.4522, Validation Loss: 0.4372\n",
            "Epoch 11, Training Loss: 0.4522, Validation Loss: 0.4370\n",
            "Epoch 12, Training Loss: 0.4505, Validation Loss: 0.4393\n",
            "Epoch 13, Training Loss: 0.4520, Validation Loss: 0.4366\n",
            "Epoch 14, Training Loss: 0.4507, Validation Loss: 0.4362\n",
            "Epoch 15, Training Loss: 0.4491, Validation Loss: 0.4366\n",
            "Epoch 16, Training Loss: 0.4490, Validation Loss: 0.4360\n",
            "Epoch 17, Training Loss: 0.4494, Validation Loss: 0.4415\n",
            "Epoch 18, Training Loss: 0.4488, Validation Loss: 0.4372\n",
            "Epoch 19, Training Loss: 0.4484, Validation Loss: 0.4379\n",
            "Epoch 20, Training Loss: 0.4486, Validation Loss: 0.4365\n",
            "Epoch 21, Training Loss: 0.4479, Validation Loss: 0.4357\n",
            "Epoch 22, Training Loss: 0.4471, Validation Loss: 0.4361\n",
            "Epoch 23, Training Loss: 0.4474, Validation Loss: 0.4361\n",
            "Epoch 24, Training Loss: 0.4470, Validation Loss: 0.4392\n",
            "Epoch 25, Training Loss: 0.4467, Validation Loss: 0.4364\n",
            "Epoch 26, Training Loss: 0.4468, Validation Loss: 0.4363\n",
            "Epoch 27, Training Loss: 0.4462, Validation Loss: 0.4365\n",
            "Epoch 28, Training Loss: 0.4469, Validation Loss: 0.4365\n",
            "Epoch 29, Training Loss: 0.4459, Validation Loss: 0.4365\n",
            "Epoch 30, Training Loss: 0.4465, Validation Loss: 0.4364\n",
            "Epoch 31, Training Loss: 0.4452, Validation Loss: 0.4396\n",
            "Epoch 32, Training Loss: 0.4457, Validation Loss: 0.4361\n",
            "Epoch 33, Training Loss: 0.4455, Validation Loss: 0.4364\n",
            "Epoch 34, Training Loss: 0.4453, Validation Loss: 0.4361\n",
            "Epoch 35, Training Loss: 0.4453, Validation Loss: 0.4363\n",
            "Epoch 36, Training Loss: 0.4452, Validation Loss: 0.4363\n",
            "Epoch 37, Training Loss: 0.4444, Validation Loss: 0.4377\n",
            "Epoch 38, Training Loss: 0.4448, Validation Loss: 0.4364\n",
            "Epoch 39, Training Loss: 0.4452, Validation Loss: 0.4373\n",
            "Early stopping!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JgkCAamWq7bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "QOCqyQZKT3KM",
        "outputId": "dcb45066-ccc9-4fc7-d6f6-c2cd90346efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 모델 가중치 불러오기\n",
        "model.load_state_dict(torch.load(\"./TrafficAccidentPredictor.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# train_x 데이터를 텐서로 변환하여 모델에 입력\n",
        "train_inp = torch.tensor(train_x.values, dtype=torch.float32)\n",
        "train_inp_preds = train_inp.to(device)  # 모델의 디바이스로 옮기기\n",
        "\n",
        "# 모델을 사용하여 예측 수행\n",
        "with torch.no_grad():\n",
        "    train_preds = model(train_inp_preds)\n",
        "\n",
        "# targets을 모델의 디바이스로 옮기기\n",
        "targets = torch.tensor(train_y.values, dtype=torch.float32)\n",
        "targets = targets.to(device)\n",
        "\n",
        "# RMSLE 계산 using RMSLELoss\n",
        "criterion = RMSLELoss()\n",
        "rmsle = criterion(train_preds, targets)\n",
        "\n",
        "print(f\"트레인 데이터에 대한 RMSLE: {rmsle.item():.4f}\")\n"
      ],
      "metadata": {
        "id": "nJ45qBMeVzjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터로 예측\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_inputs = torch.tensor(test_x.values, dtype=torch.float32)\n",
        "    # test_inputs를 모델이 사용하는 디바이스로 옮기기\n",
        "    test_inputs = test_inputs.to(device)\n",
        "    predictions = model(test_inputs)\n",
        "\n",
        "# 예측 결과 출력\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ_iFI3KldrO",
        "outputId": "cd1ee9cf-7112-41f1-d331-3a7ffdb71425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3.8930],\n",
            "        [3.5907],\n",
            "        [4.8030],\n",
            "        ...,\n",
            "        [4.7229],\n",
            "        [4.5466],\n",
            "        [4.5366]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CUDA(GPU)에서 CPU로 텐서 옮기기\n",
        "predictions_array = predictions.cpu().numpy().flatten()\n",
        "sample_submission[\"ECLO\"] = predictions_array\n",
        "sample_submission.to_csv('/content/drive/MyDrive/교통사고/result/submission_토치14.csv',index=False)"
      ],
      "metadata": {
        "id": "WYOnQu65ldtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EaPCuUt7yE2u"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wSw-e2OTezVz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}